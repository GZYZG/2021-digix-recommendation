{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "gkNWKaPTpxiB",
    "outputId": "2a91c159-0121-4ca0-866f-618514ce5e60",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datatable as dt\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "SEED = 42\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 节约内存的一个标配函数\n",
    "def reduce_mem(df):\n",
    "    starttime = time.time()\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if pd.isnull(c_min) or pd.isnull(c_max):\n",
    "                continue\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('-- Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction),time spend:{:2.2f} min'.format(end_mem,\n",
    "                                                                                                           100*(start_mem-end_mem)/start_mem,\n",
    "                                                                                                           (time.time()-starttime)/60))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(label, predict, n):\n",
    "    \"\"\"\n",
    "    计算混淆矩阵\n",
    "    :param label: 标签，np.array类型。形状可以是(n_sample,) 或者 (n_sample, n_classes)，当为第二种形状时可以表示多标签分类的情况\n",
    "    :param predict: 预测值，与 `label` 同理\n",
    "    :param n: 类别数目\n",
    "    :return: 混淆矩阵，np.array类型。shape 为 (n, n)。$cm_{ij}$表示真实标签为 $i$，预测标签为 $j$ 的样本个数\n",
    "    \"\"\"\n",
    "    k = (label >= 0) & (label < n)\n",
    "    # bincount()函数用于统计数组内每个非负整数的个数\n",
    "    # 详见 https://docs.scipy.org/doc/numpy/reference/generated/numpy.bincount.html\n",
    "    return np.bincount(n * label[k].astype(int) + predict[k], minlength=n ** 2).reshape(n, n)\n",
    "\n",
    "\n",
    "def auc(y, p, classes):\n",
    "    \"\"\"\n",
    "    给定真实标签和预测标签，计算每个类别的auc值。实际只算出了roc曲线上一个点，即一个(fpr, tpr)，再并上(0, 0)和(1, 1)来计算auc\n",
    "    :param y: 标签，np.array类型\n",
    "    :param p: 预测标签，np.array类型\n",
    "    :param classes: 类别，list-like，表示有哪些类别\n",
    "    \"\"\"\n",
    "    p = p.cpu()\n",
    "    all_aucs = np.zeros(len(classes))\n",
    "    for i, c in enumerate(classes):\n",
    "        _y = np.zeros_like(y)\n",
    "        _y[y==c] = 1\n",
    "        _y[y!=c] = 0\n",
    "        _p = np.zeros_like(p)\n",
    "        _p[p==c] = 1\n",
    "        _p[p!=c] = 0\n",
    "#         print(_y, _p)\n",
    "        cm = confusion_matrix(_y, _p, 2)\n",
    "#         print(cm)\n",
    "        tpr = (cm[0, 0] / (cm[0, 0] + cm[0, 1])) if (cm[0, 0] + cm[0, 1]) != 0 else 0\n",
    "        fpr = (cm[1, 0] / (cm[1, 0] + cm[1, 1])) if (cm[1, 0] + cm[1, 1]) != 0 else 0\n",
    "        tpr = [0, tpr, 1]\n",
    "        fpr = [0, fpr, 1]\n",
    "        auc = metrics.auc(fpr, tpr)\n",
    "        all_aucs[i] = auc\n",
    "        if _y.sum() == 0 or _p.sum() == 0:\n",
    "            all_aucs[i] = 0\n",
    "    return all_aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-44a54370d78b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mall_aucs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mweighted_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mall_aucs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-47507055a435>\u001b[0m in \u001b[0;36mauc\u001b[0;34m(y, p, classes)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m类别\u001b[0m\u001b[0;31m，\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;31m，\u001b[0m\u001b[0m表示有哪些类别\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \"\"\"\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mall_aucs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "y = np.random.randint(0, 10, 100)\n",
    "p = np.random.randint(0, 10, 100)\n",
    "\n",
    "classes = list(range(10))\n",
    "weights = np.arange(0, 1, 0.1)\n",
    "all_aucs = auc(y, p, classes)\n",
    "\n",
    "weighted_auc = (all_aucs * weights).sum()\n",
    "print(f\"{all_aucs}\\n{weighted_auc}\")\n",
    "\n",
    "classes = list(range(2))\n",
    "y = np.array([0, 0, 1, 1])\n",
    "p = np.array([0, 1, 0, 1])\n",
    "all_aucs = auc(y, p, classes)\n",
    "\n",
    "print(f\"{all_aucs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理训练数据\n",
    "可在此做一些预处理：\n",
    "- 从用户历史行为数据中筛掉在视频特征中没出现过的video_id\n",
    "- 删除多余的列\n",
    "- 调整列的顺序\n",
    "- 改变列的数据类型\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 加载训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Mem. usage decreased to 1928.41 Mb (65.5% reduction),time spend:0.44 min\n"
     ]
    }
   ],
   "source": [
    "df_train = reduce_mem(dt.fread(\"../完整版df_train.jay\").to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train['is_watch'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7353024 entries, 0 to 7353023\n",
      "Columns: 130 entries, watch_label to da_4\n",
      "dtypes: float16(97), float32(6), int16(6), int32(1), int8(20)\n",
      "memory usage: 1.8 GB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除 video_name、is_watch、video_id、user_id 列\n",
    "df_train.drop(['video_name','is_watch','date', 'user_id', 'video_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['watch_label', 'is_share', 'is_work_day', 'u_avg_watch_label_1',\n",
       "       'u_sum_watch_times_1', 'u_sum_watch_overs_1', 'u_sum_quit_times_1',\n",
       "       'u_sum_skip_times_1', 'u_sum_comment_times_1', 'u_sum_collect_times_1',\n",
       "       ...\n",
       "       'class_5', 'class_6', 'class_7', 'class_8', 'class_9', 'da_0', 'da_1',\n",
       "       'da_2', 'da_3', 'da_4'],\n",
       "      dtype='object', length=130)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7353024, 130)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df_train\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7353024,), (7353024,), (7353024, 128))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 准备数据\n",
    "watch_label = dataset.pop('watch_label').astype(np.uint8)\n",
    "is_share = dataset.pop('is_share').astype(np.uint8)\n",
    "watch_label.shape, is_share.shape, dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_work_day</th>\n",
       "      <th>u_avg_watch_label_1</th>\n",
       "      <th>u_sum_watch_times_1</th>\n",
       "      <th>u_sum_watch_overs_1</th>\n",
       "      <th>u_sum_quit_times_1</th>\n",
       "      <th>u_sum_skip_times_1</th>\n",
       "      <th>u_sum_comment_times_1</th>\n",
       "      <th>u_sum_collect_times_1</th>\n",
       "      <th>u_sum_share_times_1</th>\n",
       "      <th>u_sum_watch_time_1</th>\n",
       "      <th>...</th>\n",
       "      <th>class_5</th>\n",
       "      <th>class_6</th>\n",
       "      <th>class_7</th>\n",
       "      <th>class_8</th>\n",
       "      <th>class_9</th>\n",
       "      <th>da_0</th>\n",
       "      <th>da_1</th>\n",
       "      <th>da_2</th>\n",
       "      <th>da_3</th>\n",
       "      <th>da_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034393</td>\n",
       "      <td>0.034393</td>\n",
       "      <td>0.034393</td>\n",
       "      <td>0.233032</td>\n",
       "      <td>0.213745</td>\n",
       "      <td>0.174927</td>\n",
       "      <td>0.068787</td>\n",
       "      <td>0.248169</td>\n",
       "      <td>0.439453</td>\n",
       "      <td>0.068787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041534</td>\n",
       "      <td>0.041534</td>\n",
       "      <td>0.041534</td>\n",
       "      <td>0.625977</td>\n",
       "      <td>0.041534</td>\n",
       "      <td>0.346680</td>\n",
       "      <td>0.083069</td>\n",
       "      <td>0.083069</td>\n",
       "      <td>0.404053</td>\n",
       "      <td>0.083069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038147</td>\n",
       "      <td>0.038147</td>\n",
       "      <td>0.038147</td>\n",
       "      <td>0.038147</td>\n",
       "      <td>0.038147</td>\n",
       "      <td>0.076355</td>\n",
       "      <td>0.076355</td>\n",
       "      <td>0.694336</td>\n",
       "      <td>0.076416</td>\n",
       "      <td>0.076294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043579</td>\n",
       "      <td>0.043579</td>\n",
       "      <td>0.043579</td>\n",
       "      <td>0.043579</td>\n",
       "      <td>0.043579</td>\n",
       "      <td>0.087341</td>\n",
       "      <td>0.087341</td>\n",
       "      <td>0.650879</td>\n",
       "      <td>0.087341</td>\n",
       "      <td>0.087158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041779</td>\n",
       "      <td>0.350098</td>\n",
       "      <td>0.041779</td>\n",
       "      <td>0.041779</td>\n",
       "      <td>0.041779</td>\n",
       "      <td>0.324951</td>\n",
       "      <td>0.083557</td>\n",
       "      <td>0.083557</td>\n",
       "      <td>0.083557</td>\n",
       "      <td>0.424316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_work_day  u_avg_watch_label_1  u_sum_watch_times_1  u_sum_watch_overs_1  \\\n",
       "0            1                  0.0                    0                    0   \n",
       "1            1                  0.0                    0                    0   \n",
       "2            1                  0.0                    0                    0   \n",
       "3            1                  0.0                    0                    0   \n",
       "4            1                  0.0                    0                    0   \n",
       "\n",
       "   u_sum_quit_times_1  u_sum_skip_times_1  u_sum_comment_times_1  \\\n",
       "0                   0                   0                      0   \n",
       "1                   0                   0                      0   \n",
       "2                   0                   0                      0   \n",
       "3                   0                   0                      0   \n",
       "4                   0                   0                      0   \n",
       "\n",
       "   u_sum_collect_times_1  u_sum_share_times_1  u_sum_watch_time_1  ...  \\\n",
       "0                      0                    0                 0.0  ...   \n",
       "1                      0                    0                 0.0  ...   \n",
       "2                      0                    0                 0.0  ...   \n",
       "3                      0                    0                 0.0  ...   \n",
       "4                      0                    0                 0.0  ...   \n",
       "\n",
       "    class_5   class_6   class_7   class_8   class_9      da_0      da_1  \\\n",
       "0  0.034393  0.034393  0.034393  0.233032  0.213745  0.174927  0.068787   \n",
       "1  0.041534  0.041534  0.041534  0.625977  0.041534  0.346680  0.083069   \n",
       "2  0.038147  0.038147  0.038147  0.038147  0.038147  0.076355  0.076355   \n",
       "3  0.043579  0.043579  0.043579  0.043579  0.043579  0.087341  0.087341   \n",
       "4  0.041779  0.350098  0.041779  0.041779  0.041779  0.324951  0.083557   \n",
       "\n",
       "       da_2      da_3      da_4  \n",
       "0  0.248169  0.439453  0.068787  \n",
       "1  0.083069  0.404053  0.083069  \n",
       "2  0.694336  0.076416  0.076294  \n",
       "3  0.650879  0.087341  0.087158  \n",
       "4  0.083557  0.083557  0.424316  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理测试数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 加载测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Mem. usage decreased to 820.89 Mb (65.7% reduction),time spend:0.20 min\n"
     ]
    }
   ],
   "source": [
    "# 拼接好的测试数据集\n",
    "df_test = reduce_mem(dt.fread(\"../完整版df_test.jay\").to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2822180 entries, 0 to 2822179\n",
      "Columns: 132 entries, user_id to da_4\n",
      "dtypes: float16(120), float32(3), int32(3), int8(1), object(5)\n",
      "memory usage: 820.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除 video_name 列\n",
    "if 'video_name' in df_test.columns:\n",
    "    df_test.drop('video_name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除 video_id、user_id 列\n",
    "df_test.drop(['user_id', 'video_id','date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_work_day</th>\n",
       "      <th>u_avg_watch_label_1</th>\n",
       "      <th>u_sum_watch_times_1</th>\n",
       "      <th>u_sum_watch_overs_1</th>\n",
       "      <th>u_sum_quit_times_1</th>\n",
       "      <th>u_sum_skip_times_1</th>\n",
       "      <th>u_sum_comment_times_1</th>\n",
       "      <th>u_sum_collect_times_1</th>\n",
       "      <th>u_sum_share_times_1</th>\n",
       "      <th>u_sum_watch_time_1</th>\n",
       "      <th>...</th>\n",
       "      <th>class_5</th>\n",
       "      <th>class_6</th>\n",
       "      <th>class_7</th>\n",
       "      <th>class_8</th>\n",
       "      <th>class_9</th>\n",
       "      <th>da_0</th>\n",
       "      <th>da_1</th>\n",
       "      <th>da_2</th>\n",
       "      <th>da_3</th>\n",
       "      <th>da_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044250</td>\n",
       "      <td>0.044250</td>\n",
       "      <td>0.601562</td>\n",
       "      <td>0.044250</td>\n",
       "      <td>0.044250</td>\n",
       "      <td>0.089783</td>\n",
       "      <td>0.089844</td>\n",
       "      <td>0.220947</td>\n",
       "      <td>0.089905</td>\n",
       "      <td>0.509766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037079</td>\n",
       "      <td>0.037079</td>\n",
       "      <td>0.037079</td>\n",
       "      <td>0.037079</td>\n",
       "      <td>0.037079</td>\n",
       "      <td>0.224243</td>\n",
       "      <td>0.074158</td>\n",
       "      <td>0.553223</td>\n",
       "      <td>0.074158</td>\n",
       "      <td>0.074158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041443</td>\n",
       "      <td>0.345947</td>\n",
       "      <td>0.041443</td>\n",
       "      <td>0.041443</td>\n",
       "      <td>0.041443</td>\n",
       "      <td>0.084351</td>\n",
       "      <td>0.362305</td>\n",
       "      <td>0.082886</td>\n",
       "      <td>0.387451</td>\n",
       "      <td>0.082886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304199</td>\n",
       "      <td>0.037476</td>\n",
       "      <td>0.037476</td>\n",
       "      <td>0.395996</td>\n",
       "      <td>0.037476</td>\n",
       "      <td>0.075867</td>\n",
       "      <td>0.075989</td>\n",
       "      <td>0.388672</td>\n",
       "      <td>0.383789</td>\n",
       "      <td>0.075684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.622559</td>\n",
       "      <td>0.041931</td>\n",
       "      <td>0.041931</td>\n",
       "      <td>0.041931</td>\n",
       "      <td>0.041931</td>\n",
       "      <td>0.084717</td>\n",
       "      <td>0.084839</td>\n",
       "      <td>0.662109</td>\n",
       "      <td>0.084106</td>\n",
       "      <td>0.084473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_work_day  u_avg_watch_label_1  u_sum_watch_times_1  u_sum_watch_overs_1  \\\n",
       "0            0                  NaN                  NaN                  NaN   \n",
       "1            0                  NaN                  NaN                  NaN   \n",
       "2            0                  0.0                  0.0                  0.0   \n",
       "3            0                  NaN                  NaN                  NaN   \n",
       "4            0                  NaN                  NaN                  NaN   \n",
       "\n",
       "   u_sum_quit_times_1 u_sum_skip_times_1  u_sum_comment_times_1  \\\n",
       "0                 NaN                NaN                    NaN   \n",
       "1                 NaN                NaN                    NaN   \n",
       "2                 0.0              False                    0.0   \n",
       "3                 NaN                NaN                    NaN   \n",
       "4                 NaN                NaN                    NaN   \n",
       "\n",
       "   u_sum_collect_times_1  u_sum_share_times_1  u_sum_watch_time_1  ...  \\\n",
       "0                    NaN                  NaN                 NaN  ...   \n",
       "1                    NaN                  NaN                 NaN  ...   \n",
       "2                    0.0                  0.0                 0.0  ...   \n",
       "3                    NaN                  NaN                 NaN  ...   \n",
       "4                    NaN                  NaN                 NaN  ...   \n",
       "\n",
       "    class_5   class_6   class_7   class_8   class_9      da_0      da_1  \\\n",
       "0  0.044250  0.044250  0.601562  0.044250  0.044250  0.089783  0.089844   \n",
       "1  0.037079  0.037079  0.037079  0.037079  0.037079  0.224243  0.074158   \n",
       "2  0.041443  0.345947  0.041443  0.041443  0.041443  0.084351  0.362305   \n",
       "3  0.304199  0.037476  0.037476  0.395996  0.037476  0.075867  0.075989   \n",
       "4  0.622559  0.041931  0.041931  0.041931  0.041931  0.084717  0.084839   \n",
       "\n",
       "       da_2      da_3      da_4  \n",
       "0  0.220947  0.089905  0.509766  \n",
       "1  0.553223  0.074158  0.074158  \n",
       "2  0.082886  0.387451  0.082886  \n",
       "3  0.388672  0.383789  0.075684  \n",
       "4  0.662109  0.084106  0.084473  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填充缺失值\n",
    "df_test.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看train和test维度是否相同\n",
    "df_train.shape[1] == df_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 样本均衡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[      0 5176743]\n",
      " [      1  557421]\n",
      " [      2  314107]\n",
      " [      3  219188]\n",
      " [      4  172404]\n",
      " [      5  143001]\n",
      " [      6  125092]\n",
      " [      7  117749]\n",
      " [      8  138798]\n",
      " [      9  388521]]\n",
      "[[0.         0.70402912]\n",
      " [1.         0.0758084 ]\n",
      " [2.         0.04271807]\n",
      " [3.         0.02980923]\n",
      " [4.         0.02344668]\n",
      " [5.         0.01944792]\n",
      " [6.         0.01701232]\n",
      " [7.         0.01601368]\n",
      " [8.         0.01887632]\n",
      " [9.         0.05283826]]\n"
     ]
    }
   ],
   "source": [
    "items = list(Counter(watch_label).items())\n",
    "items.sort(key=lambda x: x[0])\n",
    "print(np.array(items))\n",
    "\n",
    "dist = np.array(items, dtype=np.float)\n",
    "dist[:, 1] = dist[:, 1] / watch_label.shape[0]\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_ss = np.array(items)\n",
    "under_ss_thresh = under_ss[3, 1]  # 设置每个类别样本数目的上限 [219188], 超过上限按上限计算\n",
    "under_ss[:, 1] = np.clip(under_ss[:, 1], a_min=None, a_max=under_ss_thresh)\n",
    "\n",
    "over_ss = under_ss.copy() \n",
    "over_ss_thresh = under_ss[2, 1]  # 设置每个类别样本数据的下限，此时under_ss为 219188, 低于下限按下限计算。\n",
    "over_ss[:, 1] = np.clip(over_ss[:, 1], a_min=over_ss_thresh, a_max=None)\n",
    "\n",
    "under_ss = dict(under_ss)\n",
    "over_ss = dict(over_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 219188,\n",
       "  1: 219188,\n",
       "  2: 219188,\n",
       "  3: 219188,\n",
       "  4: 172404,\n",
       "  5: 143001,\n",
       "  6: 125092,\n",
       "  7: 117749,\n",
       "  8: 138798,\n",
       "  9: 219188},\n",
       " {0: 219188,\n",
       "  1: 219188,\n",
       "  2: 219188,\n",
       "  3: 219188,\n",
       "  4: 219188,\n",
       "  5: 219188,\n",
       "  6: 219188,\n",
       "  7: 219188,\n",
       "  8: 219188,\n",
       "  9: 219188})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_ss, over_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5176743,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = watch_label == 0\n",
    "idxs = idxs.replace(False, np.nan).dropna().index  # 保留watch_label=0的行索引\n",
    "idxs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4957555,), (219188,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_idxs = np.random.choice(idxs, under_ss_thresh, replace=False)  # 选择一部分保留，注意replace参数，为True时会重复采样\n",
    "del_idxs = idxs.difference(left_idxs)\n",
    "del_idxs.shape, left_idxs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 7338705, 1: 14319})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(watch_label)\n",
    "Counter(is_share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2395469, 128), (2395469,), (2395469,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_data = np.delete(dataset.values, del_idxs, axis=0)\n",
    "resampled_wl = np.delete(watch_label.values, del_idxs, axis=0)\n",
    "resampled_sl = np.delete(is_share.values, del_idxs, axis=0)\n",
    "resampled_data.shape, resampled_wl.shape, resampled_sl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({9: 388521,\n",
       "         7: 117749,\n",
       "         1: 557421,\n",
       "         0: 219188,\n",
       "         4: 172404,\n",
       "         2: 314107,\n",
       "         5: 143001,\n",
       "         6: 125092,\n",
       "         3: 219188,\n",
       "         8: 138798})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(resampled_wl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2395469, 128), (2395469,), (2395469,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将采样后的数据重装回 DataFrame\n",
    "resampled_dataset = pd.DataFrame(resampled_data, columns=dataset.columns)\n",
    "watch_label_res = pd.Series(resampled_wl)\n",
    "share_label_res = pd.Series(resampled_sl)\n",
    "resampled_dataset.shape, watch_label_res.shape, share_label_res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Li6LLUtnpxiD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7353024, 128)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7353024,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watch_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7353024,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_share.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(y, num_classes=None, dtype='float32'):\n",
    "    \"\"\"\n",
    "    From keras sorucecode: https://github.com/keras-team/keras/blob/master/keras/utils/np_utils.py#L9\n",
    "    \"\"\"\n",
    "\n",
    "    y = np.array(y, dtype='int')\n",
    "    input_shape = y.shape\n",
    "    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n",
    "        input_shape = tuple(input_shape[:-1])\n",
    "    y = y.ravel()\n",
    "    if not num_classes:\n",
    "        num_classes = np.max(y) + 1\n",
    "    n = y.shape[0]\n",
    "    categorical = np.zeros((n, num_classes), dtype=dtype)\n",
    "    categorical[np.arange(n), y] = 1\n",
    "    output_shape = input_shape + (num_classes,)\n",
    "    categorical = np.reshape(categorical, output_shape)\n",
    "    return categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, wt_label, sh_label, val_ratio=0.15):\n",
    "    # 将watch 转为one-hot\n",
    "    transformed_watch_label = to_categorical(wt_label, num_classes=10, dtype=int)\n",
    "    \n",
    "    # 将train划分为 train、validation. validation占20%。\n",
    "    validation_indices = dataset.sample(frac=val_ratio, replace=False, random_state=SEED).index\n",
    "    validation_data = dataset.iloc[validation_indices]\n",
    "    validation_label = [transformed_watch_label[validation_indices], sh_label[validation_indices]] #key: income, marital.\n",
    "\n",
    "    train_indices = list(set(dataset.index) - set(validation_indices))\n",
    "    train_data = dataset.iloc[train_indices]\n",
    "    train_label = [transformed_watch_label[train_indices], sh_label[train_indices]]\n",
    "    \n",
    "    return train_data, train_label, validation_data, validation_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_label, validation_data, validation_label = split_dataset(resampled_dataset, watch_label_res, share_label_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "YRThKUgIpxiG"
   },
   "outputs": [],
   "source": [
    "def getTensorDataset(my_x, my_y):\n",
    "    tensor_x = torch.tensor(my_x)\n",
    "    tensor_y = torch.tensor(my_y)\n",
    "    return torch.utils.data.TensorDataset(tensor_x, tensor_y)\n",
    "\n",
    "# 拼接两个label\n",
    "train_label_tmp = np.column_stack([train_label[0],train_label[1]])\n",
    "train_loader = DataLoader(dataset=getTensorDataset(train_data.to_numpy(), train_label_tmp), batch_size=BATCH_SIZE)\n",
    "\n",
    "validation_label_tmp = np.column_stack([validation_label[0], validation_label[1]])\n",
    "val_loader = DataLoader(dataset=getTensorDataset(validation_data.to_numpy(), validation_label_tmp), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2036149, 11)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_tmp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfA2Z8vkpxiH"
   },
   "source": [
    "## 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Oy_S9zUUpxiH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Expert(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size):\n",
    "        super(Expert, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        # self.log_soft = nn.LogSoftmax(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        # out = self.log_soft(out)\n",
    "        return out\n",
    "    \n",
    "class Tower(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size):\n",
    "        super(Tower, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        # out = self.softmax(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "C6BGy21KpxiI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MMOE(torch.nn.Module):\n",
    "    def __init__(self, input_size, num_experts, experts_out, experts_hidden, towers_hidden, tasks):\n",
    "        super(MMOE, self).__init__()\n",
    "        # params\n",
    "        self.input_size = input_size\n",
    "        self.num_experts = num_experts\n",
    "        self.experts_out = experts_out\n",
    "        self.experts_hidden = experts_hidden\n",
    "        self.towers_hidden = towers_hidden\n",
    "        self.tasks = tasks\n",
    "        # row by row\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        # model\n",
    "        self.experts = nn.ModuleList([Expert(self.input_size, self.experts_out, self.experts_hidden) for i in range(self.num_experts)])\n",
    "        self.w_gates = nn.ParameterList([nn.Parameter(torch.randn(input_size, num_experts), requires_grad=True) for i in range(self.tasks)])\n",
    "        self.towers = nn.ModuleList([Tower(self.experts_out, 1, self.towers_hidden) for i in range(self.tasks)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # get the experts output\n",
    "        expers_o = [e(x) for e in self.experts]\n",
    "        expers_o_tensor = torch.stack(expers_o)\n",
    "\n",
    "        # get the gates output\n",
    "        # x @ g 矩阵整体乘法。\n",
    "        gates_o = [self.softmax(x @ g) for g in self.w_gates]\n",
    "        \n",
    "        # multiply the output of the experts with the corresponding gates output\n",
    "        # res = gates_o[0].t().unsqueeze(2).expand(-1, -1, self.experts_out) * expers_o_tensor\n",
    "        # https://discuss.pytorch.org/t/element-wise-multiplication-of-the-last-dimension/79534\n",
    "        towers_input = [g.t().unsqueeze(2).expand(-1, -1, self.experts_out) * expers_o_tensor for g in gates_o]\n",
    "        towers_input = [torch.sum(ti, dim=0) for ti in towers_input]\n",
    "        \n",
    "        # get the final output from the towers\n",
    "        final_output = [t(ti) for t, ti in zip(self.towers, towers_input)]\n",
    "        \n",
    "        # get the output of the towers, and stack them\n",
    "        final_output = torch.stack(final_output, dim=1)\n",
    "#         print(final_output)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "ebInrBYnpxiK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MMOE(input_size=128, num_experts=16, experts_out=32, experts_hidden=32, towers_hidden=16, tasks=11)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型预览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "id": "LP7p88WoBl9U",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": true,
    "id": "5Xq4dMaq-hcJ",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  torch.Size([2, 128])\n",
      "expers_o_tensor  torch.Size([12, 2, 32])\n",
      "towers_input :  11\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                 [1024, 32]           4,128\n",
      "              ReLU-2                 [1024, 32]               0\n",
      "           Dropout-3                 [1024, 32]               0\n",
      "            Linear-4                 [1024, 32]           1,056\n",
      "            Expert-5                 [1024, 32]               0\n",
      "            Linear-6                 [1024, 32]           4,128\n",
      "              ReLU-7                 [1024, 32]               0\n",
      "           Dropout-8                 [1024, 32]               0\n",
      "            Linear-9                 [1024, 32]           1,056\n",
      "           Expert-10                 [1024, 32]               0\n",
      "           Linear-11                 [1024, 32]           4,128\n",
      "             ReLU-12                 [1024, 32]               0\n",
      "          Dropout-13                 [1024, 32]               0\n",
      "           Linear-14                 [1024, 32]           1,056\n",
      "           Expert-15                 [1024, 32]               0\n",
      "           Linear-16                 [1024, 32]           4,128\n",
      "             ReLU-17                 [1024, 32]               0\n",
      "          Dropout-18                 [1024, 32]               0\n",
      "           Linear-19                 [1024, 32]           1,056\n",
      "           Expert-20                 [1024, 32]               0\n",
      "           Linear-21                 [1024, 32]           4,128\n",
      "             ReLU-22                 [1024, 32]               0\n",
      "          Dropout-23                 [1024, 32]               0\n",
      "           Linear-24                 [1024, 32]           1,056\n",
      "           Expert-25                 [1024, 32]               0\n",
      "           Linear-26                 [1024, 32]           4,128\n",
      "             ReLU-27                 [1024, 32]               0\n",
      "          Dropout-28                 [1024, 32]               0\n",
      "           Linear-29                 [1024, 32]           1,056\n",
      "           Expert-30                 [1024, 32]               0\n",
      "           Linear-31                 [1024, 32]           4,128\n",
      "             ReLU-32                 [1024, 32]               0\n",
      "          Dropout-33                 [1024, 32]               0\n",
      "           Linear-34                 [1024, 32]           1,056\n",
      "           Expert-35                 [1024, 32]               0\n",
      "           Linear-36                 [1024, 32]           4,128\n",
      "             ReLU-37                 [1024, 32]               0\n",
      "          Dropout-38                 [1024, 32]               0\n",
      "           Linear-39                 [1024, 32]           1,056\n",
      "           Expert-40                 [1024, 32]               0\n",
      "           Linear-41                 [1024, 32]           4,128\n",
      "             ReLU-42                 [1024, 32]               0\n",
      "          Dropout-43                 [1024, 32]               0\n",
      "           Linear-44                 [1024, 32]           1,056\n",
      "           Expert-45                 [1024, 32]               0\n",
      "           Linear-46                 [1024, 32]           4,128\n",
      "             ReLU-47                 [1024, 32]               0\n",
      "          Dropout-48                 [1024, 32]               0\n",
      "           Linear-49                 [1024, 32]           1,056\n",
      "           Expert-50                 [1024, 32]               0\n",
      "           Linear-51                 [1024, 32]           4,128\n",
      "             ReLU-52                 [1024, 32]               0\n",
      "          Dropout-53                 [1024, 32]               0\n",
      "           Linear-54                 [1024, 32]           1,056\n",
      "           Expert-55                 [1024, 32]               0\n",
      "           Linear-56                 [1024, 32]           4,128\n",
      "             ReLU-57                 [1024, 32]               0\n",
      "          Dropout-58                 [1024, 32]               0\n",
      "           Linear-59                 [1024, 32]           1,056\n",
      "           Expert-60                 [1024, 32]               0\n",
      "          Softmax-61                 [1024, 12]               0\n",
      "          Softmax-62                 [1024, 12]               0\n",
      "          Softmax-63                 [1024, 12]               0\n",
      "          Softmax-64                 [1024, 12]               0\n",
      "          Softmax-65                 [1024, 12]               0\n",
      "          Softmax-66                 [1024, 12]               0\n",
      "          Softmax-67                 [1024, 12]               0\n",
      "          Softmax-68                 [1024, 12]               0\n",
      "          Softmax-69                 [1024, 12]               0\n",
      "          Softmax-70                 [1024, 12]               0\n",
      "          Softmax-71                 [1024, 12]               0\n",
      "           Linear-72                  [1024, 8]             264\n",
      "             ReLU-73                  [1024, 8]               0\n",
      "          Dropout-74                  [1024, 8]               0\n",
      "           Linear-75                  [1024, 1]               9\n",
      "          Sigmoid-76                  [1024, 1]               0\n",
      "            Tower-77                  [1024, 1]               0\n",
      "           Linear-78                  [1024, 8]             264\n",
      "             ReLU-79                  [1024, 8]               0\n",
      "          Dropout-80                  [1024, 8]               0\n",
      "           Linear-81                  [1024, 1]               9\n",
      "          Sigmoid-82                  [1024, 1]               0\n",
      "            Tower-83                  [1024, 1]               0\n",
      "           Linear-84                  [1024, 8]             264\n",
      "             ReLU-85                  [1024, 8]               0\n",
      "          Dropout-86                  [1024, 8]               0\n",
      "           Linear-87                  [1024, 1]               9\n",
      "          Sigmoid-88                  [1024, 1]               0\n",
      "            Tower-89                  [1024, 1]               0\n",
      "           Linear-90                  [1024, 8]             264\n",
      "             ReLU-91                  [1024, 8]               0\n",
      "          Dropout-92                  [1024, 8]               0\n",
      "           Linear-93                  [1024, 1]               9\n",
      "          Sigmoid-94                  [1024, 1]               0\n",
      "            Tower-95                  [1024, 1]               0\n",
      "           Linear-96                  [1024, 8]             264\n",
      "             ReLU-97                  [1024, 8]               0\n",
      "          Dropout-98                  [1024, 8]               0\n",
      "           Linear-99                  [1024, 1]               9\n",
      "         Sigmoid-100                  [1024, 1]               0\n",
      "           Tower-101                  [1024, 1]               0\n",
      "          Linear-102                  [1024, 8]             264\n",
      "            ReLU-103                  [1024, 8]               0\n",
      "         Dropout-104                  [1024, 8]               0\n",
      "          Linear-105                  [1024, 1]               9\n",
      "         Sigmoid-106                  [1024, 1]               0\n",
      "           Tower-107                  [1024, 1]               0\n",
      "          Linear-108                  [1024, 8]             264\n",
      "            ReLU-109                  [1024, 8]               0\n",
      "         Dropout-110                  [1024, 8]               0\n",
      "          Linear-111                  [1024, 1]               9\n",
      "         Sigmoid-112                  [1024, 1]               0\n",
      "           Tower-113                  [1024, 1]               0\n",
      "          Linear-114                  [1024, 8]             264\n",
      "            ReLU-115                  [1024, 8]               0\n",
      "         Dropout-116                  [1024, 8]               0\n",
      "          Linear-117                  [1024, 1]               9\n",
      "         Sigmoid-118                  [1024, 1]               0\n",
      "           Tower-119                  [1024, 1]               0\n",
      "          Linear-120                  [1024, 8]             264\n",
      "            ReLU-121                  [1024, 8]               0\n",
      "         Dropout-122                  [1024, 8]               0\n",
      "          Linear-123                  [1024, 1]               9\n",
      "         Sigmoid-124                  [1024, 1]               0\n",
      "           Tower-125                  [1024, 1]               0\n",
      "          Linear-126                  [1024, 8]             264\n",
      "            ReLU-127                  [1024, 8]               0\n",
      "         Dropout-128                  [1024, 8]               0\n",
      "          Linear-129                  [1024, 1]               9\n",
      "         Sigmoid-130                  [1024, 1]               0\n",
      "           Tower-131                  [1024, 1]               0\n",
      "          Linear-132                  [1024, 8]             264\n",
      "            ReLU-133                  [1024, 8]               0\n",
      "         Dropout-134                  [1024, 8]               0\n",
      "          Linear-135                  [1024, 1]               9\n",
      "         Sigmoid-136                  [1024, 1]               0\n",
      "           Tower-137                  [1024, 1]               0\n",
      "================================================================\n",
      "Total params: 65,211\n",
      "Trainable params: 65,211\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.50\n",
      "Forward/backward pass size (MB): 18.35\n",
      "Params size (MB): 0.25\n",
      "Estimated Total Size (MB): 19.10\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=[(128,)], batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_input = torch.Tensor(2,128).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model(simple_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "id": "lt5pS6hZGxix",
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.onnx.export(model, simple_input,'MMoE-DouLoss.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-bMI0qepxiK"
   },
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            上次验证集损失值改善后等待几个epoch\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "                            如果是True，为每个验证集损失值改善打印一条信息\n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            监测数量的最小变化，以符合改进的要求\n",
    "                            Default: 0\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''\n",
    "        Saves model when validation loss decrease.\n",
    "        验证损失减少时保存模型。\n",
    "        '''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        # torch.save(model.state_dict(), 'checkpoint.pt')     # 这里会存储迄今最优模型的参数\n",
    "        torch.save(model, 'finish_model.pkl')                 # 这里会存储迄今最优的模型\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "7-uiAEZRpxiK",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0/500\n",
      "[  0/500] train_loss: 28.01410 valid_loss: 16.42093\n",
      "Validation loss decreased (inf --> 16.420928).  Saving model ...\n",
      "\n",
      "Epoch: 1/500\n",
      "[  1/500] train_loss: 14.43175 valid_loss: 15.65093\n",
      "Validation loss decreased (16.420928 --> 15.650929).  Saving model ...\n",
      "\n",
      "Epoch: 2/500\n",
      "[  2/500] train_loss: 13.24382 valid_loss: 14.41386\n",
      "Validation loss decreased (15.650929 --> 14.413864).  Saving model ...\n",
      "\n",
      "Epoch: 3/500\n",
      "[  3/500] train_loss: 11.69624 valid_loss: 14.36521\n",
      "Validation loss decreased (14.413864 --> 14.365207).  Saving model ...\n",
      "\n",
      "Epoch: 4/500\n",
      "[  4/500] train_loss: 11.37668 valid_loss: 14.34002\n",
      "Validation loss decreased (14.365207 --> 14.340019).  Saving model ...\n",
      "\n",
      "Epoch: 5/500\n",
      "[  5/500] train_loss: 10.39034 valid_loss: 9.22119\n",
      "Validation loss decreased (14.340019 --> 9.221190).  Saving model ...\n",
      "\n",
      "Epoch: 6/500\n",
      "[  6/500] train_loss: 8.95113 valid_loss: 9.20924\n",
      "Validation loss decreased (9.221190 --> 9.209236).  Saving model ...\n",
      "\n",
      "Epoch: 7/500\n",
      "[  7/500] train_loss: 8.14405 valid_loss: 8.31360\n",
      "Validation loss decreased (9.209236 --> 8.313596).  Saving model ...\n",
      "\n",
      "Epoch: 8/500\n",
      "[  8/500] train_loss: 7.81152 valid_loss: 8.30443\n",
      "Validation loss decreased (8.313596 --> 8.304431).  Saving model ...\n",
      "\n",
      "Epoch: 9/500\n",
      "[  9/500] train_loss: 7.67323 valid_loss: 8.29914\n",
      "Validation loss decreased (8.304431 --> 8.299137).  Saving model ...\n",
      "\n",
      "Epoch: 10/500\n",
      "[ 10/500] train_loss: 7.40512 valid_loss: 7.89481\n",
      "Validation loss decreased (8.299137 --> 7.894809).  Saving model ...\n",
      "\n",
      "Epoch: 11/500\n",
      "[ 11/500] train_loss: 7.15372 valid_loss: 7.89437\n",
      "Validation loss decreased (7.894809 --> 7.894373).  Saving model ...\n",
      "\n",
      "Epoch: 12/500\n",
      "[ 12/500] train_loss: 6.97266 valid_loss: 7.88732\n",
      "Validation loss decreased (7.894373 --> 7.887315).  Saving model ...\n",
      "\n",
      "Epoch: 13/500\n",
      "[ 13/500] train_loss: 6.91495 valid_loss: 7.88388\n",
      "Validation loss decreased (7.887315 --> 7.883882).  Saving model ...\n",
      "\n",
      "Epoch: 14/500\n",
      "[ 14/500] train_loss: 6.65492 valid_loss: 7.47517\n",
      "Validation loss decreased (7.883882 --> 7.475168).  Saving model ...\n",
      "\n",
      "Epoch: 15/500\n",
      "[ 15/500] train_loss: 6.19583 valid_loss: 6.39750\n",
      "Validation loss decreased (7.475168 --> 6.397495).  Saving model ...\n",
      "\n",
      "Epoch: 16/500\n",
      "[ 16/500] train_loss: 5.97806 valid_loss: 6.39620\n",
      "Validation loss decreased (6.397495 --> 6.396197).  Saving model ...\n",
      "\n",
      "Epoch: 17/500\n",
      "[ 17/500] train_loss: 5.93062 valid_loss: 6.39358\n",
      "Validation loss decreased (6.396197 --> 6.393582).  Saving model ...\n",
      "\n",
      "Epoch: 18/500\n",
      "[ 18/500] train_loss: 5.87412 valid_loss: 6.44748\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 19/500\n",
      "[ 19/500] train_loss: 5.85090 valid_loss: 6.39422\n",
      "EarlyStopping counter: 2 out of 20\n",
      "\n",
      "Epoch: 20/500\n",
      "[ 20/500] train_loss: 5.83767 valid_loss: 6.39198\n",
      "Validation loss decreased (6.393582 --> 6.391981).  Saving model ...\n",
      "\n",
      "Epoch: 21/500\n",
      "[ 21/500] train_loss: 5.81730 valid_loss: 6.38709\n",
      "Validation loss decreased (6.391981 --> 6.387089).  Saving model ...\n",
      "\n",
      "Epoch: 22/500\n",
      "[ 22/500] train_loss: 5.86615 valid_loss: 6.38870\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 23/500\n",
      "[ 23/500] train_loss: 5.75941 valid_loss: 6.39705\n",
      "EarlyStopping counter: 2 out of 20\n",
      "\n",
      "Epoch: 24/500\n",
      "[ 24/500] train_loss: 5.73141 valid_loss: 6.38805\n",
      "EarlyStopping counter: 3 out of 20\n",
      "\n",
      "Epoch: 25/500\n",
      "[ 25/500] train_loss: 5.71063 valid_loss: 6.38690\n",
      "Validation loss decreased (6.387089 --> 6.386898).  Saving model ...\n",
      "\n",
      "Epoch: 26/500\n",
      "[ 26/500] train_loss: 5.71622 valid_loss: 6.38740\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 27/500\n",
      "[ 27/500] train_loss: 5.68049 valid_loss: 6.38856\n",
      "EarlyStopping counter: 2 out of 20\n",
      "\n",
      "Epoch: 28/500\n",
      "[ 28/500] train_loss: 5.69778 valid_loss: 6.39076\n",
      "EarlyStopping counter: 3 out of 20\n",
      "\n",
      "Epoch: 29/500\n",
      "[ 29/500] train_loss: 5.69326 valid_loss: 6.38682\n",
      "Validation loss decreased (6.386898 --> 6.386818).  Saving model ...\n",
      "\n",
      "Epoch: 30/500\n",
      "[ 30/500] train_loss: 5.69624 valid_loss: 6.38470\n",
      "Validation loss decreased (6.386818 --> 6.384703).  Saving model ...\n",
      "\n",
      "Epoch: 31/500\n",
      "[ 31/500] train_loss: 5.69166 valid_loss: 6.38374\n",
      "Validation loss decreased (6.384703 --> 6.383740).  Saving model ...\n",
      "\n",
      "Epoch: 32/500\n",
      "[ 32/500] train_loss: 5.64367 valid_loss: 6.38520\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 33/500\n",
      "[ 33/500] train_loss: 5.61960 valid_loss: 6.38216\n",
      "Validation loss decreased (6.383740 --> 6.382162).  Saving model ...\n",
      "\n",
      "Epoch: 34/500\n",
      "[ 34/500] train_loss: 5.62669 valid_loss: 6.38171\n",
      "Validation loss decreased (6.382162 --> 6.381707).  Saving model ...\n",
      "\n",
      "Epoch: 35/500\n",
      "[ 35/500] train_loss: 5.60920 valid_loss: 6.38040\n",
      "Validation loss decreased (6.381707 --> 6.380404).  Saving model ...\n",
      "\n",
      "Epoch: 36/500\n",
      "[ 36/500] train_loss: 5.61842 valid_loss: 6.38091\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 37/500\n",
      "[ 37/500] train_loss: 5.60857 valid_loss: 6.38245\n",
      "EarlyStopping counter: 2 out of 20\n",
      "\n",
      "Epoch: 38/500\n",
      "[ 38/500] train_loss: 5.52345 valid_loss: 6.38260\n",
      "EarlyStopping counter: 3 out of 20\n",
      "\n",
      "Epoch: 39/500\n",
      "[ 39/500] train_loss: 5.36028 valid_loss: 6.04471\n",
      "Validation loss decreased (6.380404 --> 6.044711).  Saving model ...\n",
      "\n",
      "Epoch: 40/500\n",
      "[ 40/500] train_loss: 5.31218 valid_loss: 6.07463\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 41/500\n",
      "[ 41/500] train_loss: 5.21570 valid_loss: 6.04258\n",
      "Validation loss decreased (6.044711 --> 6.042579).  Saving model ...\n",
      "\n",
      "Epoch: 42/500\n",
      "[ 42/500] train_loss: 5.58973 valid_loss: 6.03906\n",
      "Validation loss decreased (6.042579 --> 6.039064).  Saving model ...\n",
      "\n",
      "Epoch: 43/500\n",
      "[ 43/500] train_loss: 5.53634 valid_loss: 6.16695\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 44/500\n",
      "[ 44/500] train_loss: 5.45979 valid_loss: 6.18081\n",
      "EarlyStopping counter: 2 out of 20\n",
      "\n",
      "Epoch: 45/500\n",
      "[ 45/500] train_loss: 5.42790 valid_loss: 5.86893\n",
      "Validation loss decreased (6.039064 --> 5.868927).  Saving model ...\n",
      "\n",
      "Epoch: 46/500\n",
      "[ 46/500] train_loss: 5.23733 valid_loss: 5.82222\n",
      "Validation loss decreased (5.868927 --> 5.822221).  Saving model ...\n",
      "\n",
      "Epoch: 47/500\n",
      "[ 47/500] train_loss: 4.72612 valid_loss: 5.20082\n",
      "Validation loss decreased (5.822221 --> 5.200824).  Saving model ...\n",
      "\n",
      "Epoch: 48/500\n",
      "[ 48/500] train_loss: 4.64000 valid_loss: 5.20012\n",
      "Validation loss decreased (5.200824 --> 5.200123).  Saving model ...\n",
      "\n",
      "Epoch: 49/500\n",
      "[ 49/500] train_loss: 4.62595 valid_loss: 5.20524\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 50/500\n",
      "[ 50/500] train_loss: 4.62721 valid_loss: 5.23636\n",
      "EarlyStopping counter: 2 out of 20\n",
      "\n",
      "Epoch: 51/500\n",
      "[ 51/500] train_loss: 4.60319 valid_loss: 5.26422\n",
      "EarlyStopping counter: 3 out of 20\n",
      "\n",
      "Epoch: 52/500\n",
      "[ 52/500] train_loss: 4.93808 valid_loss: 5.56080\n",
      "EarlyStopping counter: 4 out of 20\n",
      "\n",
      "Epoch: 53/500\n",
      "[ 53/500] train_loss: 4.77140 valid_loss: 5.20040\n",
      "EarlyStopping counter: 5 out of 20\n",
      "\n",
      "Epoch: 54/500\n",
      "[ 54/500] train_loss: 4.61525 valid_loss: 5.19885\n",
      "Validation loss decreased (5.200123 --> 5.198850).  Saving model ...\n",
      "\n",
      "Epoch: 55/500\n",
      "[ 55/500] train_loss: 4.58795 valid_loss: 5.20038\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 56/500\n",
      "[ 56/500] train_loss: 4.47699 valid_loss: 5.19646\n",
      "Validation loss decreased (5.198850 --> 5.196462).  Saving model ...\n",
      "\n",
      "Epoch: 57/500\n",
      "[ 57/500] train_loss: 4.40657 valid_loss: 5.19764\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 58/500\n",
      "[ 58/500] train_loss: 4.40199 valid_loss: 5.19736\n",
      "EarlyStopping counter: 2 out of 20\n",
      "\n",
      "Epoch: 59/500\n",
      "[ 59/500] train_loss: 4.38592 valid_loss: 5.19750\n",
      "EarlyStopping counter: 3 out of 20\n",
      "\n",
      "Epoch: 60/500\n",
      "[ 60/500] train_loss: 4.38395 valid_loss: 5.19469\n",
      "Validation loss decreased (5.196462 --> 5.194694).  Saving model ...\n",
      "\n",
      "Epoch: 61/500\n",
      "[ 61/500] train_loss: 4.34347 valid_loss: 5.19702\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 62/500\n",
      "[ 62/500] train_loss: 4.16655 valid_loss: 4.59316\n",
      "Validation loss decreased (5.194694 --> 4.593165).  Saving model ...\n",
      "\n",
      "Epoch: 63/500\n",
      "[ 63/500] train_loss: 4.04243 valid_loss: 4.59425\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 64/500\n",
      "[ 64/500] train_loss: 4.02609 valid_loss: 4.59218\n",
      "Validation loss decreased (4.593165 --> 4.592180).  Saving model ...\n",
      "\n",
      "Epoch: 65/500\n",
      "[ 65/500] train_loss: 4.02325 valid_loss: 4.59432\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 66/500\n",
      "[ 66/500] train_loss: 4.02281 valid_loss: 4.59208\n",
      "Validation loss decreased (4.592180 --> 4.592085).  Saving model ...\n",
      "\n",
      "Epoch: 67/500\n",
      "[ 67/500] train_loss: 4.01419 valid_loss: 4.59257\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 68/500\n",
      "[ 68/500] train_loss: 4.01653 valid_loss: 4.59105\n",
      "Validation loss decreased (4.592085 --> 4.591054).  Saving model ...\n",
      "\n",
      "Epoch: 69/500\n",
      "[ 69/500] train_loss: 4.02010 valid_loss: 4.58953\n",
      "Validation loss decreased (4.591054 --> 4.589533).  Saving model ...\n",
      "\n",
      "Epoch: 70/500\n",
      "[ 70/500] train_loss: 4.01518 valid_loss: 4.59076\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 71/500\n",
      "[ 71/500] train_loss: 4.00141 valid_loss: 4.58967\n",
      "EarlyStopping counter: 2 out of 20\n",
      "\n",
      "Epoch: 72/500\n",
      "[ 72/500] train_loss: 4.00628 valid_loss: 4.58869\n",
      "Validation loss decreased (4.589533 --> 4.588695).  Saving model ...\n",
      "\n",
      "Epoch: 73/500\n",
      "[ 73/500] train_loss: 4.00618 valid_loss: 4.59424\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 74/500\n",
      "[ 74/500] train_loss: 4.00534 valid_loss: 4.59272\n",
      "EarlyStopping counter: 2 out of 20\n",
      "\n",
      "Epoch: 75/500\n",
      "[ 75/500] train_loss: 4.01141 valid_loss: 4.58940\n",
      "EarlyStopping counter: 3 out of 20\n",
      "\n",
      "Epoch: 76/500\n",
      "[ 76/500] train_loss: 4.02288 valid_loss: 4.58865\n",
      "Validation loss decreased (4.588695 --> 4.588650).  Saving model ...\n",
      "\n",
      "Epoch: 77/500\n",
      "[ 77/500] train_loss: 4.00886 valid_loss: 4.59017\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 78/500\n",
      "[ 78/500] train_loss: 4.01854 valid_loss: 4.59045\n",
      "EarlyStopping counter: 2 out of 20\n",
      "\n",
      "Epoch: 79/500\n",
      "[ 79/500] train_loss: 4.01040 valid_loss: 4.59035\n",
      "EarlyStopping counter: 3 out of 20\n",
      "\n",
      "Epoch: 80/500\n",
      "[ 80/500] train_loss: 4.02106 valid_loss: 4.58943\n",
      "EarlyStopping counter: 4 out of 20\n",
      "\n",
      "Epoch: 81/500\n",
      "[ 81/500] train_loss: 4.01083 valid_loss: 4.59092\n",
      "EarlyStopping counter: 5 out of 20\n",
      "\n",
      "Epoch: 82/500\n",
      "[ 82/500] train_loss: 4.02522 valid_loss: 4.58790\n",
      "Validation loss decreased (4.588650 --> 4.587897).  Saving model ...\n",
      "\n",
      "Epoch: 83/500\n",
      "[ 83/500] train_loss: 4.01079 valid_loss: 4.58860\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 84/500\n",
      "[ 84/500] train_loss: 4.02941 valid_loss: 4.58696\n",
      "Validation loss decreased (4.587897 --> 4.586965).  Saving model ...\n",
      "\n",
      "Epoch: 85/500\n",
      "[ 85/500] train_loss: 4.00740 valid_loss: 4.58835\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 86/500\n",
      "[ 86/500] train_loss: 4.01868 valid_loss: 4.58718\n",
      "EarlyStopping counter: 2 out of 20\n",
      "\n",
      "Epoch: 87/500\n",
      "[ 87/500] train_loss: 4.02015 valid_loss: 4.58940\n",
      "EarlyStopping counter: 3 out of 20\n",
      "\n",
      "Epoch: 88/500\n",
      "[ 88/500] train_loss: 4.01411 valid_loss: 4.58751\n",
      "EarlyStopping counter: 4 out of 20\n",
      "\n",
      "Epoch: 89/500\n",
      "[ 89/500] train_loss: 4.01391 valid_loss: 4.59045\n",
      "EarlyStopping counter: 5 out of 20\n",
      "\n",
      "Epoch: 90/500\n",
      "[ 90/500] train_loss: 4.02345 valid_loss: 4.58666\n",
      "Validation loss decreased (4.586965 --> 4.586661).  Saving model ...\n",
      "\n",
      "Epoch: 91/500\n",
      "[ 91/500] train_loss: 4.00547 valid_loss: 4.58951\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 92/500\n",
      "[ 92/500] train_loss: 4.01833 valid_loss: 4.58616\n",
      "Validation loss decreased (4.586661 --> 4.586162).  Saving model ...\n",
      "\n",
      "Epoch: 93/500\n",
      "[ 93/500] train_loss: 4.01506 valid_loss: 4.59777\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 94/500\n",
      "[ 94/500] train_loss: 4.00920 valid_loss: 4.58853\n",
      "EarlyStopping counter: 2 out of 20\n",
      "\n",
      "Epoch: 95/500\n",
      "[ 95/500] train_loss: 4.00676 valid_loss: 4.58641\n",
      "EarlyStopping counter: 3 out of 20\n",
      "\n",
      "Epoch: 96/500\n",
      "[ 96/500] train_loss: 4.00526 valid_loss: 4.58607\n",
      "Validation loss decreased (4.586162 --> 4.586073).  Saving model ...\n",
      "\n",
      "Epoch: 97/500\n",
      "[ 97/500] train_loss: 4.00670 valid_loss: 4.58760\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 98/500\n",
      "[ 98/500] train_loss: 4.00679 valid_loss: 4.58863\n",
      "EarlyStopping counter: 2 out of 20\n",
      "\n",
      "Epoch: 99/500\n",
      "[ 99/500] train_loss: 4.01403 valid_loss: 4.59075\n",
      "EarlyStopping counter: 3 out of 20\n",
      "\n",
      "Epoch: 100/500\n",
      "[100/500] train_loss: 4.00761 valid_loss: 4.58674\n",
      "EarlyStopping counter: 4 out of 20\n",
      "\n",
      "Epoch: 101/500\n",
      "[101/500] train_loss: 4.01325 valid_loss: 4.58718\n",
      "EarlyStopping counter: 5 out of 20\n",
      "\n",
      "Epoch: 102/500\n",
      "[102/500] train_loss: 4.00028 valid_loss: 4.59176\n",
      "EarlyStopping counter: 6 out of 20\n",
      "\n",
      "Epoch: 103/500\n",
      "[103/500] train_loss: 3.99046 valid_loss: 4.58758\n",
      "EarlyStopping counter: 7 out of 20\n",
      "\n",
      "Epoch: 104/500\n",
      "[104/500] train_loss: 3.99416 valid_loss: 4.58590\n",
      "Validation loss decreased (4.586073 --> 4.585897).  Saving model ...\n",
      "\n",
      "Epoch: 105/500\n",
      "[105/500] train_loss: 3.99038 valid_loss: 4.58682\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 106/500\n",
      "[106/500] train_loss: 3.99835 valid_loss: 4.58816\n",
      "EarlyStopping counter: 2 out of 20\n",
      "\n",
      "Epoch: 107/500\n",
      "[107/500] train_loss: 3.99844 valid_loss: 4.58530\n",
      "Validation loss decreased (4.585897 --> 4.585301).  Saving model ...\n",
      "\n",
      "Epoch: 108/500\n",
      "[108/500] train_loss: 3.99017 valid_loss: 4.58631\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 109/500\n",
      "[109/500] train_loss: 3.99929 valid_loss: 4.58628\n",
      "EarlyStopping counter: 2 out of 20\n",
      "\n",
      "Epoch: 110/500\n",
      "[110/500] train_loss: 3.98261 valid_loss: 4.58656\n",
      "EarlyStopping counter: 3 out of 20\n",
      "\n",
      "Epoch: 111/500\n",
      "[111/500] train_loss: 3.99722 valid_loss: 4.58601\n",
      "EarlyStopping counter: 4 out of 20\n",
      "\n",
      "Epoch: 112/500\n",
      "[112/500] train_loss: 3.98993 valid_loss: 4.58682\n",
      "EarlyStopping counter: 5 out of 20\n",
      "\n",
      "Epoch: 113/500\n",
      "[113/500] train_loss: 3.98786 valid_loss: 4.58583\n",
      "EarlyStopping counter: 6 out of 20\n",
      "\n",
      "Epoch: 114/500\n",
      "[114/500] train_loss: 4.00051 valid_loss: 4.58668\n",
      "EarlyStopping counter: 7 out of 20\n",
      "\n",
      "Epoch: 115/500\n",
      "[115/500] train_loss: 3.99533 valid_loss: 4.58623\n",
      "EarlyStopping counter: 8 out of 20\n",
      "\n",
      "Epoch: 116/500\n",
      "[116/500] train_loss: 4.00069 valid_loss: 4.58656\n",
      "EarlyStopping counter: 9 out of 20\n",
      "\n",
      "Epoch: 117/500\n",
      "[117/500] train_loss: 3.99887 valid_loss: 4.58579\n",
      "EarlyStopping counter: 10 out of 20\n",
      "\n",
      "Epoch: 118/500\n",
      "[118/500] train_loss: 3.99956 valid_loss: 4.58494\n",
      "Validation loss decreased (4.585301 --> 4.584940).  Saving model ...\n",
      "\n",
      "Epoch: 119/500\n",
      "[119/500] train_loss: 3.99815 valid_loss: 4.58680\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 120/500\n",
      "[120/500] train_loss: 3.99289 valid_loss: 4.58796\n",
      "EarlyStopping counter: 2 out of 20\n",
      "\n",
      "Epoch: 121/500\n",
      "[121/500] train_loss: 3.99245 valid_loss: 4.58678\n",
      "EarlyStopping counter: 3 out of 20\n",
      "\n",
      "Epoch: 122/500\n",
      "[122/500] train_loss: 3.99494 valid_loss: 4.58554\n",
      "EarlyStopping counter: 4 out of 20\n",
      "\n",
      "Epoch: 123/500\n",
      "[123/500] train_loss: 3.98513 valid_loss: 4.58663\n",
      "EarlyStopping counter: 5 out of 20\n",
      "\n",
      "Epoch: 124/500\n",
      "[124/500] train_loss: 3.98399 valid_loss: 4.58671\n",
      "EarlyStopping counter: 6 out of 20\n",
      "\n",
      "Epoch: 125/500\n",
      "[125/500] train_loss: 3.99173 valid_loss: 4.58630\n",
      "EarlyStopping counter: 7 out of 20\n",
      "\n",
      "Epoch: 126/500\n",
      "[126/500] train_loss: 3.99125 valid_loss: 4.58673\n",
      "EarlyStopping counter: 8 out of 20\n",
      "\n",
      "Epoch: 127/500\n",
      "[127/500] train_loss: 3.99230 valid_loss: 4.58688\n",
      "EarlyStopping counter: 9 out of 20\n",
      "\n",
      "Epoch: 128/500\n",
      "[128/500] train_loss: 4.01204 valid_loss: 4.58492\n",
      "Validation loss decreased (4.584940 --> 4.584916).  Saving model ...\n",
      "\n",
      "Epoch: 129/500\n",
      "[129/500] train_loss: 3.99269 valid_loss: 4.58804\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 130/500\n",
      "[130/500] train_loss: 4.01410 valid_loss: 4.59102\n",
      "EarlyStopping counter: 2 out of 20\n",
      "\n",
      "Epoch: 131/500\n",
      "[131/500] train_loss: 4.00991 valid_loss: 4.58509\n",
      "EarlyStopping counter: 3 out of 20\n",
      "\n",
      "Epoch: 132/500\n",
      "[132/500] train_loss: 3.98898 valid_loss: 4.58376\n",
      "Validation loss decreased (4.584916 --> 4.583760).  Saving model ...\n",
      "\n",
      "Epoch: 133/500\n",
      "[133/500] train_loss: 3.98634 valid_loss: 4.58469\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 134/500\n",
      "[134/500] train_loss: 3.98623 valid_loss: 4.58452\n",
      "EarlyStopping counter: 2 out of 20\n",
      "\n",
      "Epoch: 135/500\n",
      "[135/500] train_loss: 3.98604 valid_loss: 4.58537\n",
      "EarlyStopping counter: 3 out of 20\n",
      "\n",
      "Epoch: 136/500\n",
      "[136/500] train_loss: 3.99490 valid_loss: 4.58563\n",
      "EarlyStopping counter: 4 out of 20\n",
      "\n",
      "Epoch: 137/500\n",
      "[137/500] train_loss: 3.98513 valid_loss: 4.58565\n",
      "EarlyStopping counter: 5 out of 20\n",
      "\n",
      "Epoch: 138/500\n",
      "[138/500] train_loss: 3.97558 valid_loss: 4.58432\n",
      "EarlyStopping counter: 6 out of 20\n",
      "\n",
      "Epoch: 139/500\n",
      "[139/500] train_loss: 3.32372 valid_loss: 3.03866\n",
      "Validation loss decreased (4.583760 --> 3.038662).  Saving model ...\n",
      "\n",
      "Epoch: 140/500\n",
      "[140/500] train_loss: 3.05863 valid_loss: 3.03973\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 141/500\n",
      "[141/500] train_loss: 3.05728 valid_loss: 3.03809\n",
      "Validation loss decreased (3.038662 --> 3.038094).  Saving model ...\n",
      "\n",
      "Epoch: 142/500\n",
      "[142/500] train_loss: 3.05719 valid_loss: 3.03872\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 143/500\n",
      "[143/500] train_loss: 3.06063 valid_loss: 3.03854\n",
      "EarlyStopping counter: 2 out of 20\n",
      "\n",
      "Epoch: 144/500\n",
      "[144/500] train_loss: 3.05305 valid_loss: 3.03775\n",
      "Validation loss decreased (3.038094 --> 3.037752).  Saving model ...\n",
      "\n",
      "Epoch: 145/500\n",
      "[145/500] train_loss: 3.04951 valid_loss: 3.03745\n",
      "Validation loss decreased (3.037752 --> 3.037447).  Saving model ...\n",
      "\n",
      "Epoch: 146/500\n",
      "[146/500] train_loss: 3.05080 valid_loss: 3.03810\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 147/500\n",
      "[147/500] train_loss: 3.05070 valid_loss: 3.03841\n",
      "EarlyStopping counter: 2 out of 20\n",
      "\n",
      "Epoch: 148/500\n",
      "[148/500] train_loss: 3.05067 valid_loss: 3.03912\n",
      "EarlyStopping counter: 3 out of 20\n",
      "\n",
      "Epoch: 149/500\n",
      "[149/500] train_loss: 3.05225 valid_loss: 3.03893\n",
      "EarlyStopping counter: 4 out of 20\n",
      "\n",
      "Epoch: 150/500\n",
      "[150/500] train_loss: 3.05118 valid_loss: 3.03788\n",
      "EarlyStopping counter: 5 out of 20\n",
      "\n",
      "Epoch: 151/500\n",
      "[151/500] train_loss: 3.05077 valid_loss: 3.03694\n",
      "Validation loss decreased (3.037447 --> 3.036938).  Saving model ...\n",
      "\n",
      "Epoch: 152/500\n",
      "[152/500] train_loss: 3.05307 valid_loss: 3.03745\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 153/500\n",
      "[153/500] train_loss: 3.05615 valid_loss: 3.03925\n",
      "EarlyStopping counter: 2 out of 20\n",
      "\n",
      "Epoch: 154/500\n",
      "[154/500] train_loss: 3.05407 valid_loss: 3.03731\n",
      "EarlyStopping counter: 3 out of 20\n",
      "\n",
      "Epoch: 155/500\n",
      "[155/500] train_loss: 3.05441 valid_loss: 3.03756\n",
      "EarlyStopping counter: 4 out of 20\n",
      "\n",
      "Epoch: 156/500\n",
      "[156/500] train_loss: 3.05065 valid_loss: 3.03787\n",
      "EarlyStopping counter: 5 out of 20\n",
      "\n",
      "Epoch: 157/500\n",
      "[157/500] train_loss: 3.05620 valid_loss: 3.03718\n",
      "EarlyStopping counter: 6 out of 20\n",
      "\n",
      "Epoch: 158/500\n",
      "[158/500] train_loss: 3.06167 valid_loss: 3.05087\n",
      "EarlyStopping counter: 7 out of 20\n",
      "\n",
      "Epoch: 159/500\n",
      "[159/500] train_loss: 3.05356 valid_loss: 3.03656\n",
      "Validation loss decreased (3.036938 --> 3.036561).  Saving model ...\n",
      "\n",
      "Epoch: 160/500\n",
      "[160/500] train_loss: 3.04772 valid_loss: 3.03797\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 161/500\n",
      "[161/500] train_loss: 3.04751 valid_loss: 3.03695\n",
      "EarlyStopping counter: 2 out of 20\n",
      "\n",
      "Epoch: 162/500\n",
      "[162/500] train_loss: 3.04838 valid_loss: 3.03752\n",
      "EarlyStopping counter: 3 out of 20\n",
      "\n",
      "Epoch: 163/500\n",
      "[163/500] train_loss: 3.04857 valid_loss: 3.03682\n",
      "EarlyStopping counter: 4 out of 20\n",
      "\n",
      "Epoch: 164/500\n",
      "[164/500] train_loss: 3.04883 valid_loss: 3.03760\n",
      "EarlyStopping counter: 5 out of 20\n",
      "\n",
      "Epoch: 165/500\n",
      "[165/500] train_loss: 3.04739 valid_loss: 3.03657\n",
      "EarlyStopping counter: 6 out of 20\n",
      "\n",
      "Epoch: 166/500\n",
      "[166/500] train_loss: 3.04784 valid_loss: 3.03658\n",
      "EarlyStopping counter: 7 out of 20\n",
      "\n",
      "Epoch: 167/500\n",
      "[167/500] train_loss: 3.04919 valid_loss: 3.03698\n",
      "EarlyStopping counter: 8 out of 20\n",
      "\n",
      "Epoch: 168/500\n",
      "[168/500] train_loss: 3.05857 valid_loss: 3.03668\n",
      "EarlyStopping counter: 9 out of 20\n",
      "\n",
      "Epoch: 169/500\n",
      "[169/500] train_loss: 3.05253 valid_loss: 3.04314\n",
      "EarlyStopping counter: 10 out of 20\n",
      "\n",
      "Epoch: 170/500\n",
      "[170/500] train_loss: 3.04981 valid_loss: 3.03679\n",
      "EarlyStopping counter: 11 out of 20\n",
      "\n",
      "Epoch: 171/500\n",
      "[171/500] train_loss: 3.04948 valid_loss: 3.03668\n",
      "EarlyStopping counter: 12 out of 20\n",
      "\n",
      "Epoch: 172/500\n",
      "[172/500] train_loss: 3.04799 valid_loss: 3.03628\n",
      "Validation loss decreased (3.036561 --> 3.036275).  Saving model ...\n",
      "\n",
      "Epoch: 173/500\n",
      "[173/500] train_loss: 3.04722 valid_loss: 3.03600\n",
      "Validation loss decreased (3.036275 --> 3.036002).  Saving model ...\n",
      "\n",
      "Epoch: 174/500\n",
      "[174/500] train_loss: 3.04823 valid_loss: 3.03571\n",
      "Validation loss decreased (3.036002 --> 3.035709).  Saving model ...\n",
      "\n",
      "Epoch: 175/500\n",
      "[175/500] train_loss: 3.05714 valid_loss: 3.03538\n",
      "Validation loss decreased (3.035709 --> 3.035383).  Saving model ...\n",
      "\n",
      "Epoch: 176/500\n",
      "[176/500] train_loss: 3.05918 valid_loss: 3.03894\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 177/500\n",
      "[177/500] train_loss: 3.05656 valid_loss: 3.03743\n",
      "EarlyStopping counter: 2 out of 20\n",
      "\n",
      "Epoch: 178/500\n",
      "[178/500] train_loss: 3.05092 valid_loss: 3.03535\n",
      "Validation loss decreased (3.035383 --> 3.035349).  Saving model ...\n",
      "\n",
      "Epoch: 179/500\n",
      "[179/500] train_loss: 3.05187 valid_loss: 3.03633\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 180/500\n",
      "[180/500] train_loss: 3.04965 valid_loss: 3.03610\n",
      "EarlyStopping counter: 2 out of 20\n",
      "\n",
      "Epoch: 181/500\n",
      "[181/500] train_loss: 3.05879 valid_loss: 3.03679\n",
      "EarlyStopping counter: 3 out of 20\n",
      "\n",
      "Epoch: 182/500\n",
      "[182/500] train_loss: 3.04822 valid_loss: 3.03634\n",
      "EarlyStopping counter: 4 out of 20\n",
      "\n",
      "Epoch: 183/500\n",
      "[183/500] train_loss: 3.04664 valid_loss: 3.03723\n",
      "EarlyStopping counter: 5 out of 20\n",
      "\n",
      "Epoch: 184/500\n",
      "[184/500] train_loss: 3.04591 valid_loss: 3.03573\n",
      "EarlyStopping counter: 6 out of 20\n",
      "\n",
      "Epoch: 185/500\n",
      "[185/500] train_loss: 3.04701 valid_loss: 3.03570\n",
      "EarlyStopping counter: 7 out of 20\n",
      "\n",
      "Epoch: 186/500\n",
      "[186/500] train_loss: 3.04800 valid_loss: 3.04467\n",
      "EarlyStopping counter: 8 out of 20\n",
      "\n",
      "Epoch: 187/500\n",
      "[187/500] train_loss: 3.04931 valid_loss: 3.03487\n",
      "Validation loss decreased (3.035349 --> 3.034874).  Saving model ...\n",
      "\n",
      "Epoch: 188/500\n",
      "[188/500] train_loss: 3.07268 valid_loss: 3.03519\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 189/500\n",
      "[189/500] train_loss: 3.05103 valid_loss: 3.03555\n",
      "EarlyStopping counter: 2 out of 20\n",
      "\n",
      "Epoch: 190/500\n",
      "[190/500] train_loss: 3.05480 valid_loss: 3.03439\n",
      "Validation loss decreased (3.034874 --> 3.034391).  Saving model ...\n",
      "\n",
      "Epoch: 191/500\n",
      "[191/500] train_loss: 3.05335 valid_loss: 3.03480\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 192/500\n",
      "[192/500] train_loss: 3.05408 valid_loss: 3.03453\n",
      "EarlyStopping counter: 2 out of 20\n",
      "\n",
      "Epoch: 193/500\n",
      "[193/500] train_loss: 3.05190 valid_loss: 3.03546\n",
      "EarlyStopping counter: 3 out of 20\n",
      "\n",
      "Epoch: 194/500\n",
      "[194/500] train_loss: 3.05280 valid_loss: 3.03548\n",
      "EarlyStopping counter: 4 out of 20\n",
      "\n",
      "Epoch: 195/500\n",
      "[195/500] train_loss: 3.07345 valid_loss: 3.03438\n",
      "Validation loss decreased (3.034391 --> 3.034379).  Saving model ...\n",
      "\n",
      "Epoch: 196/500\n",
      "[196/500] train_loss: 3.05083 valid_loss: 3.03577\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 197/500\n",
      "[197/500] train_loss: 3.05123 valid_loss: 3.03607\n",
      "EarlyStopping counter: 2 out of 20\n",
      "\n",
      "Epoch: 198/500\n",
      "[198/500] train_loss: 3.04829 valid_loss: 3.03542\n",
      "EarlyStopping counter: 3 out of 20\n",
      "\n",
      "Epoch: 199/500\n",
      "[199/500] train_loss: 3.05008 valid_loss: 3.03474\n",
      "EarlyStopping counter: 4 out of 20\n",
      "\n",
      "Epoch: 200/500\n",
      "[200/500] train_loss: 3.05218 valid_loss: 3.03529\n",
      "EarlyStopping counter: 5 out of 20\n",
      "\n",
      "Epoch: 201/500\n",
      "[201/500] train_loss: 3.05144 valid_loss: 3.03432\n",
      "Validation loss decreased (3.034379 --> 3.034316).  Saving model ...\n",
      "\n",
      "Epoch: 202/500\n",
      "[202/500] train_loss: 3.05117 valid_loss: 3.03496\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 203/500\n",
      "[203/500] train_loss: 3.05093 valid_loss: 3.03414\n",
      "Validation loss decreased (3.034316 --> 3.034144).  Saving model ...\n",
      "\n",
      "Epoch: 204/500\n",
      "[204/500] train_loss: 3.04750 valid_loss: 3.03466\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 205/500\n",
      "[205/500] train_loss: 3.04532 valid_loss: 3.03475\n",
      "EarlyStopping counter: 2 out of 20\n",
      "\n",
      "Epoch: 206/500\n",
      "[206/500] train_loss: 3.04498 valid_loss: 3.03543\n",
      "EarlyStopping counter: 3 out of 20\n",
      "\n",
      "Epoch: 207/500\n",
      "[207/500] train_loss: 3.07256 valid_loss: 3.03553\n",
      "EarlyStopping counter: 4 out of 20\n",
      "\n",
      "Epoch: 208/500\n",
      "[208/500] train_loss: 3.04424 valid_loss: 3.03436\n",
      "EarlyStopping counter: 5 out of 20\n",
      "\n",
      "Epoch: 209/500\n",
      "[209/500] train_loss: 3.04414 valid_loss: 3.03565\n",
      "EarlyStopping counter: 6 out of 20\n",
      "\n",
      "Epoch: 210/500\n",
      "[210/500] train_loss: 3.04656 valid_loss: 3.03380\n",
      "Validation loss decreased (3.034144 --> 3.033796).  Saving model ...\n",
      "\n",
      "Epoch: 211/500\n",
      "[211/500] train_loss: 3.04381 valid_loss: 3.03465\n",
      "EarlyStopping counter: 1 out of 20\n",
      "\n",
      "Epoch: 212/500\n",
      "[212/500] train_loss: 3.04438 valid_loss: 3.03462\n",
      "EarlyStopping counter: 2 out of 20\n",
      "\n",
      "Epoch: 213/500\n",
      "[213/500] train_loss: 3.04354 valid_loss: 3.03574\n",
      "EarlyStopping counter: 3 out of 20\n",
      "\n",
      "Epoch: 214/500\n",
      "[214/500] train_loss: 3.04475 valid_loss: 3.03511\n",
      "EarlyStopping counter: 4 out of 20\n",
      "\n",
      "Epoch: 215/500\n",
      "[215/500] train_loss: 3.04596 valid_loss: 3.03520\n",
      "EarlyStopping counter: 5 out of 20\n",
      "\n",
      "Epoch: 216/500\n",
      "[216/500] train_loss: 3.04429 valid_loss: 3.03484\n",
      "EarlyStopping counter: 6 out of 20\n",
      "\n",
      "Epoch: 217/500\n",
      "[217/500] train_loss: 3.04382 valid_loss: 3.03383\n",
      "EarlyStopping counter: 7 out of 20\n",
      "\n",
      "Epoch: 218/500\n",
      "[218/500] train_loss: 3.04376 valid_loss: 3.03508\n",
      "EarlyStopping counter: 8 out of 20\n",
      "\n",
      "Epoch: 219/500\n",
      "[219/500] train_loss: 3.04934 valid_loss: 3.03481\n",
      "EarlyStopping counter: 9 out of 20\n",
      "\n",
      "Epoch: 220/500\n",
      "[220/500] train_loss: 3.04406 valid_loss: 3.03418\n",
      "EarlyStopping counter: 10 out of 20\n",
      "\n",
      "Epoch: 221/500\n",
      "[221/500] train_loss: 3.04511 valid_loss: 3.03446\n",
      "EarlyStopping counter: 11 out of 20\n",
      "\n",
      "Epoch: 222/500\n",
      "[222/500] train_loss: 3.04367 valid_loss: 3.03523\n",
      "EarlyStopping counter: 12 out of 20\n",
      "\n",
      "Epoch: 223/500\n",
      "[223/500] train_loss: 3.04352 valid_loss: 3.03420\n",
      "EarlyStopping counter: 13 out of 20\n",
      "\n",
      "Epoch: 224/500\n",
      "[224/500] train_loss: 3.04520 valid_loss: 3.03558\n",
      "EarlyStopping counter: 14 out of 20\n",
      "\n",
      "Epoch: 225/500\n",
      "[225/500] train_loss: 3.04431 valid_loss: 3.03455\n",
      "EarlyStopping counter: 15 out of 20\n",
      "\n",
      "Epoch: 226/500\n",
      "[226/500] train_loss: 3.04279 valid_loss: 3.03450\n",
      "EarlyStopping counter: 16 out of 20\n",
      "\n",
      "Epoch: 227/500\n",
      "[227/500] train_loss: 3.04485 valid_loss: 3.03514\n",
      "EarlyStopping counter: 17 out of 20\n",
      "\n",
      "Epoch: 228/500\n",
      "[228/500] train_loss: 3.04490 valid_loss: 3.03498\n",
      "EarlyStopping counter: 18 out of 20\n",
      "\n",
      "Epoch: 229/500\n",
      "[229/500] train_loss: 3.05048 valid_loss: 3.03470\n",
      "EarlyStopping counter: 19 out of 20\n",
      "\n",
      "Epoch: 230/500\n",
      "[230/500] train_loss: 3.04748 valid_loss: 3.03393\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early stopping\n",
      "loss:  4.311367514846651\n",
      "val_loss:  4.6332005438672486\n"
     ]
    }
   ],
   "source": [
    "# Sets hyper-parameters\n",
    "lr = 1e-4\n",
    "n_epochs = 500\n",
    "tasks = 11\n",
    "patience = 20\n",
    "# BATCH_SIZE=4096\n",
    "\n",
    "# # Defines loss function and optimizer\n",
    "# loss_fn_watch = nn.CrossEntropyLoss(reduction='mean')\n",
    "loss_fn = nn.BCELoss(reduction='mean')\n",
    "early_stopping = EarlyStopping(patience, verbose=True)\n",
    "# loss_fn_watch = nn.MSELoss(reduction='mean')\n",
    "# loss_fn_share = nn.BCELoss(reduction='mean')\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "watch_auc = []\n",
    "share_auc = []\n",
    "sum_auc = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    # Uses loader to fetch one mini-batch for training\n",
    "    epoch_loss = []\n",
    "#     c = 0\n",
    "    print(\"\\nEpoch: {}/{}\".format(epoch, n_epochs)) \n",
    "    for x_batch, y_batch in train_loader:\n",
    "        # NOW, sends the mini-batch data to the device\n",
    "        # so it matches location of the MODEL\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        # One stpe of training\n",
    "        yhat = model(x_batch.float())\n",
    "#         print(yhat[0].shape)\n",
    "#         print(y_batch.shape)\n",
    "        \n",
    "        # loss = loss_fn(yhat, y_batch)      \n",
    "        loss = 0\n",
    "        for i in range(tasks):\n",
    "            loss += loss_fn(yhat[:,i].float(), y_batch[:, i].view(-1, 1).float())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss.append(loss.item())\n",
    "#         if c % 50 == 0:\n",
    "#             print(\"  Batch: {}/{}\".format(c, int(len(train_data)/BATCH_SIZE)))\n",
    "#         c += 1\n",
    "    losses.append(np.mean(epoch_loss))\n",
    "        \n",
    "    # After finishing training steps for all mini-batches,\n",
    "    # it is time for evaluation!\n",
    "        \n",
    "    # We tell PyTorch to NOT use autograd...\n",
    "    with torch.no_grad():\n",
    "        # Uses loader to fetch one mini-batch for validation\n",
    "        epoch_loss = []\n",
    "        epoch_watch_auc = []\n",
    "        epoch_share_auc = []\n",
    "        epoch_sum_auc = []\n",
    "        for x_val, y_val in val_loader:\n",
    "            # Again, sends data to same device as model\n",
    "            x_val = x_val.to(device)\n",
    "            y_val = y_val.to(device)\n",
    "#             print(x_val.shape,y_val.shape )\n",
    "            \n",
    "            \n",
    "            model.eval()\n",
    "            # Makes predictions\n",
    "            yhat = model(x_val.float()) # len=11, 一组batch的预测值\n",
    "            \n",
    "            # Computes validation loss\n",
    "            loss = 0\n",
    "            for i in range(tasks):\n",
    "                loss += loss_fn(yhat[:, i].float(), y_val[:, i].view(-1, 1).float())\n",
    "            epoch_loss.append(loss.item())\n",
    "            \n",
    "            \n",
    "            # label preds [0,1,2,..]\n",
    "#             y_v = y_val.cpu() \n",
    "#             for i in range(len(y_v)):\n",
    "#                 print(\"yhat : \", yh.shape)\n",
    "#                 print(\"y_val: \", y_v.shape)\n",
    "#                 epoch_watch_auc.append(auc(y_v[i][:10], yh[:10], np.arange(10)))\n",
    "#                 epoch_share_auc.append(auc(y_v[i][-1], yh[-1][i], [0,1]))\n",
    "#                 epoch_sum_auc.append(watch_auc * 0.7 + share_auc * 0.3)\n",
    "             \n",
    "        \n",
    "#     watch_auc.append(np.mean(epoch_watch_auc))\n",
    "#     share_auc.append(np.mean(epoch_share_auc))\n",
    "#     sum_auc.append(np.mean(epoch_sum_auc))\n",
    "    val_losses.append(np.mean(epoch_loss))\n",
    "    \n",
    "    \n",
    "    \n",
    "    epoch_len = len(str(n_epochs))\n",
    "    print_msg = (f'[{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +\n",
    "                     f'train_loss: {losses[-1]:.5f} ' +\n",
    "                     f'valid_loss: {val_losses[-1]:.5f}')\n",
    "    \n",
    "    print(print_msg)\n",
    "    \n",
    "    \n",
    "    # ************* Early Stopping ****************\n",
    "    # early_stopping needs the validation loss to check if it has decresed, \n",
    "        # and if it has, it will make a checkpoint of the current model\n",
    "    early_stopping(val_losses[-1], model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "        \n",
    "# print(model.state_dict())\n",
    "print(\"loss: \", np.mean(losses))\n",
    "print(\"val_loss: \", np.mean(val_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "vmujL-9DpxiL",
    "outputId": "a99cc787-ede6-4c30-d54b-614ea34e8fd4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, len(losses)+1)\n",
    "plt.plot(epochs, losses, 'g', label='Training loss')\n",
    "plt.plot(epochs, val_losses, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将测试数据组织为 DaTaloader\n",
    "test_loader = DataLoader(dataset=torch.utils.data.TensorDataset(torch.tensor(df_test.astype(float).to_numpy())), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测\n",
    "watch_pred = []\n",
    "share_pred = []\n",
    "with torch.no_grad():\n",
    "    # Uses loader to fetch one mini-batch for testing\n",
    "    for x_test in test_loader:\n",
    "        # Again, sends data to same device as model\n",
    "        x_test = x_test[0]\n",
    "        x_test = x_test.to(device)\n",
    "\n",
    "        model.eval()\n",
    "        # Makes predictions\n",
    "        yhat = model(x_test.float())\n",
    "        yhat = yhat.squeeze(0)\n",
    "        yhat = yhat.view(-1, 11)\n",
    "        \n",
    "        yhat_watch = yhat[:, :10]\n",
    "        yhat_share = yhat[:, 10:]\n",
    "\n",
    "        # save\n",
    "        watch_pred.append(yhat_watch)\n",
    "        share_pred.append(yhat_share)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理结果，还原为真实label\n",
    "watch_preds = torch.cat(watch_pred, dim=0)\n",
    "watch_preds = torch.detach(watch_preds).cpu()\n",
    "watch_preds_label = np.argmax(watch_preds,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0685, 0.2736, 0.1459,  ..., 0.0522, 0.0521, 0.1010],\n",
      "        [0.1576, 0.1698, 0.0956,  ..., 0.0520, 0.0623, 0.1920],\n",
      "        [0.0328, 0.1698, 0.1322,  ..., 0.0567, 0.0732, 0.2122],\n",
      "        ...,\n",
      "        [0.0239, 0.1754, 0.1261,  ..., 0.0567, 0.0694, 0.1513],\n",
      "        [0.0397, 0.1846, 0.1349,  ..., 0.0567, 0.0634, 0.1537],\n",
      "        [0.0411, 0.1924, 0.1180,  ..., 0.0567, 0.0705, 0.2255]])\n",
      "torch.Size([2822180])\n"
     ]
    }
   ],
   "source": [
    "print(watch_preds)\n",
    "print(watch_preds_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(watch_preds_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1675084, 9: 885686, 0: 252545, 2: 5958, 8: 2907})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(watch_preds_label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor(0),\n",
       "indices=tensor(0))"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.max(watch_preds_label, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "share_preds = torch.cat(share_pred, dim=0)\n",
    "share_preds = torch.detach(share_preds).cpu()\n",
    "share_preds_label = np.rint(share_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "print(share_preds_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0029)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(share_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZybNEldCpxiM"
   },
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Utuc-SE2pxiM"
   },
   "outputs": [],
   "source": [
    "test_label_tmp = np.column_stack((np.argmax(test_label[0], axis=1), np.argmax(test_label[1], axis=1)))\n",
    "test_loader = DataLoader(dataset=getTensorDataset(test_data.to_numpy(), test_label_tmp), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f_Sn3evgpxiN",
    "outputId": "b13a4bcc-3547-42d0-80f1-588bf41ea6d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5134528784119353\n"
     ]
    }
   ],
   "source": [
    "t1_pred = []\n",
    "t2_pred = []\n",
    "t1_target = []\n",
    "t2_target = []\n",
    "\n",
    "# We tell PyTorch to NOT use autograd...\n",
    "with torch.no_grad():\n",
    "    # Uses loader to fetch one mini-batch for testing\n",
    "    epoch_loss = []\n",
    "    for x_test, y_test in test_loader:\n",
    "        # Again, sends data to same device as model\n",
    "        x_test = x_test.to(device)\n",
    "        y_test = y_test.to(device)\n",
    "\n",
    "        model.eval()\n",
    "        # Makes predictions\n",
    "        yhat = model(x_test)\n",
    "\n",
    "        y_test_t1, y_test_t2 = y_test[:, 0], y_test[:, 1]\n",
    "        yhat_t1, yhat_t2 = yhat[0], yhat[1]\n",
    "\n",
    "        loss_t1 = loss_fn(yhat_t1, y_test_t1.view(-1, 1))\n",
    "        loss_t2 = loss_fn(yhat_t2, y_test_t2.view(-1, 1))\n",
    "        loss = loss_t1 + loss_t2\n",
    "        \n",
    "        # predict\n",
    "        t1_hat = yhat_t1.view(-1) > 0.5\n",
    "        t2_hat = yhat_t2.view(-1) > 0.5\n",
    "        \n",
    "        # save\n",
    "        t1_pred.append(t1_hat)\n",
    "        t2_pred.append(t2_hat)\n",
    "        t1_target.append(y_test_t1)\n",
    "        t2_target.append(y_test_t2)\n",
    "        \n",
    "\n",
    "        epoch_loss.append(loss.item())\n",
    "print(np.mean(epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uiu2JFtipxiN"
   },
   "outputs": [],
   "source": [
    "t1_pred = torch.cat(t1_pred)\n",
    "t2_pred = torch.cat(t2_pred)\n",
    "t1_target = torch.cat(t1_target)\n",
    "t2_target = torch.cat(t2_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8tcrBVJopxiN",
    "outputId": "38dc4a47-7d48-4e54-beff-0150dbacc6e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46694,   103],\n",
       "       [ 2486,   598]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(t1_target.cpu().numpy(), t1_pred.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l2vsn31ZpxiO",
    "outputId": "7f402b0b-7bde-4751-d233-c5c0b859283f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.97     46797\n",
      "         1.0       0.85      0.19      0.32      3084\n",
      "\n",
      "    accuracy                           0.95     49881\n",
      "   macro avg       0.90      0.60      0.64     49881\n",
      "weighted avg       0.94      0.95      0.93     49881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(t1_target.cpu().numpy(), t1_pred.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eDmGiBUIpxiO",
    "outputId": "38cd49c0-640f-4718-b37c-6ba77e199157"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.89      0.90     28284\n",
      "         1.0       0.86      0.89      0.87     21597\n",
      "\n",
      "    accuracy                           0.89     49881\n",
      "   macro avg       0.89      0.89      0.89     49881\n",
      "weighted avg       0.89      0.89      0.89     49881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(t2_target.cpu().numpy(), t2_pred.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AgxjvpF9pxiP"
   },
   "source": [
    "### Testing example for the loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fBSvc0V6pxiP",
    "outputId": "431d5aca-bae4-4094-9dec-e7fb47389797"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5821)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.tensor([[[0.1, 0.5], [0.1, 0.5]], [[0.1, 0.5], [0.3, 0.5]], [[0.1, 0.5], [1.0, 1.0]]])\n",
    "target = torch.tensor([[0, 0], [1, 1], [1, 1]])\n",
    "output = loss(input, target)\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MMoE-DouLoss.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
