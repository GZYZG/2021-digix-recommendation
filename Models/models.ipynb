{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "import datatable as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 给定预测标签，计算AUC\n",
    "使用OVR的策略计算每个类别的AUC\n",
    "过程：\n",
    "- 选择类别i作为正类，其他类别作为负类\n",
    "- 将真实标签中不等于i的标记为0，等于i的标记为1\n",
    "- 将预测标签中不等于i的标记为0，等于ide标记为1\n",
    "- 计算混淆矩阵\n",
    "- 计算(fpr, tpr)\n",
    "- 计算AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.random.randint(0, 10, 100)\n",
    "p = np.random.randint(0, 10, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(label, predict, n):\n",
    "    \"\"\"\n",
    "    计算混淆矩阵\n",
    "    :param label: 标签，np.array类型。形状可以是(n_sample,) 或者 (n_sample, n_classes)，当为第二种形状时可以表示多标签分类的情况\n",
    "    :param predict: 预测值，与 `label` 同理\n",
    "    :param n: 类别数目\n",
    "    :return: 混淆矩阵，np.array类型。shape 为 (n, n)。$cm_{ij}$表示真实标签为 $i$，预测标签为 $j$ 的样本个数\n",
    "    \"\"\"\n",
    "    k = (label >= 0) & (label < n)\n",
    "    # bincount()函数用于统计数组内每个非负整数的个数\n",
    "    # 详见 https://docs.scipy.org/doc/numpy/reference/generated/numpy.bincount.html\n",
    "    return np.bincount(n * label[k].astype(int) + predict[k], minlength=n ** 2).reshape(n, n)\n",
    "\n",
    "\n",
    "def auc(y, p, classes):\n",
    "    \"\"\"\n",
    "    给定真实标签和预测标签，计算每个类别的auc值。实际只算出了roc曲线上一个点，即一个(fpr, tpr)，再并上(0, 0)和(1, 1)来计算auc\n",
    "    :param y: 标签，np.array类型\n",
    "    :param p: 预测标签，np.array类型\n",
    "    :param classes: 类别，list-like，表示有哪些类别\n",
    "    \"\"\"\n",
    "    all_aucs = np.zeros(len(classes))\n",
    "    for i, c in enumerate(classes):\n",
    "        _y = np.zeros_like(y)\n",
    "        _y[y==c] = 1\n",
    "        _y[y!=c] = 0\n",
    "        _p = np.zeros_like(p)\n",
    "        _p[p==c] = 1\n",
    "        _p[p!=c] = 0\n",
    "#         print(_y, _p)\n",
    "        cm = confusion_matrix(_y, _p, 2)\n",
    "#         print(cm)\n",
    "        tpr = (cm[0, 0] / (cm[0, 0] + cm[0, 1])) if (cm[0, 0] + cm[0, 1]) != 0 else 0\n",
    "        fpr = (cm[1, 0] / (cm[1, 0] + cm[1, 1])) if (cm[1, 0] + cm[1, 1]) != 0 else 0\n",
    "        tpr = [0, tpr, 1]\n",
    "        fpr = [0, fpr, 1]\n",
    "        auc = metrics.auc(fpr, tpr)\n",
    "        all_aucs[i] = auc\n",
    "        if _y.sum() == 0 or _p.sum() == 0:\n",
    "            all_aucs[i] = 0\n",
    "    return all_aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5298913  0.65555556 0.52304147 0.50747508 0.52445652 0.58219623\n",
      " 0.57264957 0.46842105 0.53379416 0.50795756]\n",
      "2.3789687141650595\n"
     ]
    }
   ],
   "source": [
    "classes = list(range(10))\n",
    "weights = np.arange(0, 1, 0.1)\n",
    "all_aucs = auc(y, p, classes)\n",
    "\n",
    "weighted_auc = (all_aucs * weights).sum()\n",
    "print(f\"{all_aucs}\\n{weighted_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "classes = list(range(2))\n",
    "y = np.array([0, 0, 1, 1])\n",
    "p = np.array([0, 1, 0, 1])\n",
    "all_aucs = auc(y, p, classes)\n",
    "\n",
    "print(f\"{all_aucs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据\n",
    "训练数据加载过程：\n",
    "1. 分别加载处理好的用户特征和视频特征，以及整合的用户历史行为数据；\n",
    "2. 从用户历史行为数据中筛掉在视频特征中没出现过的video_id；\n",
    "3. 将行为数据中的user_id、video_id替换为对应用户/视频的特征\n",
    "4. 根据不同的任务划分为`watch_label`、`is_share`的数据集\n",
    "\n",
    "推断时，类似于上述过程拼接数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datatable import join\n",
    "\n",
    "def load_npz(path):\n",
    "    npz = np.load(path, allow_pickle=True)\n",
    "    return npz\n",
    "\n",
    "\n",
    "def load_table(path, ftype=\"csv\", data_name=\"data\", column_name=\"columns\"):\n",
    "    if ftype == \"npz\":\n",
    "        npz = load_npz(path)\n",
    "        tab = pd.DataFrame(npz[data_name], columns=column_name)\n",
    "    elif ftype == \"jay\":\n",
    "        tab = dt.fread(path)\n",
    "    elif ftype == \"csv\":\n",
    "        tab = pd.read_csv(path)\n",
    "        \n",
    "    return tab\n",
    "\n",
    "        \n",
    "def merge_user_video_action(user, video, action, return_others=False):\n",
    "    \"\"\"\n",
    "    将用户特征矩阵、视频特征矩阵、行为拼接起来\n",
    "    \"\"\"\n",
    "    tab_user = dt.fread(user) if isinstance(user, str) else dt.Frame(user)\n",
    "    tab_video = dt.fread(video) if isinstance(video, str) else dt.Frame(video)\n",
    "    tab_act = dt.fread(action) if isinstance(action, str) else dt.Frame(action)\n",
    "    \n",
    "    tab_user.key = 'user_id'\n",
    "    tab_act_user = tab_act[:, :, join(tab_user)]\n",
    "    tab_video.key = 'video_id'\n",
    "    tab_act_user_video = tab_act_user[:, :, join(tab_video)]\n",
    "    \n",
    "    if not return_others:\n",
    "        return tab_act_user_video \n",
    "    else:\n",
    "        return tab_act_user_video, {\"user\": tab_user, \"video\": tab_video, \"action\": tab_act}\n",
    "\n",
    "\n",
    "\n",
    "def load_train_test_data(path=None, pre_merged=True, return_others=False, **kwargs):\n",
    "    \"\"\"\n",
    "    读取保存的训练数据\n",
    "    \"\"\" \n",
    "    if pre_merged:\n",
    "        assert path is not None\n",
    "        tab = dt.fread(path)\n",
    "#     del tab[:, ['video_id', 'user_id']]\n",
    "        return tab\n",
    "    else:\n",
    "        p_user = kwargs.get('p_user')\n",
    "        p_video = kwargs.get('p_video')\n",
    "        p_action = kwargs.get('p_action')\n",
    "        \n",
    "        if return_others:\n",
    "            tab, others = merge_user_video_action(p_user, p_video, p_action, return_others=True)\n",
    "            return tab, others\n",
    "        else:\n",
    "            tab = merge_user_video_action(p_user, p_video, p_action)\n",
    "            return tab\n",
    "\n",
    "\n",
    "def read_npz_to_df(path, data_name='data', column_name='columns'):\n",
    "    npz = np.load(path, allow_pickle=True)\n",
    "    df = pd.DataFrame(npz[data_name], columns=npz[column_name])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"../2021_3_data\"\n",
    "test_data_dir  = os.path.join(base_dir, \"testdata\")\n",
    "train_data_dir = os.path.join(base_dir, \"traindata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过 .npz 读取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 单表读取后合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.41 s, sys: 3.35 s, total: 6.76 s\n",
      "Wall time: 12.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>is_watch</th>\n",
       "      <th>is_share</th>\n",
       "      <th>watch_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4239342</td>\n",
       "      <td>28149</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3577036</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5527504</td>\n",
       "      <td>3636</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1117889</td>\n",
       "      <td>12968</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1117889</td>\n",
       "      <td>860</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7353019</th>\n",
       "      <td>1073806</td>\n",
       "      <td>39040</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7353020</th>\n",
       "      <td>1073806</td>\n",
       "      <td>30641</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7353021</th>\n",
       "      <td>1073806</td>\n",
       "      <td>29794</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7353022</th>\n",
       "      <td>1673305</td>\n",
       "      <td>12968</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7353023</th>\n",
       "      <td>4806675</td>\n",
       "      <td>39040</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7353024 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  video_id  is_watch  is_share  watch_label\n",
       "0        4239342     28149         1         0            2\n",
       "1        3577036       115         1         0            0\n",
       "2        5527504      3636         1         0            5\n",
       "3        1117889     12968         1         0            0\n",
       "4        1117889       860         1         0            4\n",
       "...          ...       ...       ...       ...          ...\n",
       "7353019  1073806     39040         1         0            0\n",
       "7353020  1073806     30641         1         0            0\n",
       "7353021  1073806     29794         1         0            8\n",
       "7353022  1673305     12968         1         0            0\n",
       "7353023  4806675     39040         1         0            0\n",
       "\n",
       "[7353024 rows x 5 columns]"
      ]
     },
     "execution_count": 795,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 单独读取每个文件再进行合并\n",
    "user_df = read_npz_to_df(os.path.join(train_data_dir, \"user_features_data/user_features.npz\"), data_name='features', column_name='columns')\n",
    "video_df = read_npz_to_df(os.path.join(train_data_dir, \"video_features_data/video_features.npz\"), data_name='features')\n",
    "action_df = read_npz_to_df(os.path.join(train_data_dir, \"all_actions.npz\"), data_name='data')\n",
    "action_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因为将字符串保存到 .npz时会使dtype为object，重新读回DataFrame时各个列的数据类型均为 object，所以先转换类型\n",
    "dtypes = dict(zip(video_df.columns, [np.float32] * video_df.shape[1]))\n",
    "dtypes.update({'video_name': np.str})\n",
    "video_df = video_df.astype(dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 29s, sys: 5.88 s, total: 1min 35s\n",
      "Wall time: 40.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7353024, 76)"
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 合并各个表\n",
    "df_train = merge_user_video_action(user_df, video_df, action_df)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(os.path.join(train_data_dir, \"train.npz\"), data=df_train.to_pandas().values, columns=df_train.to_pandas().columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 626 ms, sys: 0 ns, total: 626 ms\n",
      "Wall time: 721 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_df = load_table(os.path.join(test_data_dir, \"test.csv\"), ftype=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 8s, sys: 12.8 s, total: 3min 20s\n",
      "Wall time: 51.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2822180, 73)"
      ]
     },
     "execution_count": 779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_test = merge_user_video_action(user_df, video_df, test_df)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取合并好的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 2s, sys: 38.4 s, total: 3min 40s\n",
      "Wall time: 3min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7353024, 76)"
      ]
     },
     "execution_count": 806,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 直接读取保存好的合并后的训练数据\n",
    "path = os.path.join(train_data_dir, \"train.npz\")\n",
    "df_train = read_npz_to_df(path, data_name='data')\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 37s, sys: 36.9 s, total: 2min 14s\n",
      "Wall time: 5min 49s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2822180, 73)"
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 直接读取保存好的合并后的测试数据\n",
    "path = os.path.join(test_data_dir, \"test.npz\")\n",
    "df_test = read_npz_to_df(path, data_name='data')\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过 .jay 文件读取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 单表读取后合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 9s, sys: 8.9 s, total: 1min 18s\n",
      "Wall time: 33.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7353024, 76)"
      ]
     },
     "execution_count": 811,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "## 使用datatable 加载训练数据\n",
    "p_user = os.path.join(train_data_dir, \"user_features_data/user_features.jay\")\n",
    "p_video = os.path.join(train_data_dir, \"video_features_data/video_features.jay\")\n",
    "p_act = os.path.join(train_data_dir, \"all_actions.jay\")\n",
    "\n",
    "df_train, others = load_train_test_data(None, pre_merged=False, return_others=True,\n",
    "                           **{\"p_user\": p_user, \"p_video\": p_video, \"p_action\": p_act})\n",
    "user_df = others['user']\n",
    "video_df = others['video']\n",
    "action_df = others['action']\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 36s, sys: 9.11 s, total: 1min 45s\n",
      "Wall time: 26 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2822180, 73)"
      ]
     },
     "execution_count": 812,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "p_user = os.path.join(train_data_dir, \"user_features_data/user_features.jay\")\n",
    "p_video = os.path.join(train_data_dir, \"video_features_data/video_features.jay\")\n",
    "p_act = os.path.join(test_data_dir, \"test.csv\")\n",
    "\n",
    "path = os.path.join(test_data_dir, \"test.jay\")\n",
    "kwargs = {\"p_user\": p_user, \"p_video\": p_video, \"p_action\": p_act}\n",
    "\n",
    "df_test, others = load_train_test_data(None, pre_merged=False, return_others=True, **kwargs)\n",
    "test_df = others['action']\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_df = action_df.to_pandas()\n",
    "user_df = user_df.to_pandas()\n",
    "video_df = video_df.to_pandas()\n",
    "test_df = test_df.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取合并好后的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 直接读取保存好的合并后的训练数据\n",
    "path = os.path.join(train_data_dir, \"train.jay\")\n",
    "tab_train = load_train_test_data(path, pre_merged=True)\n",
    "tab_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 直接读取保存好的合并后的测试数据\n",
    "path = os.path.join(test_data_dir, \"test.jay\")\n",
    "tab_train = load_train_test_data(path, pre_merged=True)\n",
    "tab_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理训练数据\n",
    "可在此做一些预处理：\n",
    "- 从用户历史行为数据中筛掉在视频特征中没出现过的video_id\n",
    "- 删除多余的列\n",
    "- 调整列的顺序\n",
    "- 改变列的数据类型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(df_train, dt.Frame):\n",
    "    df_train = df_train.to_pandas()\n",
    "if isinstance(df_test, dt.Frame):\n",
    "    df_test = df_test.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7353024 entries, 0 to 7353023\n",
      "Data columns (total 76 columns):\n",
      " #   Column               Dtype  \n",
      "---  ------               -----  \n",
      " 0   user_id              int64  \n",
      " 1   video_id             int64  \n",
      " 2   is_watch             int64  \n",
      " 3   is_share             int64  \n",
      " 4   watch_label          int64  \n",
      " 5   age_0                float64\n",
      " 6   age_1                float64\n",
      " 7   age_2                float64\n",
      " 8   age_3                float64\n",
      " 9   age_4                float64\n",
      " 10  age_5                float64\n",
      " 11  age_6                float64\n",
      " 12  age_7                float64\n",
      " 13  gender_0             float64\n",
      " 14  gender_1             float64\n",
      " 15  gender_2             float64\n",
      " 16  gender_3             float64\n",
      " 17  city_level_0         float64\n",
      " 18  city_level_1         float64\n",
      " 19  city_level_2         float64\n",
      " 20  city_level_3         float64\n",
      " 21  city_level_4         float64\n",
      " 22  city_level_5         float64\n",
      " 23  city_level_6         float64\n",
      " 24  city_level_7         float64\n",
      " 25  device_name_0        float64\n",
      " 26  device_name_1        float64\n",
      " 27  device_name_2        float64\n",
      " 28  device_name_3        float64\n",
      " 29  device_name_4        float64\n",
      " 30  device_name_5        float64\n",
      " 31  device_name_6        float64\n",
      " 32  device_name_7        float64\n",
      " 33  device_name_8        float64\n",
      " 34  device_name_9        float64\n",
      " 35  video_name           object \n",
      " 36  video_score          float32\n",
      " 37  video_duration       float32\n",
      " 38  video_release_year   float32\n",
      " 39  video_release_month  float32\n",
      " 40  video_release_day    float32\n",
      " 41  desc_0               float32\n",
      " 42  desc_1               float32\n",
      " 43  desc_2               float32\n",
      " 44  desc_3               float32\n",
      " 45  desc_4               float32\n",
      " 46  desc_5               float32\n",
      " 47  desc_6               float32\n",
      " 48  desc_7               float32\n",
      " 49  desc_8               float32\n",
      " 50  desc_9               float32\n",
      " 51  tags_0               float32\n",
      " 52  tags_1               float32\n",
      " 53  tags_2               float32\n",
      " 54  tags_3               float32\n",
      " 55  tags_4               float32\n",
      " 56  tags_5               float32\n",
      " 57  tags_6               float32\n",
      " 58  tags_7               float32\n",
      " 59  tags_8               float32\n",
      " 60  tags_9               float32\n",
      " 61  class_0              float32\n",
      " 62  class_1              float32\n",
      " 63  class_2              float32\n",
      " 64  class_3              float32\n",
      " 65  class_4              float32\n",
      " 66  class_5              float32\n",
      " 67  class_6              float32\n",
      " 68  class_7              float32\n",
      " 69  class_8              float32\n",
      " 70  class_9              float32\n",
      " 71  da_0                 float32\n",
      " 72  da_1                 float32\n",
      " 73  da_2                 float32\n",
      " 74  da_3                 float32\n",
      " 75  da_4                 float32\n",
      "dtypes: float32(40), float64(30), int64(5), object(1)\n",
      "memory usage: 3.1+ GB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除 video_name、is_watch 列\n",
    "df_train.drop(['video_name', 'is_watch'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除 video_id、user_id列\n",
    "user_video_action.drop(['user_id', 'video_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7353024 entries, 0 to 7353023\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Dtype\n",
      "---  ------       -----\n",
      " 0   user_id      int64\n",
      " 1   video_id     int64\n",
      " 2   is_watch     int64\n",
      " 3   is_share     int64\n",
      " 4   watch_label  int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 280.5 MB\n"
     ]
    }
   ],
   "source": [
    "action_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   15,   144,   428,   497,   876,  1174,  2127,  2199,  2334,\n",
       "             3153,\n",
       "            ...\n",
       "            48069, 48269, 48343, 48626, 49103, 49241, 49404, 49419, 49793,\n",
       "            50337],\n",
       "           dtype='int64', length=243)"
      ]
     },
     "execution_count": 816,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从用户历史行为数据中筛掉在视频特征中没出现过的video_id\n",
    "idx1 = pd.Index(action_df['video_id'].unique())\n",
    "idx2 = pd.Index(video_df['video_id'])\n",
    "not_exists = idx1.difference(idx2)\n",
    "not_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45006\n",
      "CPU times: user 3.58 s, sys: 0 ns, total: 3.58 s\n",
      "Wall time: 3.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = 0\n",
    "for vid in not_exists:\n",
    "    tn = (df_train['video_id'] == vid).sum()\n",
    "    #     action_df = action_df[action_df['video_id'] != vid]\n",
    "#     action_df['video_id'].replace(vid, np.nan, inplace=True)\n",
    "    n += tn\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在视频特征中不存在的video_id在行为数据集中出现的次数 = 45006\t\t(cost 10.650s)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t0 = time()\n",
    "n = 0\n",
    "for vid in not_exists:\n",
    "    tn = (action_df['video_id'] == vid).sum()\n",
    "#     action_df = action_df[action_df['video_id'] != vid]\n",
    "    action_df['video_id'].replace(vid, np.nan, inplace=True)\n",
    "    n += tn\n",
    "action_df.dropna(axis=0, inplace=True)\n",
    "print(f\"在视频特征中不存在的video_id在行为数据集中出现的次数 = {n}\\t\\t(cost {time() - t0:.3f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'test_df' not in dir():\n",
    "    test_df = pd.read_csv(os.path.join(test_data_dir, \"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2822180 entries, 0 to 2822179\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Dtype\n",
      "---  ------    -----\n",
      " 0   user_id   int32\n",
      " 1   video_id  int32\n",
      "dtypes: int32(2)\n",
      "memory usage: 21.5 MB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2822180 entries, 0 to 2822179\n",
      "Data columns (total 73 columns):\n",
      " #   Column               Dtype  \n",
      "---  ------               -----  \n",
      " 0   user_id              int32  \n",
      " 1   video_id             int32  \n",
      " 2   age_0                float64\n",
      " 3   age_1                float64\n",
      " 4   age_2                float64\n",
      " 5   age_3                float64\n",
      " 6   age_4                float64\n",
      " 7   age_5                float64\n",
      " 8   age_6                float64\n",
      " 9   age_7                float64\n",
      " 10  gender_0             float64\n",
      " 11  gender_1             float64\n",
      " 12  gender_2             float64\n",
      " 13  gender_3             float64\n",
      " 14  city_level_0         float64\n",
      " 15  city_level_1         float64\n",
      " 16  city_level_2         float64\n",
      " 17  city_level_3         float64\n",
      " 18  city_level_4         float64\n",
      " 19  city_level_5         float64\n",
      " 20  city_level_6         float64\n",
      " 21  city_level_7         float64\n",
      " 22  device_name_0        float64\n",
      " 23  device_name_1        float64\n",
      " 24  device_name_2        float64\n",
      " 25  device_name_3        float64\n",
      " 26  device_name_4        float64\n",
      " 27  device_name_5        float64\n",
      " 28  device_name_6        float64\n",
      " 29  device_name_7        float64\n",
      " 30  device_name_8        float64\n",
      " 31  device_name_9        float64\n",
      " 32  video_name           object \n",
      " 33  video_score          float32\n",
      " 34  video_duration       float32\n",
      " 35  video_release_year   float32\n",
      " 36  video_release_month  float32\n",
      " 37  video_release_day    float32\n",
      " 38  desc_0               float32\n",
      " 39  desc_1               float32\n",
      " 40  desc_2               float32\n",
      " 41  desc_3               float32\n",
      " 42  desc_4               float32\n",
      " 43  desc_5               float32\n",
      " 44  desc_6               float32\n",
      " 45  desc_7               float32\n",
      " 46  desc_8               float32\n",
      " 47  desc_9               float32\n",
      " 48  tags_0               float32\n",
      " 49  tags_1               float32\n",
      " 50  tags_2               float32\n",
      " 51  tags_3               float32\n",
      " 52  tags_4               float32\n",
      " 53  tags_5               float32\n",
      " 54  tags_6               float32\n",
      " 55  tags_7               float32\n",
      " 56  tags_8               float32\n",
      " 57  tags_9               float32\n",
      " 58  class_0              float32\n",
      " 59  class_1              float32\n",
      " 60  class_2              float32\n",
      " 61  class_3              float32\n",
      " 62  class_4              float32\n",
      " 63  class_5              float32\n",
      " 64  class_6              float32\n",
      " 65  class_7              float32\n",
      " 66  class_8              float32\n",
      " 67  class_9              float32\n",
      " 68  da_0                 float32\n",
      " 69  da_1                 float32\n",
      " 70  da_2                 float32\n",
      " 71  da_3                 float32\n",
      " 72  da_4                 float32\n",
      "dtypes: float32(40), float64(30), int32(2), object(1)\n",
      "memory usage: 1.1+ GB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除 video_name 列\n",
    "df_test.drop('video_name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除 video_id、user_id 列\n",
    "df_test.drop(['user_id', 'video_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   15,   144,   428,   497,   876,  1174,  1589,  1906,  2127,\n",
       "             2199,\n",
       "            ...\n",
       "            47945, 48069, 48269, 48343, 48626, 49241, 49404, 49419, 49793,\n",
       "            50337],\n",
       "           dtype='int64', length=276)"
      ]
     },
     "execution_count": 832,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试数据集中存在video_id没有在视频特征中出现\n",
    "idx1 = pd.Index(test_df['video_id'].unique())\n",
    "idx2 = pd.Index(video_df['video_id'].unique())\n",
    "non_exists = idx1.difference(idx2)\n",
    "non_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在视频特征中不存在的video_id在测试数据集中出现的次数 = 22038\t\t(cost 0.828s)\n",
      "CPU times: user 373 ms, sys: 457 ms, total: 830 ms\n",
      "Wall time: 829 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t0 = time()\n",
    "n = 0\n",
    "for vid in not_exists:\n",
    "    tn = (test_df['video_id'] == vid).sum()\n",
    "#     action_df = action_df[action_df['video_id'] != vid]\n",
    "    n += tn\n",
    "\n",
    "print(f\"在视频特征中不存在的video_id在测试数据集中出现的次数 = {n}\\t\\t(cost {time() - t0:.3f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_dataset = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2822180, 70)"
      ]
     },
     "execution_count": 840,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_xgb(X_train, y_train, params):\n",
    "    xg_train = xgb.DMatrix(X_train.values, label=y_train.values, enable_categorical=True)\n",
    "    xg_test = xgb.DMatrix(X_test.values, label=y_test.values, enable_categorical=True)\n",
    "    \n",
    "    watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "    num_round = 5\n",
    "    # train xgb\n",
    "    bst = xgb.train(_param, xg_train, num_round, watchlist)\n",
    "    # get prediction\n",
    "    pred = bst.predict(xg_test)\n",
    "    error_rate = np.sum(pred != y_test) / test_y.shape[0]\n",
    "    print('Test error using softmax = {}'.format(error_rate))\n",
    "\n",
    "    # do the same thing again, but output probabilities\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "    # Note: this convention has been changed since xgboost-unity\n",
    "    # get prediction, this is in 1D array, need reshape to (ndata, nclass)\n",
    "    pred_prob = bst.predict(xg_test).reshape(y_test.shape[0], 6)\n",
    "    pred_label = np.argmax(pred_prob, axis=1)\n",
    "    error_rate = np.sum(pred_label != y_test) / y_test.shape[0]\n",
    "    print('Test error using softprob = {}'.format(error_rate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据\n",
    "watch_label = dataset.pop('watch_label').astype(np.uint8)\n",
    "is_share = dataset.pop('is_share').astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## watch_label 预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理数据不均衡问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 5176743), (1, 557421), (2, 314107), (3, 219188), (4, 172404), (5, 143001), (6, 125092), (7, 117749), (8, 138798), (9, 388521)]\n",
      "[[0.         0.70402912]\n",
      " [1.         0.0758084 ]\n",
      " [2.         0.04271807]\n",
      " [3.         0.02980923]\n",
      " [4.         0.02344668]\n",
      " [5.         0.01944792]\n",
      " [6.         0.01701232]\n",
      " [7.         0.01601368]\n",
      " [8.         0.01887632]\n",
      " [9.         0.05283826]]\n"
     ]
    }
   ],
   "source": [
    "items = list(Counter(watch_label).items())\n",
    "items.sort(key=lambda x: x[0])\n",
    "print(items)\n",
    "\n",
    "dist = np.array(items, dtype=np.float)\n",
    "dist[:, 1] = dist[:, 1] / watch_label.shape[0]\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_ss = np.array(items)\n",
    "under_ss_thresh = under_ss[3, 1]  # 设置每个类别样本数目的上限\n",
    "under_ss[:, 1] = np.clip(under_ss[:, 1], a_min=None, a_max=under_ss_thresh)\n",
    "\n",
    "over_ss = under_ss.copy()\n",
    "over_ss_thresh = under_ss[2, 1]  # 设置每个类别样本数据的下限\n",
    "over_ss[:, 1] = np.clip(over_ss[:, 1], a_min=over_ss_thresh, a_max=None)\n",
    "\n",
    "under_ss = dict(under_ss)\n",
    "over_ss = dict(over_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 219188,\n",
       "  1: 219188,\n",
       "  2: 219188,\n",
       "  3: 219188,\n",
       "  4: 172404,\n",
       "  5: 143001,\n",
       "  6: 125092,\n",
       "  7: 117749,\n",
       "  8: 138798,\n",
       "  9: 219188},\n",
       " {0: 219188,\n",
       "  1: 219188,\n",
       "  2: 219188,\n",
       "  3: 219188,\n",
       "  4: 219188,\n",
       "  5: 219188,\n",
       "  6: 219188,\n",
       "  7: 219188,\n",
       "  8: 219188,\n",
       "  9: 219188})"
      ]
     },
     "execution_count": 844,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_ss, over_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5176743,)"
      ]
     },
     "execution_count": 845,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = watch_label == 0\n",
    "idxs = idxs.replace(False, np.nan).dropna().index  # 保留watch_label=0的行索引\n",
    "idxs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4957555,), (219188,))"
      ]
     },
     "execution_count": 846,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_idxs = np.random.choice(idxs, under_ss_thresh, replace=False)  # 选择一部分保留，注意replace参数，为True时会重复采样\n",
    "del_idxs = idxs.difference(left_idxs)\n",
    "del_idxs.shape, left_idxs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 312266,\n",
       "         0: 5146219,\n",
       "         5: 142012,\n",
       "         4: 171292,\n",
       "         1: 554320,\n",
       "         9: 385082,\n",
       "         3: 217820,\n",
       "         8: 137834,\n",
       "         7: 116928,\n",
       "         6: 124245})"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(watch_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2395469, 72), (2395469,))"
      ]
     },
     "execution_count": 847,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_data = np.delete(dataset.values, del_idxs, axis=0)\n",
    "resampled_wl = np.delete(watch_label.values, del_idxs, axis=0)\n",
    "resampled_data.shape, resampled_wl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 312266,\n",
       "         5: 142012,\n",
       "         4: 171292,\n",
       "         1: 554320,\n",
       "         9: 385082,\n",
       "         3: 217820,\n",
       "         0: 385082,\n",
       "         8: 137834,\n",
       "         7: 116928,\n",
       "         6: 124245})"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(resampled_wl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 速度太慢，难以忍受！\n",
    "nm  = TomekLinks(sampling_strategy=under_ss)\n",
    "smt = SMOTE(sampling_strategy=over_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "X_r, y_r = nm.fit_resample(resampled_data, pd.Series(resampled_wl))\n",
    "print(f\"Under Sampling finished ...\\t\\t({time()-t0:.3f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_r, y_r = smt.fit_resample(X_r, y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2395469, 72), (7353024,))"
      ]
     },
     "execution_count": 848,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将采样后的数据重装回 DataFrame\n",
    "data = pd.DataFrame(resampled_data, columns=dataset.columns)\n",
    "watch_label_res = pd.Series(resampled_wl)\n",
    "data.shape, watch_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1916375,), (479094,))"
      ]
     },
     "execution_count": 849,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx, test_idx = train_test_split(data.index, test_size=0.2, random_state=0)\n",
    "train_idx.shape, test_idx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.iloc[train_idx]\n",
    "X_test  = data.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = watch_label_res.iloc[train_idx]\n",
    "y_test  = watch_label_res.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1916375, 72), (1916375,), (479094, 72), (479094,))"
      ]
     },
     "execution_count": 852,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparing finished ...\t\t(1.896s)\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "xg_train = xgb.DMatrix(X_train.values, label=y_train.values, enable_categorical=True)\n",
    "xg_test = xgb.DMatrix(X_test.values, label=y_test.values, enable_categorical=True)\n",
    "print(f\"Data preparing finished ...\\t\\t({time()-t0:.3f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 11\n",
    "param['min_child_weight'] = 7\n",
    "param['nthread'] = 8\n",
    "param['num_class'] = 10\n",
    "param['gpu_id'] = 0\n",
    "param['tree_method'] = 'gpu_hist'\n",
    "# param['scale_pos_weight'] = 2\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:45:35] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\ttrain-mlogloss:2.27337\ttest-mlogloss:2.27422\n",
      "[1]\ttrain-mlogloss:2.24917\ttest-mlogloss:2.25083\n",
      "[2]\ttrain-mlogloss:2.22867\ttest-mlogloss:2.23111\n",
      "[3]\ttrain-mlogloss:2.21100\ttest-mlogloss:2.21427\n",
      "[4]\ttrain-mlogloss:2.19564\ttest-mlogloss:2.19971\n",
      "[5]\ttrain-mlogloss:2.18217\ttest-mlogloss:2.18702\n",
      "[6]\ttrain-mlogloss:2.17038\ttest-mlogloss:2.17598\n",
      "[7]\ttrain-mlogloss:2.16001\ttest-mlogloss:2.16637\n",
      "[8]\ttrain-mlogloss:2.15074\ttest-mlogloss:2.15787\n",
      "[9]\ttrain-mlogloss:2.14235\ttest-mlogloss:2.15026\n",
      "[10]\ttrain-mlogloss:2.13481\ttest-mlogloss:2.14346\n",
      "[11]\ttrain-mlogloss:2.12806\ttest-mlogloss:2.13745\n",
      "[12]\ttrain-mlogloss:2.12209\ttest-mlogloss:2.13222\n",
      "[13]\ttrain-mlogloss:2.11661\ttest-mlogloss:2.12746\n",
      "[14]\ttrain-mlogloss:2.11156\ttest-mlogloss:2.12319\n",
      "[15]\ttrain-mlogloss:2.10697\ttest-mlogloss:2.11935\n",
      "[16]\ttrain-mlogloss:2.10281\ttest-mlogloss:2.11591\n",
      "[17]\ttrain-mlogloss:2.09906\ttest-mlogloss:2.11288\n",
      "[18]\ttrain-mlogloss:2.09562\ttest-mlogloss:2.11014\n",
      "[19]\ttrain-mlogloss:2.09247\ttest-mlogloss:2.10772\n",
      "[20]\ttrain-mlogloss:2.08955\ttest-mlogloss:2.10554\n",
      "[21]\ttrain-mlogloss:2.08678\ttest-mlogloss:2.10352\n",
      "[22]\ttrain-mlogloss:2.08424\ttest-mlogloss:2.10175\n",
      "[23]\ttrain-mlogloss:2.08178\ttest-mlogloss:2.10004\n",
      "[24]\ttrain-mlogloss:2.07957\ttest-mlogloss:2.09861\n",
      "[25]\ttrain-mlogloss:2.07750\ttest-mlogloss:2.09729\n",
      "[26]\ttrain-mlogloss:2.07545\ttest-mlogloss:2.09601\n",
      "[27]\ttrain-mlogloss:2.07357\ttest-mlogloss:2.09497\n",
      "[28]\ttrain-mlogloss:2.07176\ttest-mlogloss:2.09393\n",
      "[29]\ttrain-mlogloss:2.07003\ttest-mlogloss:2.09300\n",
      "[30]\ttrain-mlogloss:2.06845\ttest-mlogloss:2.09221\n",
      "[31]\ttrain-mlogloss:2.06689\ttest-mlogloss:2.09140\n",
      "[32]\ttrain-mlogloss:2.06540\ttest-mlogloss:2.09072\n",
      "[33]\ttrain-mlogloss:2.06385\ttest-mlogloss:2.09000\n",
      "[34]\ttrain-mlogloss:2.06254\ttest-mlogloss:2.08940\n",
      "[35]\ttrain-mlogloss:2.06117\ttest-mlogloss:2.08882\n",
      "[36]\ttrain-mlogloss:2.05998\ttest-mlogloss:2.08838\n",
      "[37]\ttrain-mlogloss:2.05871\ttest-mlogloss:2.08788\n",
      "[38]\ttrain-mlogloss:2.05752\ttest-mlogloss:2.08746\n",
      "[39]\ttrain-mlogloss:2.05635\ttest-mlogloss:2.08710\n",
      "[40]\ttrain-mlogloss:2.05517\ttest-mlogloss:2.08668\n",
      "[41]\ttrain-mlogloss:2.05410\ttest-mlogloss:2.08635\n",
      "[42]\ttrain-mlogloss:2.05307\ttest-mlogloss:2.08608\n",
      "[43]\ttrain-mlogloss:2.05202\ttest-mlogloss:2.08576\n",
      "[44]\ttrain-mlogloss:2.05093\ttest-mlogloss:2.08547\n",
      "[45]\ttrain-mlogloss:2.04997\ttest-mlogloss:2.08523\n",
      "[46]\ttrain-mlogloss:2.04899\ttest-mlogloss:2.08499\n",
      "[47]\ttrain-mlogloss:2.04811\ttest-mlogloss:2.08481\n",
      "[48]\ttrain-mlogloss:2.04722\ttest-mlogloss:2.08459\n",
      "[49]\ttrain-mlogloss:2.04638\ttest-mlogloss:2.08447\n",
      "[50]\ttrain-mlogloss:2.04546\ttest-mlogloss:2.08428\n",
      "[51]\ttrain-mlogloss:2.04471\ttest-mlogloss:2.08420\n",
      "[52]\ttrain-mlogloss:2.04399\ttest-mlogloss:2.08410\n",
      "[53]\ttrain-mlogloss:2.04318\ttest-mlogloss:2.08398\n",
      "[54]\ttrain-mlogloss:2.04246\ttest-mlogloss:2.08389\n",
      "[55]\ttrain-mlogloss:2.04171\ttest-mlogloss:2.08379\n",
      "[56]\ttrain-mlogloss:2.04093\ttest-mlogloss:2.08372\n",
      "[57]\ttrain-mlogloss:2.04027\ttest-mlogloss:2.08365\n",
      "[58]\ttrain-mlogloss:2.03953\ttest-mlogloss:2.08356\n",
      "[59]\ttrain-mlogloss:2.03888\ttest-mlogloss:2.08351\n",
      "[60]\ttrain-mlogloss:2.03822\ttest-mlogloss:2.08345\n",
      "[61]\ttrain-mlogloss:2.03751\ttest-mlogloss:2.08337\n",
      "[62]\ttrain-mlogloss:2.03684\ttest-mlogloss:2.08331\n",
      "[63]\ttrain-mlogloss:2.03617\ttest-mlogloss:2.08327\n",
      "[64]\ttrain-mlogloss:2.03549\ttest-mlogloss:2.08323\n",
      "[65]\ttrain-mlogloss:2.03488\ttest-mlogloss:2.08319\n",
      "[66]\ttrain-mlogloss:2.03412\ttest-mlogloss:2.08316\n",
      "[67]\ttrain-mlogloss:2.03344\ttest-mlogloss:2.08309\n",
      "[68]\ttrain-mlogloss:2.03282\ttest-mlogloss:2.08308\n",
      "[69]\ttrain-mlogloss:2.03221\ttest-mlogloss:2.08303\n",
      "[70]\ttrain-mlogloss:2.03154\ttest-mlogloss:2.08300\n",
      "[71]\ttrain-mlogloss:2.03099\ttest-mlogloss:2.08298\n",
      "[72]\ttrain-mlogloss:2.03027\ttest-mlogloss:2.08295\n",
      "[73]\ttrain-mlogloss:2.02973\ttest-mlogloss:2.08295\n",
      "[74]\ttrain-mlogloss:2.02897\ttest-mlogloss:2.08286\n",
      "[75]\ttrain-mlogloss:2.02842\ttest-mlogloss:2.08283\n",
      "[76]\ttrain-mlogloss:2.02787\ttest-mlogloss:2.08279\n",
      "[77]\ttrain-mlogloss:2.02724\ttest-mlogloss:2.08276\n",
      "[78]\ttrain-mlogloss:2.02674\ttest-mlogloss:2.08273\n",
      "[79]\ttrain-mlogloss:2.02608\ttest-mlogloss:2.08272\n",
      "[80]\ttrain-mlogloss:2.02552\ttest-mlogloss:2.08271\n",
      "[81]\ttrain-mlogloss:2.02495\ttest-mlogloss:2.08269\n",
      "[82]\ttrain-mlogloss:2.02435\ttest-mlogloss:2.08267\n",
      "[83]\ttrain-mlogloss:2.02377\ttest-mlogloss:2.08266\n",
      "[84]\ttrain-mlogloss:2.02330\ttest-mlogloss:2.08265\n",
      "[85]\ttrain-mlogloss:2.02275\ttest-mlogloss:2.08264\n",
      "[86]\ttrain-mlogloss:2.02214\ttest-mlogloss:2.08262\n",
      "[87]\ttrain-mlogloss:2.02167\ttest-mlogloss:2.08262\n",
      "[88]\ttrain-mlogloss:2.02111\ttest-mlogloss:2.08261\n",
      "[89]\ttrain-mlogloss:2.02052\ttest-mlogloss:2.08261\n",
      "[90]\ttrain-mlogloss:2.01999\ttest-mlogloss:2.08261\n",
      "[91]\ttrain-mlogloss:2.01949\ttest-mlogloss:2.08262\n",
      "[92]\ttrain-mlogloss:2.01894\ttest-mlogloss:2.08260\n",
      "[93]\ttrain-mlogloss:2.01833\ttest-mlogloss:2.08258\n",
      "[94]\ttrain-mlogloss:2.01781\ttest-mlogloss:2.08256\n",
      "[95]\ttrain-mlogloss:2.01729\ttest-mlogloss:2.08257\n",
      "[96]\ttrain-mlogloss:2.01684\ttest-mlogloss:2.08257\n",
      "[97]\ttrain-mlogloss:2.01638\ttest-mlogloss:2.08255\n",
      "[98]\ttrain-mlogloss:2.01582\ttest-mlogloss:2.08256\n",
      "[99]\ttrain-mlogloss:2.01519\ttest-mlogloss:2.08254\n",
      "[100]\ttrain-mlogloss:2.01476\ttest-mlogloss:2.08254\n",
      "[101]\ttrain-mlogloss:2.01429\ttest-mlogloss:2.08256\n",
      "[102]\ttrain-mlogloss:2.01379\ttest-mlogloss:2.08255\n",
      "[103]\ttrain-mlogloss:2.01320\ttest-mlogloss:2.08255\n",
      "[104]\ttrain-mlogloss:2.01268\ttest-mlogloss:2.08255\n",
      "[105]\ttrain-mlogloss:2.01226\ttest-mlogloss:2.08255\n",
      "[106]\ttrain-mlogloss:2.01174\ttest-mlogloss:2.08257\n",
      "[107]\ttrain-mlogloss:2.01126\ttest-mlogloss:2.08254\n",
      "[108]\ttrain-mlogloss:2.01078\ttest-mlogloss:2.08253\n",
      "[109]\ttrain-mlogloss:2.01028\ttest-mlogloss:2.08251\n",
      "[110]\ttrain-mlogloss:2.00978\ttest-mlogloss:2.08250\n",
      "[111]\ttrain-mlogloss:2.00933\ttest-mlogloss:2.08250\n",
      "[112]\ttrain-mlogloss:2.00881\ttest-mlogloss:2.08247\n",
      "[113]\ttrain-mlogloss:2.00834\ttest-mlogloss:2.08247\n",
      "[114]\ttrain-mlogloss:2.00778\ttest-mlogloss:2.08249\n",
      "[115]\ttrain-mlogloss:2.00729\ttest-mlogloss:2.08247\n",
      "[116]\ttrain-mlogloss:2.00685\ttest-mlogloss:2.08248\n",
      "[117]\ttrain-mlogloss:2.00643\ttest-mlogloss:2.08247\n",
      "[118]\ttrain-mlogloss:2.00597\ttest-mlogloss:2.08249\n",
      "[119]\ttrain-mlogloss:2.00548\ttest-mlogloss:2.08247\n",
      "[120]\ttrain-mlogloss:2.00499\ttest-mlogloss:2.08248\n",
      "[121]\ttrain-mlogloss:2.00455\ttest-mlogloss:2.08247\n",
      "[122]\ttrain-mlogloss:2.00400\ttest-mlogloss:2.08244\n",
      "[123]\ttrain-mlogloss:2.00341\ttest-mlogloss:2.08243\n",
      "[124]\ttrain-mlogloss:2.00303\ttest-mlogloss:2.08244\n",
      "[125]\ttrain-mlogloss:2.00264\ttest-mlogloss:2.08243\n",
      "[126]\ttrain-mlogloss:2.00215\ttest-mlogloss:2.08245\n",
      "[127]\ttrain-mlogloss:2.00167\ttest-mlogloss:2.08245\n",
      "[128]\ttrain-mlogloss:2.00126\ttest-mlogloss:2.08247\n",
      "[129]\ttrain-mlogloss:2.00081\ttest-mlogloss:2.08247\n",
      "[130]\ttrain-mlogloss:2.00025\ttest-mlogloss:2.08248\n",
      "[131]\ttrain-mlogloss:1.99983\ttest-mlogloss:2.08248\n",
      "[132]\ttrain-mlogloss:1.99940\ttest-mlogloss:2.08249\n",
      "[133]\ttrain-mlogloss:1.99898\ttest-mlogloss:2.08250\n",
      "[134]\ttrain-mlogloss:1.99850\ttest-mlogloss:2.08249\n",
      "[135]\ttrain-mlogloss:1.99805\ttest-mlogloss:2.08251\n",
      "[136]\ttrain-mlogloss:1.99760\ttest-mlogloss:2.08252\n",
      "[137]\ttrain-mlogloss:1.99697\ttest-mlogloss:2.08252\n",
      "[138]\ttrain-mlogloss:1.99655\ttest-mlogloss:2.08252\n",
      "[139]\ttrain-mlogloss:1.99613\ttest-mlogloss:2.08253\n",
      "[140]\ttrain-mlogloss:1.99561\ttest-mlogloss:2.08252\n",
      "[141]\ttrain-mlogloss:1.99501\ttest-mlogloss:2.08254\n",
      "[142]\ttrain-mlogloss:1.99457\ttest-mlogloss:2.08255\n",
      "[143]\ttrain-mlogloss:1.99405\ttest-mlogloss:2.08254\n",
      "[144]\ttrain-mlogloss:1.99346\ttest-mlogloss:2.08254\n",
      "[145]\ttrain-mlogloss:1.99299\ttest-mlogloss:2.08256\n",
      "[146]\ttrain-mlogloss:1.99252\ttest-mlogloss:2.08258\n",
      "[147]\ttrain-mlogloss:1.99208\ttest-mlogloss:2.08258\n",
      "[148]\ttrain-mlogloss:1.99169\ttest-mlogloss:2.08261\n",
      "[149]\ttrain-mlogloss:1.99115\ttest-mlogloss:2.08263\n",
      "[150]\ttrain-mlogloss:1.99065\ttest-mlogloss:2.08263\n",
      "[151]\ttrain-mlogloss:1.99002\ttest-mlogloss:2.08262\n",
      "[152]\ttrain-mlogloss:1.98946\ttest-mlogloss:2.08264\n",
      "[153]\ttrain-mlogloss:1.98901\ttest-mlogloss:2.08265\n",
      "[154]\ttrain-mlogloss:1.98839\ttest-mlogloss:2.08268\n",
      "[155]\ttrain-mlogloss:1.98784\ttest-mlogloss:2.08268\n",
      "[156]\ttrain-mlogloss:1.98734\ttest-mlogloss:2.08270\n",
      "[157]\ttrain-mlogloss:1.98688\ttest-mlogloss:2.08271\n",
      "[158]\ttrain-mlogloss:1.98636\ttest-mlogloss:2.08275\n",
      "[159]\ttrain-mlogloss:1.98588\ttest-mlogloss:2.08275\n",
      "[160]\ttrain-mlogloss:1.98529\ttest-mlogloss:2.08278\n",
      "[161]\ttrain-mlogloss:1.98484\ttest-mlogloss:2.08279\n",
      "[162]\ttrain-mlogloss:1.98442\ttest-mlogloss:2.08280\n",
      "[163]\ttrain-mlogloss:1.98405\ttest-mlogloss:2.08282\n",
      "[164]\ttrain-mlogloss:1.98355\ttest-mlogloss:2.08283\n",
      "[165]\ttrain-mlogloss:1.98311\ttest-mlogloss:2.08285\n",
      "[166]\ttrain-mlogloss:1.98262\ttest-mlogloss:2.08288\n",
      "[167]\ttrain-mlogloss:1.98215\ttest-mlogloss:2.08288\n",
      "[168]\ttrain-mlogloss:1.98174\ttest-mlogloss:2.08289\n",
      "[169]\ttrain-mlogloss:1.98136\ttest-mlogloss:2.08291\n",
      "[170]\ttrain-mlogloss:1.98099\ttest-mlogloss:2.08293\n",
      "[171]\ttrain-mlogloss:1.98059\ttest-mlogloss:2.08296\n",
      "[172]\ttrain-mlogloss:1.98012\ttest-mlogloss:2.08297\n",
      "[173]\ttrain-mlogloss:1.97968\ttest-mlogloss:2.08298\n",
      "[174]\ttrain-mlogloss:1.97927\ttest-mlogloss:2.08301\n",
      "[175]\ttrain-mlogloss:1.97872\ttest-mlogloss:2.08304\n",
      "[176]\ttrain-mlogloss:1.97825\ttest-mlogloss:2.08306\n",
      "[177]\ttrain-mlogloss:1.97777\ttest-mlogloss:2.08309\n",
      "[178]\ttrain-mlogloss:1.97716\ttest-mlogloss:2.08312\n",
      "[179]\ttrain-mlogloss:1.97670\ttest-mlogloss:2.08314\n",
      "[180]\ttrain-mlogloss:1.97620\ttest-mlogloss:2.08316\n",
      "[181]\ttrain-mlogloss:1.97561\ttest-mlogloss:2.08319\n",
      "[182]\ttrain-mlogloss:1.97512\ttest-mlogloss:2.08321\n",
      "[183]\ttrain-mlogloss:1.97462\ttest-mlogloss:2.08322\n",
      "[184]\ttrain-mlogloss:1.97414\ttest-mlogloss:2.08325\n",
      "[185]\ttrain-mlogloss:1.97364\ttest-mlogloss:2.08328\n",
      "[186]\ttrain-mlogloss:1.97316\ttest-mlogloss:2.08329\n",
      "[187]\ttrain-mlogloss:1.97273\ttest-mlogloss:2.08330\n",
      "[188]\ttrain-mlogloss:1.97233\ttest-mlogloss:2.08333\n",
      "[189]\ttrain-mlogloss:1.97186\ttest-mlogloss:2.08334\n",
      "[190]\ttrain-mlogloss:1.97139\ttest-mlogloss:2.08337\n",
      "[191]\ttrain-mlogloss:1.97090\ttest-mlogloss:2.08339\n",
      "[192]\ttrain-mlogloss:1.97049\ttest-mlogloss:2.08341\n",
      "[193]\ttrain-mlogloss:1.96998\ttest-mlogloss:2.08343\n",
      "[194]\ttrain-mlogloss:1.96947\ttest-mlogloss:2.08346\n",
      "[195]\ttrain-mlogloss:1.96903\ttest-mlogloss:2.08348\n",
      "[196]\ttrain-mlogloss:1.96861\ttest-mlogloss:2.08351\n",
      "[197]\ttrain-mlogloss:1.96811\ttest-mlogloss:2.08352\n",
      "[198]\ttrain-mlogloss:1.96769\ttest-mlogloss:2.08354\n",
      "[199]\ttrain-mlogloss:1.96729\ttest-mlogloss:2.08355\n",
      "[200]\ttrain-mlogloss:1.96686\ttest-mlogloss:2.08356\n",
      "[201]\ttrain-mlogloss:1.96638\ttest-mlogloss:2.08357\n",
      "[202]\ttrain-mlogloss:1.96593\ttest-mlogloss:2.08359\n",
      "[203]\ttrain-mlogloss:1.96549\ttest-mlogloss:2.08361\n",
      "[204]\ttrain-mlogloss:1.96503\ttest-mlogloss:2.08365\n",
      "[205]\ttrain-mlogloss:1.96454\ttest-mlogloss:2.08367\n",
      "[206]\ttrain-mlogloss:1.96401\ttest-mlogloss:2.08371\n",
      "[207]\ttrain-mlogloss:1.96355\ttest-mlogloss:2.08374\n",
      "[208]\ttrain-mlogloss:1.96308\ttest-mlogloss:2.08378\n",
      "[209]\ttrain-mlogloss:1.96267\ttest-mlogloss:2.08380\n",
      "[210]\ttrain-mlogloss:1.96216\ttest-mlogloss:2.08383\n",
      "[211]\ttrain-mlogloss:1.96177\ttest-mlogloss:2.08385\n",
      "[212]\ttrain-mlogloss:1.96124\ttest-mlogloss:2.08389\n",
      "[213]\ttrain-mlogloss:1.96081\ttest-mlogloss:2.08391\n",
      "[214]\ttrain-mlogloss:1.96030\ttest-mlogloss:2.08394\n",
      "[215]\ttrain-mlogloss:1.95984\ttest-mlogloss:2.08395\n",
      "[216]\ttrain-mlogloss:1.95932\ttest-mlogloss:2.08398\n",
      "[217]\ttrain-mlogloss:1.95892\ttest-mlogloss:2.08402\n",
      "[218]\ttrain-mlogloss:1.95851\ttest-mlogloss:2.08405\n",
      "[219]\ttrain-mlogloss:1.95802\ttest-mlogloss:2.08409\n",
      "[220]\ttrain-mlogloss:1.95760\ttest-mlogloss:2.08411\n",
      "[221]\ttrain-mlogloss:1.95725\ttest-mlogloss:2.08413\n",
      "[222]\ttrain-mlogloss:1.95680\ttest-mlogloss:2.08416\n",
      "[223]\ttrain-mlogloss:1.95632\ttest-mlogloss:2.08419\n",
      "[224]\ttrain-mlogloss:1.95592\ttest-mlogloss:2.08423\n",
      "[225]\ttrain-mlogloss:1.95552\ttest-mlogloss:2.08426\n",
      "[226]\ttrain-mlogloss:1.95506\ttest-mlogloss:2.08429\n",
      "[227]\ttrain-mlogloss:1.95464\ttest-mlogloss:2.08432\n",
      "[228]\ttrain-mlogloss:1.95418\ttest-mlogloss:2.08436\n",
      "[229]\ttrain-mlogloss:1.95377\ttest-mlogloss:2.08439\n",
      "[230]\ttrain-mlogloss:1.95334\ttest-mlogloss:2.08441\n",
      "[231]\ttrain-mlogloss:1.95286\ttest-mlogloss:2.08446\n",
      "[232]\ttrain-mlogloss:1.95240\ttest-mlogloss:2.08448\n",
      "[233]\ttrain-mlogloss:1.95184\ttest-mlogloss:2.08453\n",
      "[234]\ttrain-mlogloss:1.95139\ttest-mlogloss:2.08455\n",
      "[235]\ttrain-mlogloss:1.95090\ttest-mlogloss:2.08458\n",
      "[236]\ttrain-mlogloss:1.95045\ttest-mlogloss:2.08462\n",
      "[237]\ttrain-mlogloss:1.95002\ttest-mlogloss:2.08466\n",
      "[238]\ttrain-mlogloss:1.94955\ttest-mlogloss:2.08468\n",
      "[239]\ttrain-mlogloss:1.94914\ttest-mlogloss:2.08471\n",
      "[240]\ttrain-mlogloss:1.94877\ttest-mlogloss:2.08473\n",
      "[241]\ttrain-mlogloss:1.94834\ttest-mlogloss:2.08477\n",
      "[242]\ttrain-mlogloss:1.94801\ttest-mlogloss:2.08480\n",
      "[243]\ttrain-mlogloss:1.94758\ttest-mlogloss:2.08483\n",
      "[244]\ttrain-mlogloss:1.94717\ttest-mlogloss:2.08487\n",
      "[245]\ttrain-mlogloss:1.94667\ttest-mlogloss:2.08493\n",
      "[246]\ttrain-mlogloss:1.94616\ttest-mlogloss:2.08496\n",
      "[247]\ttrain-mlogloss:1.94575\ttest-mlogloss:2.08498\n",
      "[248]\ttrain-mlogloss:1.94524\ttest-mlogloss:2.08502\n",
      "[249]\ttrain-mlogloss:1.94475\ttest-mlogloss:2.08505\n",
      "250-rounds Training finished ...\t\t(319.949s)\n"
     ]
    }
   ],
   "source": [
    "num_round = 200\n",
    "t0 = time()\n",
    "wl_bst_sm = xgb.train(param, xg_train, num_round, watchlist)\n",
    "print(f\"{num_round}-rounds Training finished ...\\t\\t({time()-t0:.3f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error using softmax = 0.7300216658943757\n"
     ]
    }
   ],
   "source": [
    "# get prediction\n",
    "pred = wl_bst_sm.predict(xg_test)\n",
    "# pred = pred.astype(np.uint8)\n",
    "error_rate = np.sum(pred != y_test) / y_test.shape[0]\n",
    "print('Test error using softmax = {}'.format(error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.57749827, 0.58572151, 0.50378435, 0.50053127, 0.50040545,\n",
       "        0.50016001, 0.50280881, 0.50046443, 0.50977498, 0.60535577]),\n",
       " 2.364381155534087)"
      ]
     },
     "execution_count": 857,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.arange(0, 1, 0.1)\n",
    "aucs = auc(y_test.astype(np.uint8), pred.astype(np.uint8), np.arange(param['num_class']))\n",
    "# aucs[aucs == 0.5] = 0\n",
    "w_aucs = (aucs * weights).sum()\n",
    "aucs, w_aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = metrics.classification_report(list(y_test), list(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.20      0.25     43915\n",
      "           1       0.29      0.67      0.40    111680\n",
      "           2       0.19      0.02      0.04     62504\n",
      "           3       0.12      0.00      0.01     43621\n",
      "           4       0.12      0.00      0.00     34605\n",
      "           5       0.11      0.00      0.00     28676\n",
      "           6       0.27      0.01      0.01     25168\n",
      "           7       0.12      0.00      0.00     23377\n",
      "           8       0.29      0.02      0.04     27486\n",
      "           9       0.24      0.56      0.33     78062\n",
      "\n",
      "    accuracy                           0.27    479094\n",
      "   macro avg       0.21      0.15      0.11    479094\n",
      "weighted avg       0.22      0.27      0.18    479094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'objective': 'multi:softmax', 'eta': 0.1, 'max_depth': 5, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 1}, {'objective': 'multi:softmax', 'eta': 0.1, 'max_depth': 7, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 1}, {'objective': 'multi:softmax', 'eta': 0.1, 'max_depth': 9, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 1}, {'objective': 'multi:softmax', 'eta': 0.1, 'max_depth': 11, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 1}, {'objective': 'multi:softmax', 'eta': 0.1, 'max_depth': 5, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 3}, {'objective': 'multi:softmax', 'eta': 0.1, 'max_depth': 7, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 3}, {'objective': 'multi:softmax', 'eta': 0.1, 'max_depth': 9, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 3}, {'objective': 'multi:softmax', 'eta': 0.1, 'max_depth': 11, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 3}, {'objective': 'multi:softmax', 'eta': 0.1, 'max_depth': 5, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 5}, {'objective': 'multi:softmax', 'eta': 0.1, 'max_depth': 7, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 5}, {'objective': 'multi:softmax', 'eta': 0.1, 'max_depth': 9, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 5}, {'objective': 'multi:softmax', 'eta': 0.1, 'max_depth': 11, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 5}, {'objective': 'multi:softmax', 'eta': 0.1, 'max_depth': 5, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 7}, {'objective': 'multi:softmax', 'eta': 0.1, 'max_depth': 7, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 7}, {'objective': 'multi:softmax', 'eta': 0.1, 'max_depth': 9, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 7}, {'objective': 'multi:softmax', 'eta': 0.1, 'max_depth': 11, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 7}]\n"
     ]
    }
   ],
   "source": [
    "base_param = {  # 基本参数，不需要调参\n",
    "    'objective': 'multi:softmax',\n",
    "    'eta': 0.1,\n",
    "    'nthread': 8,\n",
    "    'num_class': 10,\n",
    "    'gpu_id': 0,\n",
    "    'tree_method': 'gpu_hist'\n",
    "} \n",
    "ps = {  # 需要调参的参数\n",
    "    'max_depth': list(range(5, 14, 2)),\n",
    "    'min_child_weight': list(range(1, 10, 2))\n",
    "}\n",
    "\n",
    "tmp = []\n",
    "keys = list(ps.keys())\n",
    "k = keys[0]\n",
    "tmp.extend([[e] for e in ps[k].copy()])\n",
    "\n",
    "# 将需要调参的参数进行组合，即笛卡尔乘积。类似于sklearn中的 ParameterGrid\n",
    "for k in keys[1:]:\n",
    "    v = ps[k].copy()\n",
    "    l = len(tmp)\n",
    "    tmp = [tmp[i%l].copy() for i in range(len(v) * len(tmp))]\n",
    "    for i, e in enumerate(tmp):\n",
    "        e.append(v[i // l])\n",
    "        \n",
    "com_ps = [dict(zip(keys, e)) for e in tmp]\n",
    "# print(com_ps)\n",
    "all_params = [base_param.copy() for _ in range(len(com_ps))] \n",
    "for i in range(len(com_ps)):\n",
    "    all_params[i].update(com_ps[i])\n",
    "    \n",
    "print(all_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i, p in enumerate(all_params):\n",
    "    num_round = 250\n",
    "    t0 = time()\n",
    "    bst = xgb.train(p, xg_train, num_round, watchlist)\n",
    "    print(f\"{num_round}-rounds Training finished ...\\t\\t({time()-t0:.3f}s)\")\n",
    "    \n",
    "    # get prediction\n",
    "    pred = bst.predict(xg_test)\n",
    "    # pred = pred.astype(np.uint8)\n",
    "    error_rate = np.sum(pred != y_test) / y_test.shape[0]\n",
    "    print('Test error using softmax = {}'.format(error_rate))\n",
    "    \n",
    "    weights = np.arange(0, 1, 0.1)\n",
    "    aucs = auc(y_test.astype(np.uint8), pred.astype(np.uint8), np.arange(param['num_class']))\n",
    "    # aucs[aucs == 0.5] = 0\n",
    "    w_aucs = (aucs * weights).sum()\n",
    "    aucs, w_aucs\n",
    "    \n",
    "    rep = metrics.classification_report(list(y_test), list(pred))\n",
    "    results.append({\n",
    "        'test_error': error_rate, \n",
    "        'aucs': aucs,\n",
    "        'w_auc': w_aucs,\n",
    "        'report': rep\n",
    "        'model': bst\n",
    "    })\n",
    "    \n",
    "    print(f\"{i} : {num_round}-rounds Training finished ...\\t\\t({time()-t0:.3f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[-e['test_error'] for e in results], [e['w_auc'] for e in results]], dtype=np.float32)\n",
    "opt_idxs = arr.argmax(axis=1)\n",
    "if opt_idxs[0] != opt_idxs[1]:\n",
    "    raise ValueError(f\"最小误差与最大AUC对应的模型不一致 : {opt_idxs}\")\n",
    "else:\n",
    "    opt_idx = opt_idxs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    "    'max_depth':range(3,10,2),\n",
    "    'min_child_weight':range(1,6,2), \n",
    "}\n",
    "param_test2 = {\n",
    "'max_depth':[4,5,6],\n",
    "'min_child_weight':[4,5,6]\n",
    "}\n",
    "\n",
    "clf = XGBClassifier(learning_rate =0.1, n_estimators=200, max_depth=5, min_child_weight=1, gamma=0, subsample=0.8,\n",
    "        colsample_bytree=0.8, objective= 'multi:logistic', nthread=8, gpu_id=0, seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gsearch1 = GridSearchCV(estimator=clf, param_grid = param_test1, scoring='roc_auc_ovr', n_jobs=8, cv=5, verbose=3)\n",
    "gsearch1.fit(data, watch_label_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gs1 = gsearch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_clf = gs1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_pred = bst_clf.predict(inference_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_data = xgb.DMatrix(data.values, label=watch_label_res.values, enable_categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 8\n",
    "param['nthread'] = 8\n",
    "param['num_class'] = 10\n",
    "# param['gpu_id'] = 0\n",
    "# param['tree_method'] = 'gpu_hist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cv_res= xgb.cv(param, cv_data, num_boost_round=200,early_stopping_rounds=30,nfold=3, metrics='auc',show_stdv=True)\n",
    "print(cv_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## is_share 预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理数据不均衡问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 7338705), (1, 14319)]\n",
      "[[0.         0.99805264]\n",
      " [1.         0.00194736]]\n"
     ]
    }
   ],
   "source": [
    "items = list(Counter(is_share).items())\n",
    "items.sort(key=lambda x: x[0])\n",
    "print(items)\n",
    "\n",
    "dist = np.array(items, dtype=np.float)\n",
    "dist[:, 1] = dist[:, 1] / is_share.shape[0]\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_ss = np.array(items)\n",
    "under_ss_thresh = under_ss[1, 1] + 800\n",
    "under_ss[:, 1] = np.clip(under_ss[:, 1], a_min=None, a_max=under_ss_thresh)\n",
    "\n",
    "over_ss = under_ss.copy()\n",
    "over_ss_thresh = under_ss[1, 1]\n",
    "over_ss[:, 1] = np.clip(over_ss[:, 1], a_min=over_ss_thresh, a_max=None)\n",
    "\n",
    "under_ss = dict(under_ss)\n",
    "over_ss = dict(over_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 15119, 1: 14319}, {0: 15119, 1: 14319})"
      ]
     },
     "execution_count": 949,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_ss, over_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7338705,)"
      ]
     },
     "execution_count": 950,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = is_share == 0\n",
    "idxs = idxs.replace(False, np.nan).dropna().index  # 保留watch_label=0的行索引\n",
    "idxs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7323586,), (15119,))"
      ]
     },
     "execution_count": 951,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_idxs = np.random.choice(idxs, under_ss_thresh, replace=False)  # 选择一部分保留\n",
    "del_idxs = idxs.difference(left_idxs)\n",
    "del_idxs.shape, left_idxs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29438, 72), (29438,))"
      ]
     },
     "execution_count": 952,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_data = np.delete(dataset.values, del_idxs, axis=0)\n",
    "resampled_sh = np.delete(is_share.values, del_idxs, axis=0)\n",
    "resampled_data.shape, resampled_sh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2395469, 72), (7353024,))"
      ]
     },
     "execution_count": 953,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将采样后的数据重装会DataFrame\n",
    "data_sh = pd.DataFrame(resampled_data, columns=dataset.columns)\n",
    "is_share_res = pd.Series(resampled_sh)\n",
    "data.shape, is_share.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23550,), (5888,))"
      ]
     },
     "execution_count": 954,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx, test_idx = train_test_split(data_sh.index, test_size=0.2, random_state=1)\n",
    "train_idx.shape, test_idx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sh = data_sh.iloc[train_idx]\n",
    "X_test_sh  = data_sh.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_sh = is_share_res.iloc[train_idx]\n",
    "y_test_sh  = is_share_res.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparing finished ...\t\t(0.022s)\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "xg_train_sh = xgb.DMatrix(X_train_sh.values, label=y_train_sh.values, enable_categorical=True)\n",
    "xg_test_sh = xgb.DMatrix(X_test_sh.values, label=y_test_sh.values, enable_categorical=True)\n",
    "print(f\"Data preparing finished ...\\t\\t({time()-t0:.3f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup parameters for xgboost\n",
    "param_sh = {}\n",
    "# use softmax multi-class classification\n",
    "param_sh['objective'] = 'binary:hinge'\n",
    "# scale weight of positive examples\n",
    "param_sh['eta'] = 0.1\n",
    "param_sh['max_depth'] = 6\n",
    "param_sh['nthread'] = 4\n",
    "param_sh['gpu_id'] = 0\n",
    "param_sh['tree_method'] = 'gpu_hist'\n",
    "# param_sh['min_child_weight'] = 7\n",
    "\n",
    "\n",
    "watchlist = [(xg_train_sh, 'train'), (xg_test_sh, 'test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_round = 300\n",
    "t0 = time()\n",
    "sh_bst_sm = xgb.train(param_sh, xg_train_sh, num_round, watchlist)\n",
    "print(f\"{num_round}-rounds Training finished ...\\t\\t({time()-t0:.3f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error using softmax = 0.37058423913043476\n"
     ]
    }
   ],
   "source": [
    "# get prediction\n",
    "pred_sh = sh_bst_sm.predict(xg_test_sh)\n",
    "error_rate = np.sum(pred_sh != y_test_sh) / y_test_sh.shape[0]\n",
    "print('Test error using softmax = {}'.format(error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({0.0: 2882, 1.0: 3006}), Counter({0: 3058, 1: 2830}))"
      ]
     },
     "execution_count": 980,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(pred_sh), Counter(y_test_sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.61      0.63      3058\n",
      "           1       0.61      0.65      0.63      2830\n",
      "\n",
      "    accuracy                           0.63      5888\n",
      "   macro avg       0.63      0.63      0.63      5888\n",
      "weighted avg       0.63      0.63      0.63      5888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_sh = metrics.classification_report(list(y_test_sh), list(pred_sh))\n",
    "print(report_sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63001847, 0.63001847])"
      ]
     },
     "execution_count": 982,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs_sh = auc(y_test_sh.astype(np.uint8), pred_sh.astype(np.uint8), [0, 1])\n",
    "aucs_sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'max_depth': 5, 'min_child_weight': 1}, {'max_depth': 5, 'min_child_weight': 3}, {'max_depth': 5, 'min_child_weight': 5}, {'max_depth': 5, 'min_child_weight': 7}, {'max_depth': 7, 'min_child_weight': 1}, {'max_depth': 7, 'min_child_weight': 3}, {'max_depth': 7, 'min_child_weight': 5}, {'max_depth': 7, 'min_child_weight': 7}, {'max_depth': 9, 'min_child_weight': 1}, {'max_depth': 9, 'min_child_weight': 3}, {'max_depth': 9, 'min_child_weight': 5}, {'max_depth': 9, 'min_child_weight': 7}, {'max_depth': 11, 'min_child_weight': 1}, {'max_depth': 11, 'min_child_weight': 3}, {'max_depth': 11, 'min_child_weight': 5}, {'max_depth': 11, 'min_child_weight': 7}]\n",
      "[{'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 5, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 1}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 5, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 3}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 5, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 5}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 5, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 7}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 7, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 1}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 7, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 3}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 7, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 5}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 7, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 7}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 9, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 1}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 9, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 3}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 9, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 5}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 9, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 7}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 11, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 1}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 11, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 3}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 11, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 5}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 11, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 7}]\n"
     ]
    }
   ],
   "source": [
    "base_param_sh = {  # 基本参数，不需要调参\n",
    "    'objective': 'binary:hinge',\n",
    "    'eta': 0.1,\n",
    "    'nthread': 8,\n",
    "#     'num_class': 10,\n",
    "    'gpu_id': 0,\n",
    "    'tree_method': 'gpu_hist'\n",
    "} \n",
    "ps_sh = {  # 需要调参的参数\n",
    "    'max_depth': list(range(5, 13, 2)),\n",
    "    'min_child_weight': list(range(1, 10, 2))\n",
    "}\n",
    "\n",
    "com_ps_sh = list(ParameterGrid(ps_sh))\n",
    "print(com_ps_sh)\n",
    "\n",
    "all_params_sh = [base_param_sh.copy() for _ in range(len(com_ps_sh))] \n",
    "for i in range(len(com_ps_sh)):\n",
    "    all_params_sh[i].update(com_ps_sh[i])\n",
    "    \n",
    "print(all_params_sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_sh = []\n",
    "num_round = 250\n",
    "for i, p in enumerate(all_params):\n",
    "    t0 = time()\n",
    "    bst = xgb.train(p, xg_train_sh, num_round, watchlist)\n",
    "    \n",
    "    # get prediction\n",
    "    pred = bst.predict(xg_test_sh)\n",
    "    # pred = pred.astype(np.uint8)\n",
    "    error_rate = np.sum(pred != y_test_sh) / y_test_sh.shape[0]\n",
    "    \n",
    "    aucs = auc(y_test_sh.astype(np.uint8), pred.astype(np.uint8), np.arange(2))\n",
    "    \n",
    "    rep = metrics.classification_report(list(y_test_sh), list(pred))\n",
    "    results_sh.append({\n",
    "        'test_error': error_rate, \n",
    "        'aucs': aucs,\n",
    "        'report': rep,\n",
    "        'model': bst\n",
    "    })\n",
    "    \n",
    "    print(f\"{i} : {num_round}-rounds Training finished error_rate={error_rate}  aucs={aucs}...\\t\\t({time()-t0:.3f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary:hinge',\n",
       " 'eta': 0.1,\n",
       " 'max_depth': 11,\n",
       " 'nthread': 8,\n",
       " 'gpu_id': 0,\n",
       " 'tree_method': 'gpu_hist',\n",
       " 'min_child_weight': 7}"
      ]
     },
     "execution_count": 876,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([[-e['test_error'] for e in results], [e['w_auc'] for e in results]], dtype=np.float32)\n",
    "opt_idxs_sh = arr.argmax(axis=1)\n",
    "if opt_idxs_sh[0] != opt_idxs_sh[1]:\n",
    "    raise ValueError(f\"最小误差与最大AUC对应的模型不一致 : {opt_idxs_sh}\")\n",
    "else:\n",
    "    opt_idx_sh = opt_idxs_sh[0]\n",
    "all_params_sh[opt_idx_sh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [0.621498838085251, 0.621498838085251]\n",
       "1     [0.6191077482441057, 0.6191077482441057]\n",
       "2     [0.6077097920740165, 0.6077097920740165]\n",
       "3     [0.6092416694226004, 0.6092416694226004]\n",
       "4     [0.6235535033609287, 0.6235535033609287]\n",
       "5     [0.6109579445337427, 0.6109579445337427]\n",
       "6      [0.609377418608228, 0.6093774186082281]\n",
       "7     [0.6066783439631294, 0.6066783439631293]\n",
       "8     [0.6226984063414158, 0.6226984063414157]\n",
       "9     [0.6128707795516763, 0.6128707795516763]\n",
       "10    [0.6130186908815368, 0.6130186908815368]\n",
       "11    [0.6000360933128845, 0.6000360933128845]\n",
       "12    [0.6218615525382517, 0.6218615525382518]\n",
       "13    [0.6121879181504891, 0.6121879181504892]\n",
       "14    [0.6121575127899075, 0.6121575127899075]\n",
       "15    [0.6054038372425004, 0.6054038372425004]\n",
       "Name: aucs, dtype: object"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_sh)['aucs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = inference_dataset\n",
    "test = xgb.DMatrix(test.values, enable_categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2822180, 70), 70)"
      ]
     },
     "execution_count": 986,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_dataset.shape, test.num_col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({0.0: 1859022,\n",
       "          2.0: 339419,\n",
       "          1.0: 301301,\n",
       "          3.0: 271395,\n",
       "          4.0: 42236,\n",
       "          9.0: 8785,\n",
       "          5.0: 18,\n",
       "          7.0: 4}),\n",
       " Counter({0.0: 1739411, 1.0: 1082769}))"
      ]
     },
     "execution_count": 988,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst_wl = wl_bst_sm\n",
    "bst_sh = sh_bst_sm  # results_sh[4]['model']\n",
    "\n",
    "wl = bst_wl.predict(test)\n",
    "sh = bst_sh.predict(test)\n",
    "Counter(wl), Counter(Counter(sh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({1.0: 1311788,\n",
       "          0.0: 788117,\n",
       "          9.0: 681228,\n",
       "          2.0: 23596,\n",
       "          4.0: 741,\n",
       "          8.0: 9749,\n",
       "          3.0: 3041,\n",
       "          6.0: 2609,\n",
       "          7.0: 910,\n",
       "          5.0: 401}),\n",
       " Counter({1.0: 1131623, 0.0: 1690557}))"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl = wl_bst_sm.predict(test)\n",
    "sh = sh_bst_sm.predict(test)\n",
    "Counter(wl), Counter(Counter(sh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2822180, 4)"
      ]
     },
     "execution_count": 989,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['watch_label'] = wl.astype(np.uint8)\n",
    "test_df['is_share'] = sh.astype(np.uint8)\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new submission saved to ../submission-1625145233.csv\n"
     ]
    }
   ],
   "source": [
    "fn = f'../submission-{int(time())}.csv'\n",
    "test_df.to_csv(fn, index=False, sep=\",\")\n",
    "print(f\"new submission saved to {fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2822180, 4)"
      ]
     },
     "execution_count": 990,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf = pd.read_csv('../submission-1625116622.csv')\n",
    "tdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "metadata": {},
   "outputs": [],
   "source": [
    "widx = test_df['watch_label'] != tdf['watch_label']\n",
    "sidx = test_df['is_share'] != tdf['is_share']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2104451, 1253446)"
      ]
     },
     "execution_count": 992,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "widx.sum(), sidx.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_wl.save_model('wl_model_v6')\n",
    "bst_sh.save_model('sh_model_v6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_log(log_name, info, log_path=\"./\"):\n",
    "    import datetime\n",
    "    with open(os.path.join(log_path, log_name), 'w') as log:\n",
    "        log.write(f\"# {datetime.datetime.now().__str__()}\\n\")\n",
    "        log.write(f\"\\n## model name: {info['model_name']}\\n\")\n",
    "        log.write(f\"- model save path : {info['model_save_path']}\\n\")\n",
    "        \n",
    "        log.write(f\"\\n## Data setup\\n\")\n",
    "        log.write(f\"- dataset.shape : {dataset.shape}\\n\")\n",
    "        log.write(f\"- dataset.columns : {dataset.columns}\\n\")\n",
    "        log.write(f\"- is resample : {info['is_resample']}\\n\")\n",
    "        log.write(f\"- Traing_Data.shape (watch_label)  : {X_train.shape}\\n\")\n",
    "        log.write(f\"- Testing_Data.shape (watch_label) : {X_test.shape}\\n\")\n",
    "        log.write(f\"- Traing_Data.shape (is_share)  : {X_train_sh.shape}\\n\")\n",
    "        log.write(f\"- Testing_Data.shape (is_share) : {X_test_sh.shape}\\n\")\n",
    "        if info.get('is_resample', False):\n",
    "            log.write(f\"- Resampled class distribution (watch_label): \\n{Counter(resampled_wl)}\\n\")\n",
    "            log.write(f\"- Resampled class distribution (is_share): \\n{Counter(resampled_sh)}\\n\")\n",
    "            \n",
    "        log.write(f\"\\n## Model Params\\n\")\n",
    "        log.write(f\"- model params (watch_label) : \\n{param}\\n\")\n",
    "        log.write(f\"- model params (is_share) : \\n{param_sh}\\n\")\n",
    "        \n",
    "        log.write(f\"\\n## Model's Performance\\n\")\n",
    "        log.write(f\"- Aucs (watch_label) : {aucs}\\n\")\n",
    "        log.write(f\"- Weighted Aucs (watch_label) : {w_aucs}\\n\")\n",
    "        log.write(f\"- Aucs (is_share) : {aucs_sh}\\n\")\n",
    "        \n",
    "        log.write(f\"- Classification Report (watch_label) : \\n\\n{report}\\n\")\n",
    "        log.write(f\"- Classification Report (is_share) : \\n\\n{report_sh}\\n\")\n",
    "        \n",
    "        log.flush()\n",
    "        \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_name = \"log_v6.md\"\n",
    "info = {'is_resample': True, 'model_name': ['wl_model_v6', 'sh_model_v6'], 'model_save_path': os.getcwd()}\n",
    "write_log(log_name, info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 服务器间同步文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推向Digix服务器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models.ipynb                                  100%  115KB   9.8MB/s   00:00    \n"
     ]
    }
   ],
   "source": [
    "!scp ./models.ipynb digix@49.123.120.71:/home/digix/digix/Models/models.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explore-data.ipynb                            100%  306KB  10.6MB/s   00:00    \n"
     ]
    }
   ],
   "source": [
    "!scp ../explore-data.ipynb digix@49.123.120.71:/home/digix/digix/explore-data.ipynb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从Digix服务器拉数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM.ipynb                                100%   71KB   9.0MB/s   00:00    \n"
     ]
    }
   ],
   "source": [
    "!scp  digix@49.123.120.71:/home/digix/digix/Models/LightGBM.ipynb ./LightGBM.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scp: /home/digix/digix/Models/feature_engineering.ipynb: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!scp  digix@49.123.120.71:/home/digix/digix/Models/feature_engineering.ipynb ./feature_engineering.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_analysis.ipynb                           100% 6493KB  11.2MB/s   00:00    \n",
      "data_analysis-checkpoint.ipynb                100% 6493KB  11.2MB/s   00:00    \n"
     ]
    }
   ],
   "source": [
    "!scp -r digix@49.123.120.71:/home/digix/digix/Models/Feature_Engineering/  ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
