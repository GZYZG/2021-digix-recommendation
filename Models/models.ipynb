{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "import datatable as dt\n",
    "import warnings\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 给定预测标签，计算AUC\n",
    "使用OVR的策略计算每个类别的AUC\n",
    "过程：\n",
    "- 选择类别i作为正类，其他类别作为负类\n",
    "- 将真实标签中不等于i的标记为0，等于i的标记为1\n",
    "- 将预测标签中不等于i的标记为0，等于ide标记为1\n",
    "- 计算混淆矩阵\n",
    "- 计算(fpr, tpr)\n",
    "- 计算AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据\n",
    "训练数据加载过程：\n",
    "1. 分别加载处理好的用户特征和视频特征，以及整合的用户历史行为数据；\n",
    "2. 从用户历史行为数据中筛掉在视频特征中没出现过的video_id；\n",
    "3. 将行为数据中的user_id、video_id替换为对应用户/视频的特征\n",
    "4. 根据不同的任务划分为`watch_label`、`is_share`的数据集\n",
    "\n",
    "推断时，类似于上述过程拼接数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"../2021_3_data\"\n",
    "test_data_dir  = os.path.join(base_dir, \"testdata\")\n",
    "train_data_dir = os.path.join(base_dir, \"traindata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基础特征与附加特征合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_status = dt.fread(os.path.join(train_data_dir, \"video_features_data/video_status.csv\"))\n",
    "user_status = dt.fread(os.path.join(train_data_dir, \"user_features_data/user_status.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_user = dt.fread(os.path.join(train_data_dir, \"user_features_data/user_features.jay\"))\n",
    "tab_video = dt.fread(os.path.join(train_data_dir, \"video_features_data/video_features.jay\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_status.key = 'video_id'\n",
    "video_ws = tab_video[:, :, join(video_status)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_status.key = 'user_id'\n",
    "user_ws = tab_user[:, :, join(user_status)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ws.to_jay(os.path.join(train_data_dir, \"video_features_data/video_features_with_status.jay\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ws.to_jay(os.path.join(train_data_dir, \"user_features_data/user_features_with_status.jay\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='datatable'>\n",
       "  <table class='frame'>\n",
       "  <thead>\n",
       "    <tr class='colnames'><td class='row_index'></td><th>user_id</th><th>age_0</th><th>age_1</th><th>age_2</th><th>age_3</th><th>age_4</th><th>age_5</th><th>age_6</th><th>age_7</th><th>gender_0</th><th class='vellipsis'>&hellip;</th><th>average_watch_label</th><th>sum_watch_times</th><th>sum_comment_times</th><th>sum_collect_times</th><th>sum_share_times</th></tr>\n",
       "    <tr class='coltypes'><td class='row_index'></td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td></td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><td class='row_index'>0</td><td>1.757e+06</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td class=vellipsis>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>1</td><td>17938</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td class=vellipsis>&hellip;</td><td>0.0967742</td><td>3</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>2</td><td>4.26352e+06</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td class=vellipsis>&hellip;</td><td>0.204545</td><td>2</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>3</td><td>1.4116e+06</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td class=vellipsis>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>4</td><td>3.99224e+06</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td class=vellipsis>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>5</td><td>4.0116e+06</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td class=vellipsis>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>6</td><td>4.78556e+06</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td class=vellipsis>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>7</td><td>5.11036e+06</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td class=vellipsis>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>8</td><td>1.3212e+06</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td class=vellipsis>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>9</td><td>3.20698e+06</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td class=vellipsis>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>10</td><td>5.18172e+06</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td class=vellipsis>&hellip;</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>11</td><td>1.878e+06</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td class=vellipsis>&hellip;</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>12</td><td>3.04464e+06</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td class=vellipsis>&hellip;</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>13</td><td>108273</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td class=vellipsis>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>14</td><td>5.64838e+06</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td class=vellipsis>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22F1;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td></tr>\n",
       "    <tr><td class='row_index'>5,910,795</td><td>3.22343e+06</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td class=vellipsis>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>5,910,796</td><td>4.70783e+06</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td class=vellipsis>&hellip;</td><td>0.142857</td><td>3</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>5,910,797</td><td>5.90765e+06</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td class=vellipsis>&hellip;</td><td>0</td><td>2</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>5,910,798</td><td>3.63322e+06</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td class=vellipsis>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>5,910,799</td><td>782537</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td class=vellipsis>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "  </tbody>\n",
       "  </table>\n",
       "  <div class='footer'>\n",
       "    <div class='frame_dimensions'>5,910,800 rows &times; 36 columns</div>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<Frame#7f315506be10 5910800x36>"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过 .npz 读取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 单表读取后合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.6 s, sys: 2.4 s, total: 6 s\n",
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 单独读取每个文件再进行合并\n",
    "user_df = read_npz_to_df(os.path.join(train_data_dir, \"user_features_data/user_features.npz\"), data_name='features', column_name='columns')\n",
    "video_df = read_npz_to_df(os.path.join(train_data_dir, \"video_features_data/video_features.npz\"), data_name='features')\n",
    "action_df = read_npz_to_df(os.path.join(train_data_dir, \"all_actions.npz\"), data_name='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因为将字符串保存到 .npz时会使dtype为object，重新读回DataFrame时各个列的数据类型均为 object，所以先转换类型\n",
    "dtypes = dict(zip(video_df.columns, [np.float32] * video_df.shape[1]))\n",
    "dtypes.update({'video_name': np.str})\n",
    "video_df = video_df.astype(dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 29s, sys: 5.88 s, total: 1min 35s\n",
      "Wall time: 40.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7353024, 76)"
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 合并各个表\n",
    "df_train = merge_user_video_action(user_df, video_df, action_df)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(os.path.join(train_data_dir, \"train.npz\"), data=df_train.to_pandas().values, columns=df_train.to_pandas().columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 626 ms, sys: 0 ns, total: 626 ms\n",
      "Wall time: 721 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_df = load_table(os.path.join(test_data_dir, \"test.csv\"), ftype=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 8s, sys: 12.8 s, total: 3min 20s\n",
      "Wall time: 51.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2822180, 73)"
      ]
     },
     "execution_count": 779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_test = merge_user_video_action(user_df, video_df, test_df)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取合并好的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 2s, sys: 38.4 s, total: 3min 40s\n",
      "Wall time: 3min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7353024, 76)"
      ]
     },
     "execution_count": 806,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 直接读取保存好的合并后的训练数据\n",
    "path = os.path.join(train_data_dir, \"train.npz\")\n",
    "df_train = read_npz_to_df(path, data_name='data')\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 37s, sys: 36.9 s, total: 2min 14s\n",
      "Wall time: 5min 49s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2822180, 73)"
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 直接读取保存好的合并后的测试数据\n",
    "path = os.path.join(test_data_dir, \"test.npz\")\n",
    "df_test = read_npz_to_df(path, data_name='data')\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过 .jay 文件读取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 单表读取后合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_status = False\n",
    "if with_status:\n",
    "    user_features_name = \"user_features_with_status\"\n",
    "    video_features_name = \"video_features_with_status\"\n",
    "else:\n",
    "    user_features_name = \"user_features\"\n",
    "    video_features_name = \"video_features\"\n",
    "    \n",
    "p_user = os.path.join(train_data_dir, f\"user_features_data/{user_features_name}.jay\")\n",
    "p_video = os.path.join(train_data_dir, f\"video_features_data/{video_features_name}.jay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.9 s, sys: 2.9 s, total: 33.8 s\n",
      "Wall time: 6.05 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7353024, 76)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "## 使用datatable 加载训练数据\n",
    "p_act = os.path.join(train_data_dir, \"all_actions.jay\")\n",
    "\n",
    "df_train, others = load_train_test_data(None, pre_merged=False, return_others=True,\n",
    "                           **{\"p_user\": p_user, \"p_video\": p_video, \"p_action\": p_act})\n",
    "user_df = others['user']\n",
    "video_df = others['video']\n",
    "action_df = others['action']\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = df_train.to_pandas()\n",
    "np.savez(os.path.join(train_data_dir, \"train\"), data=tt.values, columns=tt.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.8 s, sys: 1.07 s, total: 29.9 s\n",
      "Wall time: 1.73 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2822180, 73)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# p_user = os.path.join(train_data_dir, \"user_features_data/user_features.jay\")\n",
    "# p_video = os.path.join(train_data_dir, \"video_features_data/video_features.jay\")\n",
    "p_act = os.path.join(test_data_dir, \"test.csv\")\n",
    "\n",
    "path = os.path.join(test_data_dir, \"test.jay\")\n",
    "kwargs = {\"p_user\": p_user, \"p_video\": p_video, \"p_action\": p_act}\n",
    "\n",
    "df_test, others = load_train_test_data(None, pre_merged=False, return_others=True, **kwargs)\n",
    "test_df = others['action']\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'to_pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30693/319292494.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maction_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0muser_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvideo_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5463\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5464\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5465\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'to_pandas'"
     ]
    }
   ],
   "source": [
    "action_df = action_df.to_pandas()\n",
    "user_df = user_df.to_pandas()\n",
    "video_df = video_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'to_pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30693/4265749660.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5463\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5464\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5465\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'to_pandas'"
     ]
    }
   ],
   "source": [
    "test_df = test_df.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取合并好后的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 177 ms, total: 177 ms\n",
      "Wall time: 184 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7353024, 76)"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 直接读取保存好的合并后的训练数据\n",
    "path = os.path.join(train_data_dir, \"train.jay\")\n",
    "df_train = load_train_test_data(path, pre_merged=True)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 649 µs, sys: 46 µs, total: 695 µs\n",
      "Wall time: 684 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2822180, 72)"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 直接读取保存好的合并后的测试数据\n",
    "path = os.path.join(test_data_dir, \"test.jay\")\n",
    "df_test = load_train_test_data(path, pre_merged=True)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理训练数据\n",
    "可在此做一些预处理：\n",
    "- 从用户历史行为数据中筛掉在视频特征中没出现过的video_id\n",
    "- 删除多余的列\n",
    "- 调整列的顺序\n",
    "- 改变列的数据类型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.8 s, sys: 3.4 s, total: 27.2 s\n",
      "Wall time: 4.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if isinstance(df_train, dt.Frame):\n",
    "    df_train = df_train.to_pandas()\n",
    "if isinstance(df_test, dt.Frame):\n",
    "    df_test = df_test.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7353024 entries, 0 to 7353023\n",
      "Data columns (total 76 columns):\n",
      " #   Column               Dtype  \n",
      "---  ------               -----  \n",
      " 0   user_id              int64  \n",
      " 1   video_id             int64  \n",
      " 2   is_watch             int64  \n",
      " 3   is_share             int64  \n",
      " 4   watch_label          int64  \n",
      " 5   age_0                float64\n",
      " 6   age_1                float64\n",
      " 7   age_2                float64\n",
      " 8   age_3                float64\n",
      " 9   age_4                float64\n",
      " 10  age_5                float64\n",
      " 11  age_6                float64\n",
      " 12  age_7                float64\n",
      " 13  gender_0             float64\n",
      " 14  gender_1             float64\n",
      " 15  gender_2             float64\n",
      " 16  gender_3             float64\n",
      " 17  city_level_0         float64\n",
      " 18  city_level_1         float64\n",
      " 19  city_level_2         float64\n",
      " 20  city_level_3         float64\n",
      " 21  city_level_4         float64\n",
      " 22  city_level_5         float64\n",
      " 23  city_level_6         float64\n",
      " 24  city_level_7         float64\n",
      " 25  device_name_0        float64\n",
      " 26  device_name_1        float64\n",
      " 27  device_name_2        float64\n",
      " 28  device_name_3        float64\n",
      " 29  device_name_4        float64\n",
      " 30  device_name_5        float64\n",
      " 31  device_name_6        float64\n",
      " 32  device_name_7        float64\n",
      " 33  device_name_8        float64\n",
      " 34  device_name_9        float64\n",
      " 35  video_name           object \n",
      " 36  video_score          float32\n",
      " 37  video_duration       float32\n",
      " 38  video_release_year   float32\n",
      " 39  video_release_month  float32\n",
      " 40  video_release_day    float32\n",
      " 41  desc_0               float32\n",
      " 42  desc_1               float32\n",
      " 43  desc_2               float32\n",
      " 44  desc_3               float32\n",
      " 45  desc_4               float32\n",
      " 46  desc_5               float32\n",
      " 47  desc_6               float32\n",
      " 48  desc_7               float32\n",
      " 49  desc_8               float32\n",
      " 50  desc_9               float32\n",
      " 51  tags_0               float32\n",
      " 52  tags_1               float32\n",
      " 53  tags_2               float32\n",
      " 54  tags_3               float32\n",
      " 55  tags_4               float32\n",
      " 56  tags_5               float32\n",
      " 57  tags_6               float32\n",
      " 58  tags_7               float32\n",
      " 59  tags_8               float32\n",
      " 60  tags_9               float32\n",
      " 61  class_0              float32\n",
      " 62  class_1              float32\n",
      " 63  class_2              float32\n",
      " 64  class_3              float32\n",
      " 65  class_4              float32\n",
      " 66  class_5              float32\n",
      " 67  class_6              float32\n",
      " 68  class_7              float32\n",
      " 69  class_8              float32\n",
      " 70  class_9              float32\n",
      " 71  da_0                 float32\n",
      " 72  da_1                 float32\n",
      " 73  da_2                 float32\n",
      " 74  da_3                 float32\n",
      " 75  da_4                 float32\n",
      "dtypes: float32(40), float64(30), int64(5), object(1)\n",
      "memory usage: 3.1+ GB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除 video_name、is_watch 列\n",
    "df_train.drop(['video_name', 'is_watch'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'action_df' not in dir():\n",
    "    action_df = load_table(os.path.join(train_data_dir, \"all_actions.jay\")).to_pandas()\n",
    "if 'video_df' not in dir():\n",
    "    video_df = load_table(os.path.join(train_data_dir, \"video_features_data/video_features.jay\")).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7353024 entries, 0 to 7353023\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Dtype\n",
      "---  ------       -----\n",
      " 0   user_id      int64\n",
      " 1   video_id     int64\n",
      " 2   is_watch     int64\n",
      " 3   is_share     int64\n",
      " 4   watch_label  int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 280.5 MB\n"
     ]
    }
   ],
   "source": [
    "action_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([], dtype='int64')"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从用户历史行为数据中筛掉在视频特征中没出现过的video_id\n",
    "idx1 = pd.Index(action_df['video_id'].unique())\n",
    "idx2 = pd.Index(video_df['video_id'])\n",
    "not_exists = idx1.difference(idx2)\n",
    "not_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "CPU times: user 1.25 ms, sys: 0 ns, total: 1.25 ms\n",
      "Wall time: 1.07 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 将训练数据中未出现的视频剔除\n",
    "n = 0\n",
    "for vid in not_exists:\n",
    "    tn = (df_train['video_id'] == vid).sum()\n",
    "    df_train['video_id'].replace(vid, np.nan, inplace=True)\n",
    "    n += tn\n",
    "\n",
    "if n > 0:\n",
    "    df_train.dropna(axis=0, inplace=True)\n",
    "    df_train.reset_index(drop=True, inplace=True)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除 video_id、user_id列\n",
    "df_train.drop(['user_id', 'video_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7353024, 72)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df_train\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7353024,), (7353024,), (7353024, 70))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 准备数据\n",
    "watch_label = dataset.pop('watch_label').astype(np.uint8)\n",
    "is_share = dataset.pop('is_share').astype(np.uint8)\n",
    "watch_label.shape, is_share.shape, dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'test_df' not in dir():\n",
    "    test_df = pd.read_csv(os.path.join(test_data_dir, \"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2822180 entries, 0 to 2822179\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Dtype\n",
      "---  ------    -----\n",
      " 0   user_id   int32\n",
      " 1   video_id  int32\n",
      "dtypes: int32(2)\n",
      "memory usage: 21.5 MB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2822180 entries, 0 to 2822179\n",
      "Data columns (total 72 columns):\n",
      " #   Column               Dtype  \n",
      "---  ------               -----  \n",
      " 0   user_id              float32\n",
      " 1   video_id             float32\n",
      " 2   age_0                float32\n",
      " 3   age_1                float32\n",
      " 4   age_2                float32\n",
      " 5   age_3                float32\n",
      " 6   age_4                float32\n",
      " 7   age_5                float32\n",
      " 8   age_6                float32\n",
      " 9   age_7                float32\n",
      " 10  gender_0             float32\n",
      " 11  gender_1             float32\n",
      " 12  gender_2             float32\n",
      " 13  gender_3             float32\n",
      " 14  city_level_0         float32\n",
      " 15  city_level_1         float32\n",
      " 16  city_level_2         float32\n",
      " 17  city_level_3         float32\n",
      " 18  city_level_4         float32\n",
      " 19  city_level_5         float32\n",
      " 20  city_level_6         float32\n",
      " 21  city_level_7         float32\n",
      " 22  device_name_0        float32\n",
      " 23  device_name_1        float32\n",
      " 24  device_name_2        float32\n",
      " 25  device_name_3        float32\n",
      " 26  device_name_4        float32\n",
      " 27  device_name_5        float32\n",
      " 28  device_name_6        float32\n",
      " 29  device_name_7        float32\n",
      " 30  device_name_8        float32\n",
      " 31  device_name_9        float32\n",
      " 32  video_score          float32\n",
      " 33  video_duration       float32\n",
      " 34  video_release_year   float32\n",
      " 35  video_release_month  float32\n",
      " 36  video_release_day    float32\n",
      " 37  desc_0               float32\n",
      " 38  desc_1               float32\n",
      " 39  desc_2               float32\n",
      " 40  desc_3               float32\n",
      " 41  desc_4               float32\n",
      " 42  desc_5               float32\n",
      " 43  desc_6               float32\n",
      " 44  desc_7               float32\n",
      " 45  desc_8               float32\n",
      " 46  desc_9               float32\n",
      " 47  tags_0               float32\n",
      " 48  tags_1               float32\n",
      " 49  tags_2               float32\n",
      " 50  tags_3               float32\n",
      " 51  tags_4               float32\n",
      " 52  tags_5               float32\n",
      " 53  tags_6               float32\n",
      " 54  tags_7               float32\n",
      " 55  tags_8               float32\n",
      " 56  tags_9               float32\n",
      " 57  class_0              float32\n",
      " 58  class_1              float32\n",
      " 59  class_2              float32\n",
      " 60  class_3              float32\n",
      " 61  class_4              float32\n",
      " 62  class_5              float32\n",
      " 63  class_6              float32\n",
      " 64  class_7              float32\n",
      " 65  class_8              float32\n",
      " 66  class_9              float32\n",
      " 67  da_0                 float32\n",
      " 68  da_1                 float32\n",
      " 69  da_2                 float32\n",
      " 70  da_3                 float32\n",
      " 71  da_4                 float32\n",
      "dtypes: float32(72)\n",
      "memory usage: 775.1 MB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除 video_name 列\n",
    "if 'video_name' in df_test.columns:\n",
    "    df_test.drop('video_name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([], dtype='int64')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试数据集中存在video_id没有在视频特征中出现\n",
    "idx1 = pd.Index(test_df['video_id'].unique())\n",
    "idx2 = pd.Index(video_df['video_id'].unique())\n",
    "non_exists = idx1.difference(idx2)\n",
    "non_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在视频特征中不存在的video_id在测试数据集中出现的次数 = 0\t\t(cost 0.000s)\n",
      "CPU times: user 0 ns, sys: 430 µs, total: 430 µs\n",
      "Wall time: 390 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t0 = time()\n",
    "n = 0\n",
    "for vid in not_exists:\n",
    "    tn = (test_df['video_id'] == vid).sum()\n",
    "#     df_test = action_df[action_df['video_id'] != vid]\n",
    "    n += tn\n",
    "\n",
    "print(f\"在视频特征中不存在的video_id在测试数据集中出现的次数 = {n}\\t\\t(cost {time() - t0:.3f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除 video_id、user_id 列\n",
    "df_test.drop(['user_id', 'video_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2822180, 70)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_dataset = df_test\n",
    "inference_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# watch_label 预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理数据不均衡问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 5176743), (1, 557421), (2, 314107), (3, 219188), (4, 172404), (5, 143001), (6, 125092), (7, 117749), (8, 138798), (9, 388521)]\n",
      "[[0.         0.70402912]\n",
      " [1.         0.0758084 ]\n",
      " [2.         0.04271807]\n",
      " [3.         0.02980923]\n",
      " [4.         0.02344668]\n",
      " [5.         0.01944792]\n",
      " [6.         0.01701232]\n",
      " [7.         0.01601368]\n",
      " [8.         0.01887632]\n",
      " [9.         0.05283826]]\n"
     ]
    }
   ],
   "source": [
    "items = list(Counter(watch_label).items())\n",
    "items.sort(key=lambda x: x[0])\n",
    "print(items)\n",
    "\n",
    "dist = np.array(items, dtype=np.float)\n",
    "dist[:, 1] = dist[:, 1] / watch_label.shape[0]\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_ss = np.array(items)\n",
    "under_ss_thresh = under_ss[3, 1]  # 设置每个类别样本数目的上限\n",
    "under_ss[:, 1] = np.clip(under_ss[:, 1], a_min=None, a_max=under_ss_thresh)\n",
    "\n",
    "over_ss = under_ss.copy()\n",
    "over_ss_thresh = under_ss[2, 1]  # 设置每个类别样本数据的下限\n",
    "over_ss[:, 1] = np.clip(over_ss[:, 1], a_min=over_ss_thresh, a_max=None)\n",
    "\n",
    "under_ss = dict(under_ss)\n",
    "over_ss = dict(over_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 219188,\n",
       "  1: 219188,\n",
       "  2: 219188,\n",
       "  3: 219188,\n",
       "  4: 172404,\n",
       "  5: 143001,\n",
       "  6: 125092,\n",
       "  7: 117749,\n",
       "  8: 138798,\n",
       "  9: 219188},\n",
       " {0: 219188,\n",
       "  1: 219188,\n",
       "  2: 219188,\n",
       "  3: 219188,\n",
       "  4: 219188,\n",
       "  5: 219188,\n",
       "  6: 219188,\n",
       "  7: 219188,\n",
       "  8: 219188,\n",
       "  9: 219188})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_ss, over_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5176743,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = watch_label == 0\n",
    "idxs = idxs.replace(False, np.nan).dropna().index  # 保留watch_label=0的行索引\n",
    "idxs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4957555,), (219188,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_idxs = np.random.choice(idxs, under_ss_thresh, replace=False)  # 选择一部分保留，注意replace参数，为True时会重复采样\n",
    "del_idxs = idxs.difference(left_idxs)\n",
    "del_idxs.shape, left_idxs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 314107,\n",
       "         0: 5176743,\n",
       "         5: 143001,\n",
       "         4: 172404,\n",
       "         1: 557421,\n",
       "         9: 388521,\n",
       "         3: 219188,\n",
       "         8: 138798,\n",
       "         7: 117749,\n",
       "         6: 125092})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(watch_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2395469, 70), (2395469,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_data = np.delete(dataset.values, del_idxs, axis=0)\n",
    "resampled_wl = np.delete(watch_label.values, del_idxs, axis=0)\n",
    "resampled_data.shape, resampled_wl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 314107,\n",
       "         0: 219188,\n",
       "         5: 143001,\n",
       "         4: 172404,\n",
       "         1: 557421,\n",
       "         9: 388521,\n",
       "         3: 219188,\n",
       "         8: 138798,\n",
       "         7: 117749,\n",
       "         6: 125092})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(resampled_wl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 速度太慢，难以忍受！\n",
    "nm  = TomekLinks(sampling_strategy=under_ss)\n",
    "smt = SMOTE(sampling_strategy=over_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "X_r, y_r = nm.fit_resample(resampled_data, pd.Series(resampled_wl))\n",
    "print(f\"Under Sampling finished ...\\t\\t({time()-t0:.3f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_r, y_r = smt.fit_resample(X_r, y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2395469, 70), (2395469,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将采样后的数据重装回 DataFrame\n",
    "data = pd.DataFrame(resampled_data, columns=dataset.columns)\n",
    "watch_label_res = pd.Series(resampled_wl)\n",
    "data.shape, watch_label_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1916375,), (479094,))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx, test_idx = train_test_split(data.index, test_size=0.2, random_state=0)\n",
    "train_idx.shape, test_idx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.iloc[train_idx]\n",
    "X_test  = data.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = watch_label_res.iloc[train_idx]\n",
    "y_test  = watch_label_res.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1916375, 70), (1916375,), (479094, 70), (479094,))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparing finished ...\t\t(1.579s)\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "xg_train = xgb.DMatrix(X_train.values, label=y_train.values, enable_categorical=True)\n",
    "xg_test = xgb.DMatrix(X_test.values, label=y_test.values, enable_categorical=True)\n",
    "print(f\"Data preparing finished ...\\t\\t({time()-t0:.3f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup parameters for xgboost\n",
    "param = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'eta': 0.1,\n",
    "    'nthread': 8,\n",
    "    'num_class': 10,\n",
    "    'gpu_id': 0,\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'eval_metric': ['mlogloss', 'auc', 'merror'],\n",
    "    'max_depth': 9,\n",
    "    'min_child_weight': 9,\n",
    "    'gamma': 0.2,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'reg_alpha': 0\n",
    "}\n",
    "# use softmax multi-class classification\n",
    "# param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "# param['eta'] = 0.1\n",
    "# param['max_depth'] = 11\n",
    "# param['min_child_weight'] = 7\n",
    "# param['nthread'] = 8\n",
    "# param['num_class'] = 10\n",
    "# param['gamma'] = .4\n",
    "# param['gpu_id'] = 0\n",
    "# param['tree_method'] = 'gpu_hist'\n",
    "# param['eval_metric'] = ['mlogloss', 'auc', 'merror']\n",
    "\n",
    "# param['scale_pos_weight'] = 2\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.27520\ttrain-auc:0.59790\ttrain-merror:0.74007\ttest-mlogloss:2.27556\ttest-auc:0.59217\ttest-merror:0.74108\n",
      "[1]\ttrain-mlogloss:2.25244\ttrain-auc:0.60582\ttrain-merror:0.73830\ttest-mlogloss:2.25308\ttest-auc:0.59852\ttest-merror:0.73967\n",
      "[2]\ttrain-mlogloss:2.23305\ttrain-auc:0.60837\ttrain-merror:0.73741\ttest-mlogloss:2.23401\ttest-auc:0.60040\ttest-merror:0.73867\n",
      "[3]\ttrain-mlogloss:2.21664\ttrain-auc:0.61043\ttrain-merror:0.73728\ttest-mlogloss:2.21788\ttest-auc:0.60182\ttest-merror:0.73829\n",
      "[4]\ttrain-mlogloss:2.20232\ttrain-auc:0.61191\ttrain-merror:0.73714\ttest-mlogloss:2.20384\ttest-auc:0.60281\ttest-merror:0.73815\n",
      "[5]\ttrain-mlogloss:2.18972\ttrain-auc:0.61318\ttrain-merror:0.73684\ttest-mlogloss:2.19151\ttest-auc:0.60366\ttest-merror:0.73808\n",
      "[6]\ttrain-mlogloss:2.17870\ttrain-auc:0.61417\ttrain-merror:0.73628\ttest-mlogloss:2.18076\ttest-auc:0.60423\ttest-merror:0.73756\n",
      "[7]\ttrain-mlogloss:2.16885\ttrain-auc:0.61520\ttrain-merror:0.73611\ttest-mlogloss:2.17121\ttest-auc:0.60475\ttest-merror:0.73749\n",
      "[8]\ttrain-mlogloss:2.16016\ttrain-auc:0.61606\ttrain-merror:0.73590\ttest-mlogloss:2.16279\ttest-auc:0.60520\ttest-merror:0.73730\n",
      "[9]\ttrain-mlogloss:2.15246\ttrain-auc:0.61680\ttrain-merror:0.73572\ttest-mlogloss:2.15538\ttest-auc:0.60556\ttest-merror:0.73727\n",
      "[10]\ttrain-mlogloss:2.14557\ttrain-auc:0.61745\ttrain-merror:0.73549\ttest-mlogloss:2.14873\ttest-auc:0.60598\ttest-merror:0.73713\n",
      "[11]\ttrain-mlogloss:2.13942\ttrain-auc:0.61799\ttrain-merror:0.73529\ttest-mlogloss:2.14287\ttest-auc:0.60620\ttest-merror:0.73703\n",
      "[12]\ttrain-mlogloss:2.13389\ttrain-auc:0.61849\ttrain-merror:0.73533\ttest-mlogloss:2.13761\ttest-auc:0.60645\ttest-merror:0.73701\n",
      "[13]\ttrain-mlogloss:2.12886\ttrain-auc:0.61904\ttrain-merror:0.73500\ttest-mlogloss:2.13285\ttest-auc:0.60679\ttest-merror:0.73671\n",
      "[14]\ttrain-mlogloss:2.12433\ttrain-auc:0.61968\ttrain-merror:0.73478\ttest-mlogloss:2.12860\ttest-auc:0.60710\ttest-merror:0.73648\n",
      "[15]\ttrain-mlogloss:2.12026\ttrain-auc:0.62023\ttrain-merror:0.73452\ttest-mlogloss:2.12481\ttest-auc:0.60737\ttest-merror:0.73638\n",
      "[16]\ttrain-mlogloss:2.11657\ttrain-auc:0.62075\ttrain-merror:0.73420\ttest-mlogloss:2.12138\ttest-auc:0.60761\ttest-merror:0.73608\n",
      "[17]\ttrain-mlogloss:2.11317\ttrain-auc:0.62129\ttrain-merror:0.73386\ttest-mlogloss:2.11826\ttest-auc:0.60781\ttest-merror:0.73588\n",
      "[18]\ttrain-mlogloss:2.11012\ttrain-auc:0.62184\ttrain-merror:0.73354\ttest-mlogloss:2.11549\ttest-auc:0.60804\ttest-merror:0.73566\n",
      "[19]\ttrain-mlogloss:2.10734\ttrain-auc:0.62222\ttrain-merror:0.73337\ttest-mlogloss:2.11300\ttest-auc:0.60816\ttest-merror:0.73547\n",
      "[20]\ttrain-mlogloss:2.10474\ttrain-auc:0.62268\ttrain-merror:0.73325\ttest-mlogloss:2.11070\ttest-auc:0.60830\ttest-merror:0.73527\n",
      "[21]\ttrain-mlogloss:2.10239\ttrain-auc:0.62315\ttrain-merror:0.73298\ttest-mlogloss:2.10865\ttest-auc:0.60843\ttest-merror:0.73503\n",
      "[22]\ttrain-mlogloss:2.10026\ttrain-auc:0.62357\ttrain-merror:0.73291\ttest-mlogloss:2.10678\ttest-auc:0.60858\ttest-merror:0.73501\n",
      "[23]\ttrain-mlogloss:2.09827\ttrain-auc:0.62395\ttrain-merror:0.73277\ttest-mlogloss:2.10507\ttest-auc:0.60875\ttest-merror:0.73489\n",
      "[24]\ttrain-mlogloss:2.09644\ttrain-auc:0.62442\ttrain-merror:0.73257\ttest-mlogloss:2.10356\ttest-auc:0.60886\ttest-merror:0.73475\n",
      "[25]\ttrain-mlogloss:2.09477\ttrain-auc:0.62489\ttrain-merror:0.73250\ttest-mlogloss:2.10218\ttest-auc:0.60901\ttest-merror:0.73466\n",
      "[26]\ttrain-mlogloss:2.09328\ttrain-auc:0.62526\ttrain-merror:0.73245\ttest-mlogloss:2.10096\ttest-auc:0.60912\ttest-merror:0.73465\n",
      "[27]\ttrain-mlogloss:2.09181\ttrain-auc:0.62569\ttrain-merror:0.73230\ttest-mlogloss:2.09976\ttest-auc:0.60931\ttest-merror:0.73453\n",
      "[28]\ttrain-mlogloss:2.09048\ttrain-auc:0.62605\ttrain-merror:0.73223\ttest-mlogloss:2.09869\ttest-auc:0.60945\ttest-merror:0.73452\n",
      "[29]\ttrain-mlogloss:2.08925\ttrain-auc:0.62645\ttrain-merror:0.73203\ttest-mlogloss:2.09776\ttest-auc:0.60956\ttest-merror:0.73437\n",
      "[30]\ttrain-mlogloss:2.08808\ttrain-auc:0.62683\ttrain-merror:0.73185\ttest-mlogloss:2.09686\ttest-auc:0.60968\ttest-merror:0.73431\n",
      "[31]\ttrain-mlogloss:2.08699\ttrain-auc:0.62718\ttrain-merror:0.73176\ttest-mlogloss:2.09606\ttest-auc:0.60979\ttest-merror:0.73420\n",
      "[32]\ttrain-mlogloss:2.08592\ttrain-auc:0.62757\ttrain-merror:0.73157\ttest-mlogloss:2.09526\ttest-auc:0.60993\ttest-merror:0.73413\n",
      "[33]\ttrain-mlogloss:2.08499\ttrain-auc:0.62787\ttrain-merror:0.73146\ttest-mlogloss:2.09460\ttest-auc:0.61000\ttest-merror:0.73406\n",
      "[34]\ttrain-mlogloss:2.08407\ttrain-auc:0.62825\ttrain-merror:0.73136\ttest-mlogloss:2.09396\ttest-auc:0.61011\ttest-merror:0.73398\n",
      "[35]\ttrain-mlogloss:2.08320\ttrain-auc:0.62865\ttrain-merror:0.73118\ttest-mlogloss:2.09338\ttest-auc:0.61024\ttest-merror:0.73384\n",
      "[36]\ttrain-mlogloss:2.08237\ttrain-auc:0.62899\ttrain-merror:0.73100\ttest-mlogloss:2.09280\ttest-auc:0.61034\ttest-merror:0.73383\n",
      "[37]\ttrain-mlogloss:2.08160\ttrain-auc:0.62932\ttrain-merror:0.73092\ttest-mlogloss:2.09232\ttest-auc:0.61040\ttest-merror:0.73374\n",
      "[38]\ttrain-mlogloss:2.08085\ttrain-auc:0.62970\ttrain-merror:0.73075\ttest-mlogloss:2.09186\ttest-auc:0.61050\ttest-merror:0.73366\n",
      "[39]\ttrain-mlogloss:2.08013\ttrain-auc:0.63004\ttrain-merror:0.73059\ttest-mlogloss:2.09141\ttest-auc:0.61060\ttest-merror:0.73352\n",
      "[40]\ttrain-mlogloss:2.07942\ttrain-auc:0.63041\ttrain-merror:0.73041\ttest-mlogloss:2.09098\ttest-auc:0.61069\ttest-merror:0.73343\n",
      "[41]\ttrain-mlogloss:2.07877\ttrain-auc:0.63072\ttrain-merror:0.73024\ttest-mlogloss:2.09060\ttest-auc:0.61077\ttest-merror:0.73332\n",
      "[42]\ttrain-mlogloss:2.07816\ttrain-auc:0.63108\ttrain-merror:0.73012\ttest-mlogloss:2.09028\ttest-auc:0.61084\ttest-merror:0.73328\n",
      "[43]\ttrain-mlogloss:2.07746\ttrain-auc:0.63150\ttrain-merror:0.72996\ttest-mlogloss:2.08985\ttest-auc:0.61099\ttest-merror:0.73315\n",
      "[44]\ttrain-mlogloss:2.07687\ttrain-auc:0.63188\ttrain-merror:0.72983\ttest-mlogloss:2.08955\ttest-auc:0.61108\ttest-merror:0.73311\n",
      "[45]\ttrain-mlogloss:2.07629\ttrain-auc:0.63226\ttrain-merror:0.72966\ttest-mlogloss:2.08927\ttest-auc:0.61116\ttest-merror:0.73309\n",
      "[46]\ttrain-mlogloss:2.07573\ttrain-auc:0.63259\ttrain-merror:0.72954\ttest-mlogloss:2.08897\ttest-auc:0.61127\ttest-merror:0.73304\n",
      "[47]\ttrain-mlogloss:2.07517\ttrain-auc:0.63292\ttrain-merror:0.72947\ttest-mlogloss:2.08867\ttest-auc:0.61139\ttest-merror:0.73301\n",
      "[48]\ttrain-mlogloss:2.07469\ttrain-auc:0.63325\ttrain-merror:0.72940\ttest-mlogloss:2.08845\ttest-auc:0.61144\ttest-merror:0.73295\n",
      "[49]\ttrain-mlogloss:2.07423\ttrain-auc:0.63357\ttrain-merror:0.72934\ttest-mlogloss:2.08827\ttest-auc:0.61148\ttest-merror:0.73292\n",
      "[50]\ttrain-mlogloss:2.07368\ttrain-auc:0.63396\ttrain-merror:0.72918\ttest-mlogloss:2.08801\ttest-auc:0.61157\ttest-merror:0.73282\n",
      "[51]\ttrain-mlogloss:2.07321\ttrain-auc:0.63431\ttrain-merror:0.72907\ttest-mlogloss:2.08783\ttest-auc:0.61162\ttest-merror:0.73277\n",
      "[52]\ttrain-mlogloss:2.07272\ttrain-auc:0.63467\ttrain-merror:0.72896\ttest-mlogloss:2.08761\ttest-auc:0.61170\ttest-merror:0.73271\n",
      "[53]\ttrain-mlogloss:2.07222\ttrain-auc:0.63504\ttrain-merror:0.72883\ttest-mlogloss:2.08740\ttest-auc:0.61179\ttest-merror:0.73267\n",
      "[54]\ttrain-mlogloss:2.07178\ttrain-auc:0.63539\ttrain-merror:0.72872\ttest-mlogloss:2.08722\ttest-auc:0.61184\ttest-merror:0.73261\n",
      "[55]\ttrain-mlogloss:2.07131\ttrain-auc:0.63572\ttrain-merror:0.72862\ttest-mlogloss:2.08700\ttest-auc:0.61193\ttest-merror:0.73255\n",
      "[56]\ttrain-mlogloss:2.07089\ttrain-auc:0.63602\ttrain-merror:0.72858\ttest-mlogloss:2.08685\ttest-auc:0.61198\ttest-merror:0.73251\n",
      "[57]\ttrain-mlogloss:2.07050\ttrain-auc:0.63632\ttrain-merror:0.72849\ttest-mlogloss:2.08675\ttest-auc:0.61199\ttest-merror:0.73245\n",
      "[58]\ttrain-mlogloss:2.07007\ttrain-auc:0.63667\ttrain-merror:0.72840\ttest-mlogloss:2.08660\ttest-auc:0.61203\ttest-merror:0.73239\n",
      "[59]\ttrain-mlogloss:2.06968\ttrain-auc:0.63696\ttrain-merror:0.72830\ttest-mlogloss:2.08649\ttest-auc:0.61208\ttest-merror:0.73240\n",
      "[60]\ttrain-mlogloss:2.06928\ttrain-auc:0.63727\ttrain-merror:0.72819\ttest-mlogloss:2.08635\ttest-auc:0.61212\ttest-merror:0.73240\n",
      "[61]\ttrain-mlogloss:2.06890\ttrain-auc:0.63759\ttrain-merror:0.72807\ttest-mlogloss:2.08627\ttest-auc:0.61213\ttest-merror:0.73243\n",
      "[62]\ttrain-mlogloss:2.06854\ttrain-auc:0.63792\ttrain-merror:0.72802\ttest-mlogloss:2.08617\ttest-auc:0.61219\ttest-merror:0.73233\n",
      "[63]\ttrain-mlogloss:2.06815\ttrain-auc:0.63826\ttrain-merror:0.72785\ttest-mlogloss:2.08608\ttest-auc:0.61222\ttest-merror:0.73225\n",
      "[64]\ttrain-mlogloss:2.06781\ttrain-auc:0.63853\ttrain-merror:0.72778\ttest-mlogloss:2.08598\ttest-auc:0.61225\ttest-merror:0.73233\n",
      "[65]\ttrain-mlogloss:2.06745\ttrain-auc:0.63883\ttrain-merror:0.72767\ttest-mlogloss:2.08588\ttest-auc:0.61228\ttest-merror:0.73228\n",
      "[66]\ttrain-mlogloss:2.06705\ttrain-auc:0.63915\ttrain-merror:0.72756\ttest-mlogloss:2.08578\ttest-auc:0.61232\ttest-merror:0.73224\n",
      "[67]\ttrain-mlogloss:2.06668\ttrain-auc:0.63941\ttrain-merror:0.72752\ttest-mlogloss:2.08565\ttest-auc:0.61237\ttest-merror:0.73221\n",
      "[68]\ttrain-mlogloss:2.06630\ttrain-auc:0.63974\ttrain-merror:0.72742\ttest-mlogloss:2.08556\ttest-auc:0.61240\ttest-merror:0.73213\n",
      "[69]\ttrain-mlogloss:2.06589\ttrain-auc:0.64007\ttrain-merror:0.72730\ttest-mlogloss:2.08543\ttest-auc:0.61246\ttest-merror:0.73207\n",
      "[70]\ttrain-mlogloss:2.06554\ttrain-auc:0.64036\ttrain-merror:0.72720\ttest-mlogloss:2.08531\ttest-auc:0.61252\ttest-merror:0.73196\n",
      "[71]\ttrain-mlogloss:2.06519\ttrain-auc:0.64066\ttrain-merror:0.72714\ttest-mlogloss:2.08522\ttest-auc:0.61256\ttest-merror:0.73198\n",
      "[72]\ttrain-mlogloss:2.06487\ttrain-auc:0.64096\ttrain-merror:0.72701\ttest-mlogloss:2.08516\ttest-auc:0.61258\ttest-merror:0.73190\n",
      "[73]\ttrain-mlogloss:2.06450\ttrain-auc:0.64133\ttrain-merror:0.72688\ttest-mlogloss:2.08507\ttest-auc:0.61261\ttest-merror:0.73193\n",
      "[74]\ttrain-mlogloss:2.06416\ttrain-auc:0.64163\ttrain-merror:0.72675\ttest-mlogloss:2.08500\ttest-auc:0.61265\ttest-merror:0.73190\n",
      "[75]\ttrain-mlogloss:2.06383\ttrain-auc:0.64196\ttrain-merror:0.72662\ttest-mlogloss:2.08494\ttest-auc:0.61268\ttest-merror:0.73186\n",
      "[76]\ttrain-mlogloss:2.06349\ttrain-auc:0.64224\ttrain-merror:0.72653\ttest-mlogloss:2.08486\ttest-auc:0.61273\ttest-merror:0.73180\n",
      "[77]\ttrain-mlogloss:2.06321\ttrain-auc:0.64247\ttrain-merror:0.72645\ttest-mlogloss:2.08478\ttest-auc:0.61279\ttest-merror:0.73174\n",
      "[78]\ttrain-mlogloss:2.06290\ttrain-auc:0.64273\ttrain-merror:0.72633\ttest-mlogloss:2.08470\ttest-auc:0.61282\ttest-merror:0.73175\n",
      "[79]\ttrain-mlogloss:2.06259\ttrain-auc:0.64299\ttrain-merror:0.72630\ttest-mlogloss:2.08462\ttest-auc:0.61287\ttest-merror:0.73176\n",
      "[80]\ttrain-mlogloss:2.06226\ttrain-auc:0.64328\ttrain-merror:0.72622\ttest-mlogloss:2.08453\ttest-auc:0.61291\ttest-merror:0.73170\n",
      "[81]\ttrain-mlogloss:2.06190\ttrain-auc:0.64355\ttrain-merror:0.72607\ttest-mlogloss:2.08442\ttest-auc:0.61297\ttest-merror:0.73165\n",
      "[82]\ttrain-mlogloss:2.06155\ttrain-auc:0.64389\ttrain-merror:0.72599\ttest-mlogloss:2.08433\ttest-auc:0.61302\ttest-merror:0.73159\n",
      "[83]\ttrain-mlogloss:2.06124\ttrain-auc:0.64416\ttrain-merror:0.72583\ttest-mlogloss:2.08427\ttest-auc:0.61306\ttest-merror:0.73157\n",
      "[84]\ttrain-mlogloss:2.06094\ttrain-auc:0.64447\ttrain-merror:0.72573\ttest-mlogloss:2.08423\ttest-auc:0.61308\ttest-merror:0.73157\n",
      "[85]\ttrain-mlogloss:2.06064\ttrain-auc:0.64470\ttrain-merror:0.72567\ttest-mlogloss:2.08416\ttest-auc:0.61311\ttest-merror:0.73154\n",
      "[86]\ttrain-mlogloss:2.06034\ttrain-auc:0.64496\ttrain-merror:0.72560\ttest-mlogloss:2.08410\ttest-auc:0.61315\ttest-merror:0.73148\n",
      "[87]\ttrain-mlogloss:2.06005\ttrain-auc:0.64521\ttrain-merror:0.72553\ttest-mlogloss:2.08405\ttest-auc:0.61318\ttest-merror:0.73149\n",
      "[88]\ttrain-mlogloss:2.05979\ttrain-auc:0.64543\ttrain-merror:0.72542\ttest-mlogloss:2.08399\ttest-auc:0.61321\ttest-merror:0.73145\n",
      "[89]\ttrain-mlogloss:2.05952\ttrain-auc:0.64567\ttrain-merror:0.72534\ttest-mlogloss:2.08394\ttest-auc:0.61323\ttest-merror:0.73130\n",
      "[90]\ttrain-mlogloss:2.05922\ttrain-auc:0.64591\ttrain-merror:0.72526\ttest-mlogloss:2.08387\ttest-auc:0.61326\ttest-merror:0.73128\n",
      "[91]\ttrain-mlogloss:2.05890\ttrain-auc:0.64621\ttrain-merror:0.72510\ttest-mlogloss:2.08382\ttest-auc:0.61330\ttest-merror:0.73118\n",
      "[92]\ttrain-mlogloss:2.05866\ttrain-auc:0.64640\ttrain-merror:0.72505\ttest-mlogloss:2.08377\ttest-auc:0.61333\ttest-merror:0.73116\n",
      "[93]\ttrain-mlogloss:2.05834\ttrain-auc:0.64669\ttrain-merror:0.72498\ttest-mlogloss:2.08367\ttest-auc:0.61339\ttest-merror:0.73108\n",
      "[94]\ttrain-mlogloss:2.05805\ttrain-auc:0.64694\ttrain-merror:0.72488\ttest-mlogloss:2.08363\ttest-auc:0.61342\ttest-merror:0.73101\n",
      "[95]\ttrain-mlogloss:2.05774\ttrain-auc:0.64720\ttrain-merror:0.72477\ttest-mlogloss:2.08355\ttest-auc:0.61346\ttest-merror:0.73095\n",
      "[96]\ttrain-mlogloss:2.05741\ttrain-auc:0.64749\ttrain-merror:0.72471\ttest-mlogloss:2.08349\ttest-auc:0.61349\ttest-merror:0.73094\n",
      "[97]\ttrain-mlogloss:2.05711\ttrain-auc:0.64776\ttrain-merror:0.72458\ttest-mlogloss:2.08343\ttest-auc:0.61352\ttest-merror:0.73097\n",
      "[98]\ttrain-mlogloss:2.05680\ttrain-auc:0.64804\ttrain-merror:0.72448\ttest-mlogloss:2.08338\ttest-auc:0.61355\ttest-merror:0.73093\n",
      "[99]\ttrain-mlogloss:2.05652\ttrain-auc:0.64824\ttrain-merror:0.72435\ttest-mlogloss:2.08330\ttest-auc:0.61360\ttest-merror:0.73088\n",
      "[100]\ttrain-mlogloss:2.05625\ttrain-auc:0.64848\ttrain-merror:0.72428\ttest-mlogloss:2.08325\ttest-auc:0.61363\ttest-merror:0.73091\n",
      "[101]\ttrain-mlogloss:2.05601\ttrain-auc:0.64868\ttrain-merror:0.72419\ttest-mlogloss:2.08320\ttest-auc:0.61365\ttest-merror:0.73084\n",
      "[102]\ttrain-mlogloss:2.05576\ttrain-auc:0.64888\ttrain-merror:0.72413\ttest-mlogloss:2.08314\ttest-auc:0.61369\ttest-merror:0.73085\n",
      "[103]\ttrain-mlogloss:2.05546\ttrain-auc:0.64913\ttrain-merror:0.72401\ttest-mlogloss:2.08310\ttest-auc:0.61370\ttest-merror:0.73078\n",
      "[104]\ttrain-mlogloss:2.05522\ttrain-auc:0.64935\ttrain-merror:0.72394\ttest-mlogloss:2.08309\ttest-auc:0.61372\ttest-merror:0.73074\n",
      "[105]\ttrain-mlogloss:2.05496\ttrain-auc:0.64957\ttrain-merror:0.72387\ttest-mlogloss:2.08303\ttest-auc:0.61376\ttest-merror:0.73071\n",
      "[106]\ttrain-mlogloss:2.05470\ttrain-auc:0.64978\ttrain-merror:0.72381\ttest-mlogloss:2.08299\ttest-auc:0.61378\ttest-merror:0.73067\n",
      "[107]\ttrain-mlogloss:2.05442\ttrain-auc:0.65001\ttrain-merror:0.72368\ttest-mlogloss:2.08295\ttest-auc:0.61380\ttest-merror:0.73063\n",
      "[108]\ttrain-mlogloss:2.05417\ttrain-auc:0.65023\ttrain-merror:0.72357\ttest-mlogloss:2.08291\ttest-auc:0.61382\ttest-merror:0.73065\n",
      "[109]\ttrain-mlogloss:2.05392\ttrain-auc:0.65043\ttrain-merror:0.72352\ttest-mlogloss:2.08287\ttest-auc:0.61385\ttest-merror:0.73068\n",
      "[110]\ttrain-mlogloss:2.05364\ttrain-auc:0.65065\ttrain-merror:0.72345\ttest-mlogloss:2.08283\ttest-auc:0.61387\ttest-merror:0.73063\n",
      "[111]\ttrain-mlogloss:2.05337\ttrain-auc:0.65088\ttrain-merror:0.72336\ttest-mlogloss:2.08281\ttest-auc:0.61387\ttest-merror:0.73055\n",
      "[112]\ttrain-mlogloss:2.05312\ttrain-auc:0.65109\ttrain-merror:0.72329\ttest-mlogloss:2.08277\ttest-auc:0.61389\ttest-merror:0.73052\n",
      "[113]\ttrain-mlogloss:2.05286\ttrain-auc:0.65130\ttrain-merror:0.72322\ttest-mlogloss:2.08273\ttest-auc:0.61391\ttest-merror:0.73052\n",
      "[114]\ttrain-mlogloss:2.05265\ttrain-auc:0.65149\ttrain-merror:0.72316\ttest-mlogloss:2.08270\ttest-auc:0.61394\ttest-merror:0.73051\n",
      "[115]\ttrain-mlogloss:2.05243\ttrain-auc:0.65165\ttrain-merror:0.72304\ttest-mlogloss:2.08267\ttest-auc:0.61396\ttest-merror:0.73050\n",
      "[116]\ttrain-mlogloss:2.05216\ttrain-auc:0.65189\ttrain-merror:0.72295\ttest-mlogloss:2.08262\ttest-auc:0.61398\ttest-merror:0.73044\n",
      "[117]\ttrain-mlogloss:2.05191\ttrain-auc:0.65210\ttrain-merror:0.72286\ttest-mlogloss:2.08259\ttest-auc:0.61400\ttest-merror:0.73042\n",
      "[118]\ttrain-mlogloss:2.05168\ttrain-auc:0.65228\ttrain-merror:0.72279\ttest-mlogloss:2.08256\ttest-auc:0.61403\ttest-merror:0.73037\n",
      "[119]\ttrain-mlogloss:2.05145\ttrain-auc:0.65247\ttrain-merror:0.72272\ttest-mlogloss:2.08253\ttest-auc:0.61404\ttest-merror:0.73032\n",
      "[120]\ttrain-mlogloss:2.05121\ttrain-auc:0.65268\ttrain-merror:0.72265\ttest-mlogloss:2.08251\ttest-auc:0.61404\ttest-merror:0.73028\n",
      "[121]\ttrain-mlogloss:2.05100\ttrain-auc:0.65285\ttrain-merror:0.72257\ttest-mlogloss:2.08249\ttest-auc:0.61405\ttest-merror:0.73034\n",
      "[122]\ttrain-mlogloss:2.05072\ttrain-auc:0.65309\ttrain-merror:0.72247\ttest-mlogloss:2.08244\ttest-auc:0.61407\ttest-merror:0.73032\n",
      "[123]\ttrain-mlogloss:2.05053\ttrain-auc:0.65324\ttrain-merror:0.72242\ttest-mlogloss:2.08243\ttest-auc:0.61406\ttest-merror:0.73028\n",
      "[124]\ttrain-mlogloss:2.05027\ttrain-auc:0.65347\ttrain-merror:0.72231\ttest-mlogloss:2.08240\ttest-auc:0.61408\ttest-merror:0.73028\n",
      "[125]\ttrain-mlogloss:2.05004\ttrain-auc:0.65364\ttrain-merror:0.72225\ttest-mlogloss:2.08236\ttest-auc:0.61410\ttest-merror:0.73027\n",
      "[126]\ttrain-mlogloss:2.04978\ttrain-auc:0.65385\ttrain-merror:0.72216\ttest-mlogloss:2.08235\ttest-auc:0.61411\ttest-merror:0.73023\n",
      "[127]\ttrain-mlogloss:2.04953\ttrain-auc:0.65404\ttrain-merror:0.72207\ttest-mlogloss:2.08229\ttest-auc:0.61415\ttest-merror:0.73017\n",
      "[128]\ttrain-mlogloss:2.04926\ttrain-auc:0.65426\ttrain-merror:0.72201\ttest-mlogloss:2.08225\ttest-auc:0.61418\ttest-merror:0.73013\n",
      "[129]\ttrain-mlogloss:2.04903\ttrain-auc:0.65446\ttrain-merror:0.72194\ttest-mlogloss:2.08224\ttest-auc:0.61419\ttest-merror:0.73013\n",
      "[130]\ttrain-mlogloss:2.04883\ttrain-auc:0.65462\ttrain-merror:0.72188\ttest-mlogloss:2.08222\ttest-auc:0.61420\ttest-merror:0.73011\n",
      "[131]\ttrain-mlogloss:2.04859\ttrain-auc:0.65482\ttrain-merror:0.72178\ttest-mlogloss:2.08218\ttest-auc:0.61421\ttest-merror:0.73011\n",
      "[132]\ttrain-mlogloss:2.04836\ttrain-auc:0.65500\ttrain-merror:0.72174\ttest-mlogloss:2.08217\ttest-auc:0.61421\ttest-merror:0.73005\n",
      "[133]\ttrain-mlogloss:2.04808\ttrain-auc:0.65525\ttrain-merror:0.72164\ttest-mlogloss:2.08213\ttest-auc:0.61424\ttest-merror:0.72998\n",
      "[134]\ttrain-mlogloss:2.04788\ttrain-auc:0.65540\ttrain-merror:0.72159\ttest-mlogloss:2.08211\ttest-auc:0.61424\ttest-merror:0.72996\n",
      "[135]\ttrain-mlogloss:2.04765\ttrain-auc:0.65558\ttrain-merror:0.72152\ttest-mlogloss:2.08206\ttest-auc:0.61426\ttest-merror:0.72989\n",
      "[136]\ttrain-mlogloss:2.04743\ttrain-auc:0.65575\ttrain-merror:0.72140\ttest-mlogloss:2.08203\ttest-auc:0.61429\ttest-merror:0.72995\n",
      "[137]\ttrain-mlogloss:2.04721\ttrain-auc:0.65592\ttrain-merror:0.72132\ttest-mlogloss:2.08201\ttest-auc:0.61429\ttest-merror:0.72992\n",
      "[138]\ttrain-mlogloss:2.04700\ttrain-auc:0.65612\ttrain-merror:0.72126\ttest-mlogloss:2.08199\ttest-auc:0.61430\ttest-merror:0.72991\n",
      "[139]\ttrain-mlogloss:2.04679\ttrain-auc:0.65628\ttrain-merror:0.72119\ttest-mlogloss:2.08199\ttest-auc:0.61430\ttest-merror:0.72997\n",
      "[140]\ttrain-mlogloss:2.04655\ttrain-auc:0.65647\ttrain-merror:0.72110\ttest-mlogloss:2.08194\ttest-auc:0.61433\ttest-merror:0.72989\n",
      "[141]\ttrain-mlogloss:2.04631\ttrain-auc:0.65668\ttrain-merror:0.72103\ttest-mlogloss:2.08191\ttest-auc:0.61435\ttest-merror:0.72981\n",
      "[142]\ttrain-mlogloss:2.04607\ttrain-auc:0.65687\ttrain-merror:0.72091\ttest-mlogloss:2.08190\ttest-auc:0.61435\ttest-merror:0.72973\n",
      "[143]\ttrain-mlogloss:2.04585\ttrain-auc:0.65706\ttrain-merror:0.72085\ttest-mlogloss:2.08188\ttest-auc:0.61436\ttest-merror:0.72973\n",
      "[144]\ttrain-mlogloss:2.04561\ttrain-auc:0.65724\ttrain-merror:0.72079\ttest-mlogloss:2.08186\ttest-auc:0.61437\ttest-merror:0.72971\n",
      "[145]\ttrain-mlogloss:2.04534\ttrain-auc:0.65747\ttrain-merror:0.72071\ttest-mlogloss:2.08183\ttest-auc:0.61438\ttest-merror:0.72967\n",
      "[146]\ttrain-mlogloss:2.04509\ttrain-auc:0.65767\ttrain-merror:0.72061\ttest-mlogloss:2.08182\ttest-auc:0.61438\ttest-merror:0.72969\n",
      "[147]\ttrain-mlogloss:2.04489\ttrain-auc:0.65783\ttrain-merror:0.72055\ttest-mlogloss:2.08181\ttest-auc:0.61438\ttest-merror:0.72972\n",
      "[148]\ttrain-mlogloss:2.04464\ttrain-auc:0.65802\ttrain-merror:0.72046\ttest-mlogloss:2.08178\ttest-auc:0.61439\ttest-merror:0.72974\n",
      "[149]\ttrain-mlogloss:2.04442\ttrain-auc:0.65820\ttrain-merror:0.72039\ttest-mlogloss:2.08177\ttest-auc:0.61439\ttest-merror:0.72971\n",
      "[150]\ttrain-mlogloss:2.04416\ttrain-auc:0.65841\ttrain-merror:0.72028\ttest-mlogloss:2.08176\ttest-auc:0.61440\ttest-merror:0.72969\n",
      "[151]\ttrain-mlogloss:2.04394\ttrain-auc:0.65858\ttrain-merror:0.72021\ttest-mlogloss:2.08174\ttest-auc:0.61441\ttest-merror:0.72963\n",
      "[152]\ttrain-mlogloss:2.04370\ttrain-auc:0.65877\ttrain-merror:0.72016\ttest-mlogloss:2.08173\ttest-auc:0.61441\ttest-merror:0.72964\n",
      "[153]\ttrain-mlogloss:2.04351\ttrain-auc:0.65892\ttrain-merror:0.72011\ttest-mlogloss:2.08170\ttest-auc:0.61442\ttest-merror:0.72963\n",
      "[154]\ttrain-mlogloss:2.04330\ttrain-auc:0.65910\ttrain-merror:0.72007\ttest-mlogloss:2.08170\ttest-auc:0.61442\ttest-merror:0.72958\n",
      "[155]\ttrain-mlogloss:2.04309\ttrain-auc:0.65925\ttrain-merror:0.72000\ttest-mlogloss:2.08169\ttest-auc:0.61441\ttest-merror:0.72960\n",
      "[156]\ttrain-mlogloss:2.04287\ttrain-auc:0.65943\ttrain-merror:0.71989\ttest-mlogloss:2.08167\ttest-auc:0.61443\ttest-merror:0.72957\n",
      "[157]\ttrain-mlogloss:2.04263\ttrain-auc:0.65961\ttrain-merror:0.71981\ttest-mlogloss:2.08165\ttest-auc:0.61444\ttest-merror:0.72957\n",
      "[158]\ttrain-mlogloss:2.04242\ttrain-auc:0.65979\ttrain-merror:0.71975\ttest-mlogloss:2.08164\ttest-auc:0.61444\ttest-merror:0.72954\n",
      "[159]\ttrain-mlogloss:2.04221\ttrain-auc:0.65994\ttrain-merror:0.71970\ttest-mlogloss:2.08161\ttest-auc:0.61446\ttest-merror:0.72956\n",
      "[160]\ttrain-mlogloss:2.04202\ttrain-auc:0.66010\ttrain-merror:0.71965\ttest-mlogloss:2.08160\ttest-auc:0.61447\ttest-merror:0.72953\n",
      "[161]\ttrain-mlogloss:2.04183\ttrain-auc:0.66025\ttrain-merror:0.71959\ttest-mlogloss:2.08159\ttest-auc:0.61447\ttest-merror:0.72958\n",
      "[162]\ttrain-mlogloss:2.04161\ttrain-auc:0.66041\ttrain-merror:0.71951\ttest-mlogloss:2.08158\ttest-auc:0.61448\ttest-merror:0.72950\n",
      "[163]\ttrain-mlogloss:2.04140\ttrain-auc:0.66059\ttrain-merror:0.71944\ttest-mlogloss:2.08157\ttest-auc:0.61448\ttest-merror:0.72949\n",
      "[164]\ttrain-mlogloss:2.04120\ttrain-auc:0.66075\ttrain-merror:0.71940\ttest-mlogloss:2.08155\ttest-auc:0.61448\ttest-merror:0.72952\n",
      "[165]\ttrain-mlogloss:2.04100\ttrain-auc:0.66092\ttrain-merror:0.71932\ttest-mlogloss:2.08153\ttest-auc:0.61449\ttest-merror:0.72945\n",
      "[166]\ttrain-mlogloss:2.04074\ttrain-auc:0.66112\ttrain-merror:0.71925\ttest-mlogloss:2.08152\ttest-auc:0.61451\ttest-merror:0.72944\n",
      "[167]\ttrain-mlogloss:2.04054\ttrain-auc:0.66128\ttrain-merror:0.71917\ttest-mlogloss:2.08150\ttest-auc:0.61451\ttest-merror:0.72940\n",
      "[168]\ttrain-mlogloss:2.04030\ttrain-auc:0.66146\ttrain-merror:0.71912\ttest-mlogloss:2.08149\ttest-auc:0.61452\ttest-merror:0.72943\n",
      "[169]\ttrain-mlogloss:2.04010\ttrain-auc:0.66162\ttrain-merror:0.71905\ttest-mlogloss:2.08148\ttest-auc:0.61452\ttest-merror:0.72939\n",
      "[170]\ttrain-mlogloss:2.03987\ttrain-auc:0.66181\ttrain-merror:0.71900\ttest-mlogloss:2.08148\ttest-auc:0.61452\ttest-merror:0.72936\n",
      "[171]\ttrain-mlogloss:2.03965\ttrain-auc:0.66197\ttrain-merror:0.71897\ttest-mlogloss:2.08147\ttest-auc:0.61452\ttest-merror:0.72931\n",
      "[172]\ttrain-mlogloss:2.03947\ttrain-auc:0.66211\ttrain-merror:0.71888\ttest-mlogloss:2.08147\ttest-auc:0.61451\ttest-merror:0.72932\n",
      "[173]\ttrain-mlogloss:2.03929\ttrain-auc:0.66223\ttrain-merror:0.71883\ttest-mlogloss:2.08145\ttest-auc:0.61453\ttest-merror:0.72930\n",
      "[174]\ttrain-mlogloss:2.03907\ttrain-auc:0.66239\ttrain-merror:0.71877\ttest-mlogloss:2.08141\ttest-auc:0.61455\ttest-merror:0.72920\n",
      "[175]\ttrain-mlogloss:2.03883\ttrain-auc:0.66259\ttrain-merror:0.71873\ttest-mlogloss:2.08140\ttest-auc:0.61456\ttest-merror:0.72917\n",
      "[176]\ttrain-mlogloss:2.03865\ttrain-auc:0.66271\ttrain-merror:0.71866\ttest-mlogloss:2.08138\ttest-auc:0.61457\ttest-merror:0.72912\n",
      "[177]\ttrain-mlogloss:2.03847\ttrain-auc:0.66285\ttrain-merror:0.71860\ttest-mlogloss:2.08136\ttest-auc:0.61458\ttest-merror:0.72914\n",
      "[178]\ttrain-mlogloss:2.03827\ttrain-auc:0.66298\ttrain-merror:0.71853\ttest-mlogloss:2.08134\ttest-auc:0.61460\ttest-merror:0.72915\n",
      "[179]\ttrain-mlogloss:2.03808\ttrain-auc:0.66312\ttrain-merror:0.71851\ttest-mlogloss:2.08131\ttest-auc:0.61462\ttest-merror:0.72912\n",
      "[180]\ttrain-mlogloss:2.03790\ttrain-auc:0.66324\ttrain-merror:0.71845\ttest-mlogloss:2.08131\ttest-auc:0.61461\ttest-merror:0.72911\n",
      "[181]\ttrain-mlogloss:2.03768\ttrain-auc:0.66341\ttrain-merror:0.71834\ttest-mlogloss:2.08130\ttest-auc:0.61462\ttest-merror:0.72906\n",
      "[182]\ttrain-mlogloss:2.03745\ttrain-auc:0.66359\ttrain-merror:0.71828\ttest-mlogloss:2.08129\ttest-auc:0.61461\ttest-merror:0.72912\n",
      "[183]\ttrain-mlogloss:2.03724\ttrain-auc:0.66375\ttrain-merror:0.71820\ttest-mlogloss:2.08128\ttest-auc:0.61462\ttest-merror:0.72910\n",
      "[184]\ttrain-mlogloss:2.03705\ttrain-auc:0.66387\ttrain-merror:0.71815\ttest-mlogloss:2.08125\ttest-auc:0.61464\ttest-merror:0.72906\n",
      "[185]\ttrain-mlogloss:2.03681\ttrain-auc:0.66404\ttrain-merror:0.71805\ttest-mlogloss:2.08123\ttest-auc:0.61464\ttest-merror:0.72906\n",
      "[186]\ttrain-mlogloss:2.03659\ttrain-auc:0.66421\ttrain-merror:0.71801\ttest-mlogloss:2.08123\ttest-auc:0.61465\ttest-merror:0.72906\n",
      "[187]\ttrain-mlogloss:2.03639\ttrain-auc:0.66437\ttrain-merror:0.71792\ttest-mlogloss:2.08123\ttest-auc:0.61464\ttest-merror:0.72908\n",
      "[188]\ttrain-mlogloss:2.03619\ttrain-auc:0.66452\ttrain-merror:0.71787\ttest-mlogloss:2.08123\ttest-auc:0.61465\ttest-merror:0.72906\n",
      "[189]\ttrain-mlogloss:2.03600\ttrain-auc:0.66465\ttrain-merror:0.71781\ttest-mlogloss:2.08123\ttest-auc:0.61465\ttest-merror:0.72904\n",
      "[190]\ttrain-mlogloss:2.03583\ttrain-auc:0.66478\ttrain-merror:0.71776\ttest-mlogloss:2.08122\ttest-auc:0.61465\ttest-merror:0.72896\n",
      "[191]\ttrain-mlogloss:2.03563\ttrain-auc:0.66493\ttrain-merror:0.71768\ttest-mlogloss:2.08122\ttest-auc:0.61464\ttest-merror:0.72899\n",
      "[192]\ttrain-mlogloss:2.03542\ttrain-auc:0.66508\ttrain-merror:0.71761\ttest-mlogloss:2.08122\ttest-auc:0.61464\ttest-merror:0.72894\n",
      "[193]\ttrain-mlogloss:2.03525\ttrain-auc:0.66522\ttrain-merror:0.71756\ttest-mlogloss:2.08122\ttest-auc:0.61464\ttest-merror:0.72897\n",
      "[194]\ttrain-mlogloss:2.03506\ttrain-auc:0.66535\ttrain-merror:0.71752\ttest-mlogloss:2.08120\ttest-auc:0.61466\ttest-merror:0.72899\n",
      "[195]\ttrain-mlogloss:2.03485\ttrain-auc:0.66551\ttrain-merror:0.71746\ttest-mlogloss:2.08119\ttest-auc:0.61467\ttest-merror:0.72901\n",
      "[196]\ttrain-mlogloss:2.03465\ttrain-auc:0.66565\ttrain-merror:0.71739\ttest-mlogloss:2.08116\ttest-auc:0.61469\ttest-merror:0.72895\n",
      "[197]\ttrain-mlogloss:2.03448\ttrain-auc:0.66578\ttrain-merror:0.71734\ttest-mlogloss:2.08116\ttest-auc:0.61469\ttest-merror:0.72900\n",
      "[198]\ttrain-mlogloss:2.03428\ttrain-auc:0.66592\ttrain-merror:0.71728\ttest-mlogloss:2.08115\ttest-auc:0.61470\ttest-merror:0.72901\n",
      "[199]\ttrain-mlogloss:2.03406\ttrain-auc:0.66609\ttrain-merror:0.71719\ttest-mlogloss:2.08115\ttest-auc:0.61469\ttest-merror:0.72903\n",
      "200-rounds Training finished ...\t\t(144.365s)\n"
     ]
    }
   ],
   "source": [
    "num_round = 200\n",
    "t0 = time()\n",
    "eval_result = {}\n",
    "def decay_eta(nth):\n",
    "    etas = [.1, .05, .03, .01]\n",
    "    return etas[(nth // 60) % len(etas)]\n",
    "\n",
    "wl_bst_sm = xgb.train(param, xg_train, num_round, watchlist, evals_result=eval_result)\n",
    "print(f\"{num_round}-rounds Training finished ...\\t\\t({time()-t0:.3f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': OrderedDict([('mlogloss',\n",
       "               [2.273391,\n",
       "                2.249271,\n",
       "                2.228938,\n",
       "                2.211438,\n",
       "                2.196323,\n",
       "                2.183143,\n",
       "                2.171514,\n",
       "                2.16128,\n",
       "                2.15201,\n",
       "                2.14378,\n",
       "                2.136391,\n",
       "                2.129838,\n",
       "                2.12384,\n",
       "                2.118412,\n",
       "                2.113522,\n",
       "                2.109029,\n",
       "                2.105014,\n",
       "                2.101309,\n",
       "                2.0979,\n",
       "                2.094819,\n",
       "                2.092041,\n",
       "                2.089248,\n",
       "                2.086848,\n",
       "                2.084486,\n",
       "                2.082175,\n",
       "                2.080239,\n",
       "                2.078318,\n",
       "                2.076628,\n",
       "                2.074873,\n",
       "                2.073293,\n",
       "                2.071798,\n",
       "                2.070462,\n",
       "                2.069056,\n",
       "                2.067713,\n",
       "                2.066565,\n",
       "                2.065228,\n",
       "                2.064006,\n",
       "                2.062921,\n",
       "                2.061723,\n",
       "                2.060604,\n",
       "                2.059523,\n",
       "                2.058563,\n",
       "                2.057618,\n",
       "                2.056739,\n",
       "                2.055834,\n",
       "                2.055038,\n",
       "                2.054273,\n",
       "                2.053414,\n",
       "                2.052641,\n",
       "                2.051878,\n",
       "                2.051152,\n",
       "                2.050514,\n",
       "                2.049806,\n",
       "                2.049126,\n",
       "                2.04851,\n",
       "                2.047696,\n",
       "                2.047043,\n",
       "                2.046361,\n",
       "                2.045739,\n",
       "                2.045126,\n",
       "                2.044484,\n",
       "                2.043822,\n",
       "                2.043189,\n",
       "                2.042589,\n",
       "                2.041953,\n",
       "                2.041371,\n",
       "                2.040852,\n",
       "                2.040214,\n",
       "                2.039633,\n",
       "                2.039045,\n",
       "                2.038459,\n",
       "                2.037893,\n",
       "                2.037293,\n",
       "                2.03677,\n",
       "                2.036205,\n",
       "                2.035654,\n",
       "                2.035119,\n",
       "                2.034608,\n",
       "                2.034042,\n",
       "                2.033438,\n",
       "                2.033002,\n",
       "                2.032466,\n",
       "                2.031891,\n",
       "                2.031407,\n",
       "                2.030922,\n",
       "                2.030501,\n",
       "                2.029937,\n",
       "                2.029474,\n",
       "                2.028983,\n",
       "                2.028555,\n",
       "                2.028012,\n",
       "                2.027574,\n",
       "                2.027126,\n",
       "                2.026658,\n",
       "                2.026212,\n",
       "                2.025816,\n",
       "                2.025496,\n",
       "                2.025096,\n",
       "                2.024753,\n",
       "                2.024403,\n",
       "                2.024139,\n",
       "                2.023821,\n",
       "                2.023507,\n",
       "                2.023234,\n",
       "                2.022821,\n",
       "                2.022518,\n",
       "                2.022208,\n",
       "                2.022001,\n",
       "                2.021776,\n",
       "                2.021562,\n",
       "                2.021295,\n",
       "                2.021012,\n",
       "                2.020731,\n",
       "                2.020529,\n",
       "                2.020328,\n",
       "                2.020141,\n",
       "                2.01988,\n",
       "                2.019671,\n",
       "                2.01945,\n",
       "                2.019143,\n",
       "                2.018958,\n",
       "                2.018705,\n",
       "                2.018505,\n",
       "                2.018282,\n",
       "                2.018093,\n",
       "                2.017933,\n",
       "                2.017817,\n",
       "                2.017704,\n",
       "                2.017591,\n",
       "                2.017471,\n",
       "                2.017397,\n",
       "                2.017253,\n",
       "                2.017146,\n",
       "                2.017033,\n",
       "                2.016887,\n",
       "                2.016766,\n",
       "                2.016657,\n",
       "                2.01646,\n",
       "                2.016353,\n",
       "                2.016211,\n",
       "                2.016126,\n",
       "                2.016019,\n",
       "                2.015876,\n",
       "                2.015805,\n",
       "                2.015669,\n",
       "                2.015573,\n",
       "                2.015421,\n",
       "                2.015299,\n",
       "                2.015163,\n",
       "                2.015013,\n",
       "                2.014934,\n",
       "                2.014853,\n",
       "                2.014726,\n",
       "                2.014677,\n",
       "                2.014621,\n",
       "                2.014551,\n",
       "                2.014474,\n",
       "                2.014271,\n",
       "                2.01423,\n",
       "                2.014152,\n",
       "                2.014093,\n",
       "                2.014045,\n",
       "                2.013975,\n",
       "                2.013928,\n",
       "                2.013889,\n",
       "                2.013806,\n",
       "                2.013786,\n",
       "                2.013756,\n",
       "                2.013702,\n",
       "                2.013679,\n",
       "                2.013618,\n",
       "                2.013508,\n",
       "                2.013389,\n",
       "                2.013267,\n",
       "                2.01323,\n",
       "                2.013192,\n",
       "                2.01314,\n",
       "                2.013098,\n",
       "                2.01299,\n",
       "                2.012877,\n",
       "                2.012784,\n",
       "                2.012739,\n",
       "                2.012705,\n",
       "                2.012635,\n",
       "                2.012612,\n",
       "                2.012561,\n",
       "                2.012506,\n",
       "                2.012436,\n",
       "                2.012393,\n",
       "                2.012362,\n",
       "                2.012309,\n",
       "                2.012259,\n",
       "                2.012213,\n",
       "                2.012111,\n",
       "                2.012066,\n",
       "                2.011981,\n",
       "                2.011952,\n",
       "                2.011911,\n",
       "                2.011884,\n",
       "                2.011832]),\n",
       "              ('auc',\n",
       "               [0.609166,\n",
       "                0.613574,\n",
       "                0.615673,\n",
       "                0.617684,\n",
       "                0.618899,\n",
       "                0.620377,\n",
       "                0.621478,\n",
       "                0.62236,\n",
       "                0.623596,\n",
       "                0.624718,\n",
       "                0.625693,\n",
       "                0.626546,\n",
       "                0.627477,\n",
       "                0.628391,\n",
       "                0.629221,\n",
       "                0.630098,\n",
       "                0.630813,\n",
       "                0.631575,\n",
       "                0.632343,\n",
       "                0.633113,\n",
       "                0.633773,\n",
       "                0.634675,\n",
       "                0.635358,\n",
       "                0.636146,\n",
       "                0.637049,\n",
       "                0.637714,\n",
       "                0.638476,\n",
       "                0.63913,\n",
       "                0.639907,\n",
       "                0.64057,\n",
       "                0.641302,\n",
       "                0.641907,\n",
       "                0.642584,\n",
       "                0.643294,\n",
       "                0.64389,\n",
       "                0.644677,\n",
       "                0.645397,\n",
       "                0.646051,\n",
       "                0.646797,\n",
       "                0.64751,\n",
       "                0.648158,\n",
       "                0.648724,\n",
       "                0.649365,\n",
       "                0.649896,\n",
       "                0.650452,\n",
       "                0.650985,\n",
       "                0.651553,\n",
       "                0.652133,\n",
       "                0.652763,\n",
       "                0.653332,\n",
       "                0.653814,\n",
       "                0.654313,\n",
       "                0.654877,\n",
       "                0.655356,\n",
       "                0.655828,\n",
       "                0.656415,\n",
       "                0.656954,\n",
       "                0.65745,\n",
       "                0.657979,\n",
       "                0.658472,\n",
       "                0.658947,\n",
       "                0.659518,\n",
       "                0.660011,\n",
       "                0.66048,\n",
       "                0.661035,\n",
       "                0.661515,\n",
       "                0.661939,\n",
       "                0.66243,\n",
       "                0.662903,\n",
       "                0.663358,\n",
       "                0.663827,\n",
       "                0.664305,\n",
       "                0.664799,\n",
       "                0.665215,\n",
       "                0.665669,\n",
       "                0.66609,\n",
       "                0.666529,\n",
       "                0.666907,\n",
       "                0.66736,\n",
       "                0.667831,\n",
       "                0.668144,\n",
       "                0.668582,\n",
       "                0.669065,\n",
       "                0.66944,\n",
       "                0.669814,\n",
       "                0.67014,\n",
       "                0.670602,\n",
       "                0.670932,\n",
       "                0.671322,\n",
       "                0.671626,\n",
       "                0.672037,\n",
       "                0.672368,\n",
       "                0.672707,\n",
       "                0.673066,\n",
       "                0.673372,\n",
       "                0.673655,\n",
       "                0.673886,\n",
       "                0.674167,\n",
       "                0.674412,\n",
       "                0.67468,\n",
       "                0.674849,\n",
       "                0.675083,\n",
       "                0.675328,\n",
       "                0.675503,\n",
       "                0.675813,\n",
       "                0.676021,\n",
       "                0.676225,\n",
       "                0.67635,\n",
       "                0.676503,\n",
       "                0.676644,\n",
       "                0.676819,\n",
       "                0.677004,\n",
       "                0.677191,\n",
       "                0.677305,\n",
       "                0.677427,\n",
       "                0.677553,\n",
       "                0.677731,\n",
       "                0.677853,\n",
       "                0.678005,\n",
       "                0.67821,\n",
       "                0.678332,\n",
       "                0.678514,\n",
       "                0.678642,\n",
       "                0.678797,\n",
       "                0.678916,\n",
       "                0.67901,\n",
       "                0.679068,\n",
       "                0.679116,\n",
       "                0.679174,\n",
       "                0.679233,\n",
       "                0.679268,\n",
       "                0.679347,\n",
       "                0.679393,\n",
       "                0.679453,\n",
       "                0.679532,\n",
       "                0.679592,\n",
       "                0.679641,\n",
       "                0.679756,\n",
       "                0.679805,\n",
       "                0.679884,\n",
       "                0.67992,\n",
       "                0.679976,\n",
       "                0.680058,\n",
       "                0.680091,\n",
       "                0.680166,\n",
       "                0.680201,\n",
       "                0.680297,\n",
       "                0.680364,\n",
       "                0.680429,\n",
       "                0.680511,\n",
       "                0.680554,\n",
       "                0.680594,\n",
       "                0.68066,\n",
       "                0.680675,\n",
       "                0.680696,\n",
       "                0.680724,\n",
       "                0.680755,\n",
       "                0.680916,\n",
       "                0.68093,\n",
       "                0.680963,\n",
       "                0.680986,\n",
       "                0.681005,\n",
       "                0.681047,\n",
       "                0.681063,\n",
       "                0.681076,\n",
       "                0.681109,\n",
       "                0.681114,\n",
       "                0.681125,\n",
       "                0.681142,\n",
       "                0.681148,\n",
       "                0.681176,\n",
       "                0.681243,\n",
       "                0.681297,\n",
       "                0.68136,\n",
       "                0.681373,\n",
       "                0.681389,\n",
       "                0.681404,\n",
       "                0.681419,\n",
       "                0.681469,\n",
       "                0.681542,\n",
       "                0.681581,\n",
       "                0.681599,\n",
       "                0.681611,\n",
       "                0.681642,\n",
       "                0.681648,\n",
       "                0.681666,\n",
       "                0.681681,\n",
       "                0.681711,\n",
       "                0.681724,\n",
       "                0.681731,\n",
       "                0.681748,\n",
       "                0.681768,\n",
       "                0.681781,\n",
       "                0.681825,\n",
       "                0.681841,\n",
       "                0.681887,\n",
       "                0.681898,\n",
       "                0.681912,\n",
       "                0.681922,\n",
       "                0.681937]),\n",
       "              ('merror',\n",
       "               [0.736567,\n",
       "                0.734123,\n",
       "                0.733287,\n",
       "                0.732624,\n",
       "                0.732093,\n",
       "                0.731596,\n",
       "                0.731194,\n",
       "                0.730924,\n",
       "                0.730526,\n",
       "                0.730136,\n",
       "                0.729627,\n",
       "                0.729457,\n",
       "                0.729307,\n",
       "                0.729097,\n",
       "                0.72865,\n",
       "                0.728462,\n",
       "                0.728281,\n",
       "                0.728087,\n",
       "                0.727865,\n",
       "                0.72766,\n",
       "                0.727516,\n",
       "                0.727328,\n",
       "                0.727033,\n",
       "                0.72682,\n",
       "                0.726528,\n",
       "                0.726331,\n",
       "                0.726146,\n",
       "                0.725933,\n",
       "                0.725733,\n",
       "                0.725498,\n",
       "                0.725218,\n",
       "                0.725064,\n",
       "                0.724871,\n",
       "                0.724663,\n",
       "                0.724455,\n",
       "                0.724101,\n",
       "                0.723866,\n",
       "                0.723614,\n",
       "                0.723313,\n",
       "                0.723139,\n",
       "                0.722898,\n",
       "                0.722674,\n",
       "                0.72244,\n",
       "                0.722268,\n",
       "                0.722085,\n",
       "                0.721878,\n",
       "                0.721729,\n",
       "                0.721451,\n",
       "                0.721261,\n",
       "                0.721111,\n",
       "                0.720938,\n",
       "                0.720817,\n",
       "                0.72056,\n",
       "                0.72037,\n",
       "                0.720195,\n",
       "                0.719901,\n",
       "                0.719704,\n",
       "                0.719465,\n",
       "                0.719327,\n",
       "                0.719086,\n",
       "                0.71886,\n",
       "                0.718676,\n",
       "                0.718485,\n",
       "                0.718345,\n",
       "                0.718081,\n",
       "                0.717925,\n",
       "                0.717798,\n",
       "                0.717584,\n",
       "                0.717402,\n",
       "                0.717194,\n",
       "                0.716954,\n",
       "                0.716775,\n",
       "                0.716569,\n",
       "                0.71638,\n",
       "                0.716216,\n",
       "                0.716011,\n",
       "                0.715823,\n",
       "                0.715645,\n",
       "                0.715486,\n",
       "                0.715216,\n",
       "                0.71509,\n",
       "                0.714905,\n",
       "                0.714731,\n",
       "                0.714552,\n",
       "                0.714427,\n",
       "                0.714291,\n",
       "                0.714078,\n",
       "                0.71394,\n",
       "                0.71374,\n",
       "                0.713625,\n",
       "                0.713416,\n",
       "                0.71326,\n",
       "                0.713118,\n",
       "                0.71294,\n",
       "                0.712771,\n",
       "                0.712584,\n",
       "                0.712466,\n",
       "                0.712347,\n",
       "                0.712194,\n",
       "                0.712007,\n",
       "                0.711866,\n",
       "                0.711762,\n",
       "                0.711646,\n",
       "                0.711515,\n",
       "                0.711271,\n",
       "                0.71117,\n",
       "                0.711008,\n",
       "                0.710895,\n",
       "                0.710786,\n",
       "                0.710699,\n",
       "                0.710572,\n",
       "                0.710429,\n",
       "                0.710301,\n",
       "                0.710233,\n",
       "                0.710098,\n",
       "                0.709965,\n",
       "                0.709799,\n",
       "                0.709727,\n",
       "                0.709592,\n",
       "                0.709422,\n",
       "                0.709292,\n",
       "                0.709139,\n",
       "                0.708986,\n",
       "                0.708837,\n",
       "                0.708743,\n",
       "                0.70863,\n",
       "                0.708564,\n",
       "                0.708518,\n",
       "                0.708465,\n",
       "                0.708408,\n",
       "                0.708354,\n",
       "                0.708295,\n",
       "                0.708238,\n",
       "                0.708167,\n",
       "                0.708065,\n",
       "                0.708008,\n",
       "                0.70796,\n",
       "                0.707828,\n",
       "                0.707759,\n",
       "                0.707672,\n",
       "                0.707609,\n",
       "                0.707545,\n",
       "                0.707455,\n",
       "                0.707402,\n",
       "                0.707346,\n",
       "                0.707296,\n",
       "                0.707199,\n",
       "                0.707134,\n",
       "                0.707047,\n",
       "                0.706961,\n",
       "                0.706909,\n",
       "                0.706842,\n",
       "                0.706767,\n",
       "                0.706737,\n",
       "                0.706718,\n",
       "                0.706687,\n",
       "                0.706645,\n",
       "                0.70648,\n",
       "                0.706468,\n",
       "                0.706433,\n",
       "                0.706415,\n",
       "                0.706409,\n",
       "                0.706365,\n",
       "                0.706351,\n",
       "                0.706338,\n",
       "                0.706305,\n",
       "                0.706298,\n",
       "                0.706279,\n",
       "                0.706264,\n",
       "                0.706252,\n",
       "                0.706232,\n",
       "                0.706168,\n",
       "                0.706121,\n",
       "                0.706088,\n",
       "                0.70608,\n",
       "                0.706062,\n",
       "                0.706038,\n",
       "                0.70602,\n",
       "                0.705938,\n",
       "                0.705859,\n",
       "                0.705835,\n",
       "                0.705819,\n",
       "                0.705809,\n",
       "                0.705772,\n",
       "                0.705756,\n",
       "                0.705754,\n",
       "                0.705724,\n",
       "                0.705688,\n",
       "                0.705675,\n",
       "                0.705644,\n",
       "                0.705621,\n",
       "                0.705604,\n",
       "                0.705576,\n",
       "                0.705528,\n",
       "                0.705507,\n",
       "                0.705469,\n",
       "                0.705457,\n",
       "                0.705441,\n",
       "                0.705429,\n",
       "                0.705403])]),\n",
       " 'test': OrderedDict([('mlogloss',\n",
       "               [2.273966,\n",
       "                2.250428,\n",
       "                2.230677,\n",
       "                2.213754,\n",
       "                2.199225,\n",
       "                2.186585,\n",
       "                2.175527,\n",
       "                2.165833,\n",
       "                2.157122,\n",
       "                2.149473,\n",
       "                2.142651,\n",
       "                2.136662,\n",
       "                2.131266,\n",
       "                2.126448,\n",
       "                2.122146,\n",
       "                2.118271,\n",
       "                2.114859,\n",
       "                2.111758,\n",
       "                2.108978,\n",
       "                2.106493,\n",
       "                2.104311,\n",
       "                2.102141,\n",
       "                2.100348,\n",
       "                2.098594,\n",
       "                2.096948,\n",
       "                2.095634,\n",
       "                2.094353,\n",
       "                2.093259,\n",
       "                2.092155,\n",
       "                2.091199,\n",
       "                2.090338,\n",
       "                2.089609,\n",
       "                2.088794,\n",
       "                2.088084,\n",
       "                2.087566,\n",
       "                2.086879,\n",
       "                2.086292,\n",
       "                2.085867,\n",
       "                2.085336,\n",
       "                2.08488,\n",
       "                2.084435,\n",
       "                2.084051,\n",
       "                2.083765,\n",
       "                2.083475,\n",
       "                2.083183,\n",
       "                2.083005,\n",
       "                2.08284,\n",
       "                2.082611,\n",
       "                2.082492,\n",
       "                2.082344,\n",
       "                2.082157,\n",
       "                2.08208,\n",
       "                2.082,\n",
       "                2.081881,\n",
       "                2.081804,\n",
       "                2.081594,\n",
       "                2.081518,\n",
       "                2.081397,\n",
       "                2.081355,\n",
       "                2.081302,\n",
       "                2.081173,\n",
       "                2.081138,\n",
       "                2.081072,\n",
       "                2.08103,\n",
       "                2.080996,\n",
       "                2.080967,\n",
       "                2.080953,\n",
       "                2.080883,\n",
       "                2.08084,\n",
       "                2.080801,\n",
       "                2.080752,\n",
       "                2.080732,\n",
       "                2.080695,\n",
       "                2.080673,\n",
       "                2.080658,\n",
       "                2.080602,\n",
       "                2.080593,\n",
       "                2.080565,\n",
       "                2.080539,\n",
       "                2.080512,\n",
       "                2.080488,\n",
       "                2.080473,\n",
       "                2.080469,\n",
       "                2.08046,\n",
       "                2.080437,\n",
       "                2.080427,\n",
       "                2.080432,\n",
       "                2.080418,\n",
       "                2.080394,\n",
       "                2.080377,\n",
       "                2.080375,\n",
       "                2.080362,\n",
       "                2.080354,\n",
       "                2.080343,\n",
       "                2.080349,\n",
       "                2.08034,\n",
       "                2.080347,\n",
       "                2.080342,\n",
       "                2.080329,\n",
       "                2.080311,\n",
       "                2.080294,\n",
       "                2.080276,\n",
       "                2.080289,\n",
       "                2.080271,\n",
       "                2.08027,\n",
       "                2.080249,\n",
       "                2.080216,\n",
       "                2.080196,\n",
       "                2.080184,\n",
       "                2.080182,\n",
       "                2.080157,\n",
       "                2.080133,\n",
       "                2.08011,\n",
       "                2.080096,\n",
       "                2.08008,\n",
       "                2.080082,\n",
       "                2.080074,\n",
       "                2.080047,\n",
       "                2.080029,\n",
       "                2.080013,\n",
       "                2.079996,\n",
       "                2.079986,\n",
       "                2.079977,\n",
       "                2.079978,\n",
       "                2.079966,\n",
       "                2.079957,\n",
       "                2.07994,\n",
       "                2.079918,\n",
       "                2.079911,\n",
       "                2.07991,\n",
       "                2.079897,\n",
       "                2.079887,\n",
       "                2.07987,\n",
       "                2.079848,\n",
       "                2.079819,\n",
       "                2.079782,\n",
       "                2.079779,\n",
       "                2.079745,\n",
       "                2.07973,\n",
       "                2.079714,\n",
       "                2.07969,\n",
       "                2.079686,\n",
       "                2.079694,\n",
       "                2.079683,\n",
       "                2.079683,\n",
       "                2.079665,\n",
       "                2.079645,\n",
       "                2.079633,\n",
       "                2.079602,\n",
       "                2.079573,\n",
       "                2.079575,\n",
       "                2.079566,\n",
       "                2.079545,\n",
       "                2.079539,\n",
       "                2.079537,\n",
       "                2.079527,\n",
       "                2.07952,\n",
       "                2.079513,\n",
       "                2.079507,\n",
       "                2.079505,\n",
       "                2.0795,\n",
       "                2.079493,\n",
       "                2.079496,\n",
       "                2.079484,\n",
       "                2.079475,\n",
       "                2.07947,\n",
       "                2.079468,\n",
       "                2.079465,\n",
       "                2.079451,\n",
       "                2.07945,\n",
       "                2.079444,\n",
       "                2.079444,\n",
       "                2.079428,\n",
       "                2.079413,\n",
       "                2.079404,\n",
       "                2.079399,\n",
       "                2.079379,\n",
       "                2.079372,\n",
       "                2.079349,\n",
       "                2.079342,\n",
       "                2.079335,\n",
       "                2.079337,\n",
       "                2.079336,\n",
       "                2.079337,\n",
       "                2.079331,\n",
       "                2.079327,\n",
       "                2.079313,\n",
       "                2.079311,\n",
       "                2.079301,\n",
       "                2.079287,\n",
       "                2.079275,\n",
       "                2.079274,\n",
       "                2.079258,\n",
       "                2.079248,\n",
       "                2.079233,\n",
       "                2.07923,\n",
       "                2.07923,\n",
       "                2.079229,\n",
       "                2.079225,\n",
       "                2.079212]),\n",
       "              ('auc',\n",
       "               [0.598253,\n",
       "                0.601141,\n",
       "                0.602342,\n",
       "                0.603543,\n",
       "                0.604139,\n",
       "                0.60494,\n",
       "                0.605443,\n",
       "                0.605851,\n",
       "                0.606437,\n",
       "                0.606949,\n",
       "                0.607375,\n",
       "                0.607739,\n",
       "                0.608041,\n",
       "                0.608347,\n",
       "                0.60867,\n",
       "                0.608922,\n",
       "                0.609089,\n",
       "                0.60928,\n",
       "                0.609503,\n",
       "                0.609693,\n",
       "                0.60982,\n",
       "                0.61015,\n",
       "                0.610302,\n",
       "                0.610542,\n",
       "                0.610849,\n",
       "                0.61098,\n",
       "                0.611182,\n",
       "                0.611318,\n",
       "                0.611519,\n",
       "                0.61164,\n",
       "                0.611776,\n",
       "                0.611853,\n",
       "                0.612054,\n",
       "                0.61219,\n",
       "                0.612242,\n",
       "                0.612456,\n",
       "                0.61262,\n",
       "                0.612678,\n",
       "                0.612842,\n",
       "                0.612986,\n",
       "                0.613119,\n",
       "                0.61323,\n",
       "                0.613288,\n",
       "                0.613347,\n",
       "                0.613418,\n",
       "                0.613423,\n",
       "                0.613461,\n",
       "                0.613496,\n",
       "                0.61352,\n",
       "                0.61354,\n",
       "                0.6136,\n",
       "                0.613591,\n",
       "                0.613589,\n",
       "                0.613613,\n",
       "                0.613626,\n",
       "                0.61372,\n",
       "                0.613748,\n",
       "                0.613798,\n",
       "                0.613788,\n",
       "                0.6138,\n",
       "                0.613858,\n",
       "                0.613856,\n",
       "                0.613858,\n",
       "                0.613861,\n",
       "                0.613865,\n",
       "                0.613865,\n",
       "                0.613868,\n",
       "                0.613893,\n",
       "                0.613916,\n",
       "                0.613913,\n",
       "                0.613942,\n",
       "                0.613944,\n",
       "                0.613963,\n",
       "                0.613981,\n",
       "                0.61398,\n",
       "                0.614018,\n",
       "                0.614012,\n",
       "                0.61403,\n",
       "                0.614051,\n",
       "                0.614065,\n",
       "                0.614085,\n",
       "                0.614102,\n",
       "                0.614087,\n",
       "                0.614089,\n",
       "                0.614105,\n",
       "                0.614113,\n",
       "                0.6141,\n",
       "                0.61411,\n",
       "                0.614128,\n",
       "                0.614128,\n",
       "                0.614123,\n",
       "                0.614124,\n",
       "                0.614132,\n",
       "                0.61414,\n",
       "                0.614134,\n",
       "                0.614134,\n",
       "                0.614128,\n",
       "                0.614134,\n",
       "                0.614138,\n",
       "                0.614145,\n",
       "                0.614153,\n",
       "                0.614162,\n",
       "                0.61415,\n",
       "                0.614162,\n",
       "                0.614155,\n",
       "                0.614178,\n",
       "                0.614195,\n",
       "                0.614212,\n",
       "                0.614221,\n",
       "                0.614221,\n",
       "                0.614237,\n",
       "                0.614244,\n",
       "                0.61426,\n",
       "                0.61427,\n",
       "                0.614282,\n",
       "                0.614284,\n",
       "                0.61429,\n",
       "                0.614312,\n",
       "                0.614321,\n",
       "                0.614324,\n",
       "                0.614341,\n",
       "                0.614347,\n",
       "                0.614351,\n",
       "                0.61435,\n",
       "                0.614353,\n",
       "                0.614354,\n",
       "                0.614365,\n",
       "                0.61438,\n",
       "                0.614384,\n",
       "                0.614381,\n",
       "                0.614389,\n",
       "                0.614395,\n",
       "                0.614405,\n",
       "                0.61442,\n",
       "                0.614442,\n",
       "                0.61446,\n",
       "                0.614462,\n",
       "                0.614475,\n",
       "                0.614485,\n",
       "                0.614492,\n",
       "                0.614502,\n",
       "                0.614504,\n",
       "                0.614497,\n",
       "                0.614501,\n",
       "                0.614498,\n",
       "                0.614504,\n",
       "                0.614515,\n",
       "                0.614524,\n",
       "                0.614536,\n",
       "                0.614551,\n",
       "                0.61455,\n",
       "                0.614554,\n",
       "                0.614567,\n",
       "                0.614571,\n",
       "                0.614571,\n",
       "                0.614577,\n",
       "                0.61458,\n",
       "                0.614577,\n",
       "                0.61458,\n",
       "                0.61458,\n",
       "                0.614584,\n",
       "                0.614586,\n",
       "                0.614584,\n",
       "                0.61459,\n",
       "                0.614594,\n",
       "                0.614598,\n",
       "                0.6146,\n",
       "                0.614601,\n",
       "                0.614609,\n",
       "                0.61461,\n",
       "                0.614611,\n",
       "                0.614604,\n",
       "                0.614612,\n",
       "                0.614622,\n",
       "                0.614628,\n",
       "                0.61463,\n",
       "                0.61464,\n",
       "                0.614643,\n",
       "                0.614659,\n",
       "                0.614665,\n",
       "                0.614668,\n",
       "                0.614668,\n",
       "                0.614669,\n",
       "                0.614669,\n",
       "                0.614672,\n",
       "                0.614676,\n",
       "                0.614683,\n",
       "                0.614684,\n",
       "                0.614688,\n",
       "                0.614696,\n",
       "                0.614702,\n",
       "                0.614704,\n",
       "                0.614712,\n",
       "                0.614716,\n",
       "                0.614726,\n",
       "                0.614729,\n",
       "                0.61473,\n",
       "                0.61473,\n",
       "                0.614731,\n",
       "                0.614737]),\n",
       "              ('merror',\n",
       "               [0.73782,\n",
       "                0.736012,\n",
       "                0.734923,\n",
       "                0.734415,\n",
       "                0.734394,\n",
       "                0.733806,\n",
       "                0.733643,\n",
       "                0.733631,\n",
       "                0.73342,\n",
       "                0.732988,\n",
       "                0.732547,\n",
       "                0.732556,\n",
       "                0.732391,\n",
       "                0.732311,\n",
       "                0.732046,\n",
       "                0.73203,\n",
       "                0.731683,\n",
       "                0.731566,\n",
       "                0.731479,\n",
       "                0.731341,\n",
       "                0.73133,\n",
       "                0.731284,\n",
       "                0.731188,\n",
       "                0.731063,\n",
       "                0.730976,\n",
       "                0.730907,\n",
       "                0.730913,\n",
       "                0.730882,\n",
       "                0.730976,\n",
       "                0.730836,\n",
       "                0.730779,\n",
       "                0.730742,\n",
       "                0.730683,\n",
       "                0.730523,\n",
       "                0.730479,\n",
       "                0.730354,\n",
       "                0.730351,\n",
       "                0.730258,\n",
       "                0.730009,\n",
       "                0.729901,\n",
       "                0.729949,\n",
       "                0.729951,\n",
       "                0.729876,\n",
       "                0.729736,\n",
       "                0.729702,\n",
       "                0.72969,\n",
       "                0.729656,\n",
       "                0.729569,\n",
       "                0.729602,\n",
       "                0.729469,\n",
       "                0.7294,\n",
       "                0.729448,\n",
       "                0.729412,\n",
       "                0.729385,\n",
       "                0.729333,\n",
       "                0.729258,\n",
       "                0.729235,\n",
       "                0.729224,\n",
       "                0.729268,\n",
       "                0.729203,\n",
       "                0.729218,\n",
       "                0.72917,\n",
       "                0.729254,\n",
       "                0.729312,\n",
       "                0.729208,\n",
       "                0.729199,\n",
       "                0.729228,\n",
       "                0.729258,\n",
       "                0.72926,\n",
       "                0.72926,\n",
       "                0.729176,\n",
       "                0.729158,\n",
       "                0.729145,\n",
       "                0.729137,\n",
       "                0.729116,\n",
       "                0.729064,\n",
       "                0.729074,\n",
       "                0.728995,\n",
       "                0.728963,\n",
       "                0.728934,\n",
       "                0.728982,\n",
       "                0.728997,\n",
       "                0.729076,\n",
       "                0.729028,\n",
       "                0.729053,\n",
       "                0.729068,\n",
       "                0.729001,\n",
       "                0.729036,\n",
       "                0.728955,\n",
       "                0.72892,\n",
       "                0.728886,\n",
       "                0.72892,\n",
       "                0.728799,\n",
       "                0.728817,\n",
       "                0.728861,\n",
       "                0.728884,\n",
       "                0.728847,\n",
       "                0.728849,\n",
       "                0.728865,\n",
       "                0.728867,\n",
       "                0.728805,\n",
       "                0.728799,\n",
       "                0.728834,\n",
       "                0.72879,\n",
       "                0.728803,\n",
       "                0.728744,\n",
       "                0.728688,\n",
       "                0.728663,\n",
       "                0.728609,\n",
       "                0.72864,\n",
       "                0.728581,\n",
       "                0.728598,\n",
       "                0.728586,\n",
       "                0.72855,\n",
       "                0.728525,\n",
       "                0.728571,\n",
       "                0.728538,\n",
       "                0.728569,\n",
       "                0.728561,\n",
       "                0.728542,\n",
       "                0.728563,\n",
       "                0.728604,\n",
       "                0.728617,\n",
       "                0.728682,\n",
       "                0.728667,\n",
       "                0.728623,\n",
       "                0.728665,\n",
       "                0.728632,\n",
       "                0.728638,\n",
       "                0.728625,\n",
       "                0.728669,\n",
       "                0.728565,\n",
       "                0.728506,\n",
       "                0.728554,\n",
       "                0.728504,\n",
       "                0.728462,\n",
       "                0.728475,\n",
       "                0.72846,\n",
       "                0.72841,\n",
       "                0.728364,\n",
       "                0.728392,\n",
       "                0.728348,\n",
       "                0.728398,\n",
       "                0.728406,\n",
       "                0.7284,\n",
       "                0.728389,\n",
       "                0.728379,\n",
       "                0.728398,\n",
       "                0.728362,\n",
       "                0.728312,\n",
       "                0.728314,\n",
       "                0.728258,\n",
       "                0.72827,\n",
       "                0.72825,\n",
       "                0.728233,\n",
       "                0.728225,\n",
       "                0.728222,\n",
       "                0.728225,\n",
       "                0.728212,\n",
       "                0.728254,\n",
       "                0.728247,\n",
       "                0.728237,\n",
       "                0.72825,\n",
       "                0.728252,\n",
       "                0.728258,\n",
       "                0.728306,\n",
       "                0.728293,\n",
       "                0.728279,\n",
       "                0.728268,\n",
       "                0.728266,\n",
       "                0.728277,\n",
       "                0.728266,\n",
       "                0.728235,\n",
       "                0.72826,\n",
       "                0.728245,\n",
       "                0.728235,\n",
       "                0.72822,\n",
       "                0.728212,\n",
       "                0.728179,\n",
       "                0.728131,\n",
       "                0.728166,\n",
       "                0.728193,\n",
       "                0.728218,\n",
       "                0.728222,\n",
       "                0.728206,\n",
       "                0.728197,\n",
       "                0.728195,\n",
       "                0.728195,\n",
       "                0.728195,\n",
       "                0.728183,\n",
       "                0.728183,\n",
       "                0.728197,\n",
       "                0.728202,\n",
       "                0.728214,\n",
       "                0.728229,\n",
       "                0.728227,\n",
       "                0.728225,\n",
       "                0.728239,\n",
       "                0.728229,\n",
       "                0.728218])])}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error using softmax = 0.7290322984633496\n"
     ]
    }
   ],
   "source": [
    "# get prediction\n",
    "pred = wl_bst_sm.predict(xg_test)\n",
    "# pred = pred.astype(np.uint8)\n",
    "error_rate = np.sum(pred != y_test) / y_test.shape[0]\n",
    "print('Test error using softmax = {}'.format(error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0]\\teval-mlogloss:2.081153\\teval-auc:0.614688\\teval-merror:0.729032'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_s = wl_bst_sm.eval(xg_test)\n",
    "# eval_dict = eval_str_2_dict(eval_s)\n",
    "eval_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.56775223, 0.58589565, 0.50352267, 0.50013574, 0.50020896,\n",
       "        0.50015228, 0.5028023 , 0.50020022, 0.50903426, 0.60518875]),\n",
       " 2.36321336447277)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.arange(0, 1, 0.1)\n",
    "aucs = auc(y_test.astype(np.uint8), pred.astype(np.uint8), np.arange(param['num_class']))\n",
    "# aucs[aucs == 0.5] = 0\n",
    "w_auc = (aucs * weights).sum()\n",
    "aucs, w_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = metrics.classification_report(list(y_test), list(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.17      0.23     44017\n",
      "           1       0.29      0.70      0.41    111575\n",
      "           2       0.26      0.01      0.02     62786\n",
      "           3       0.13      0.00      0.00     43844\n",
      "           4       0.22      0.00      0.00     34491\n",
      "           5       0.23      0.00      0.00     28448\n",
      "           6       0.30      0.01      0.01     25054\n",
      "           7       0.14      0.00      0.00     23498\n",
      "           8       0.30      0.02      0.04     27589\n",
      "           9       0.24      0.56      0.33     77792\n",
      "\n",
      "    accuracy                           0.27    479094\n",
      "   macro avg       0.24      0.15      0.10    479094\n",
      "weighted avg       0.25      0.27      0.18    479094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from collections.abc import Iterable\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_param = {  # 基本参数，不需要调参\n",
    "    'objective': 'multi:softmax',\n",
    "    'eta': 0.1,\n",
    "    'nthread': 8,\n",
    "    'num_class': 10,\n",
    "    'gpu_id': 0,\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'eval_metric': ['mlogloss', 'auc', 'merror']\n",
    "} \n",
    "# 需要调参的参数\n",
    "ps1 = {  \n",
    "    'max_depth': list(range(5, 14, 2)),\n",
    "    'min_child_weight': list(range(1, 10, 2)),\n",
    "}\n",
    "\n",
    "ps2 = {\n",
    "    'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "}\n",
    "\n",
    "ps3 = {\n",
    "    'subsample':  [i/10.0 for i in range(6,11,1)], \n",
    "    'colsample_bytree':  [i/10.0 for i in range(6,11,1)] \n",
    "}\n",
    "\n",
    "ps4 = {'reg_alpha': [0, 0.1, 0.2, 0.5, 1, 1.5, 2, 4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparing finished ...\t\t(5.092s)\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "xg_train = xgb.DMatrix(X_train.values, label=y_train.values, enable_categorical=True)\n",
    "xg_test = xgb.DMatrix(X_test.values, label=y_test.values, enable_categorical=True)\n",
    "print(f\"Data preparing finished ...\\t\\t({time()-t0:.3f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myproduct(*iterables):\n",
    "    n = len(iterables)\n",
    "#     print(iterables)\n",
    "    if n == 0:\n",
    "        return None \n",
    "    \n",
    "    ret = []\n",
    "    ret.extend([[e] for e in iterables[0].copy()])\n",
    "    if n == 1:\n",
    "        return ret\n",
    "\n",
    "    # 将需要调参的参数进行组合，即笛卡尔乘积。类似于sklearn中的 ParameterGrid\n",
    "    for k in range(1, n):\n",
    "        v = iterables[k].copy()\n",
    "        l = len(ret)\n",
    "        ret = [ret[i%l].copy() for i in range(len(v) * len(ret))]\n",
    "        for i, e in enumerate(ret):\n",
    "            e.append(v[i // l])\n",
    "    return ret\n",
    "\n",
    "def compose_param_grid(grid, base):\n",
    "    items = list(grid.items())\n",
    "    iterables = [item[1] for item in items]\n",
    "    keys = [item[0] for item in items]\n",
    "\n",
    "    ret = myproduct(*iterables)\n",
    "    com_ps = [dict(zip(keys, e)) for e in ret]\n",
    "\n",
    "\n",
    "    all_params = [base.copy() for _ in range(len(com_ps))] \n",
    "    for i in range(len(com_ps)):\n",
    "        all_params[i].update(com_ps[i])\n",
    "        \n",
    "    return all_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始搜索：colsample_bytree=[0.6, 0.7, 0.8, 0.9, 1.0], subsample=[0.6, 0.7, 0.8, 0.9, 1.0]\n",
      "待搜索的参数组合数量：25\n",
      "1 / 25: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 0.6, 'colsample_bytree': 0.6} ...\t\t(820.946s)\n",
      "2 / 25: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 0.7, 'colsample_bytree': 0.6} ...\t\t(816.416s)\n",
      "3 / 25: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 0.8, 'colsample_bytree': 0.6} ...\t\t(828.957s)\n",
      "4 / 25: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 0.9, 'colsample_bytree': 0.6} ...\t\t(838.505s)\n",
      "5 / 25: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 1.0, 'colsample_bytree': 0.6} ...\t\t(823.276s)\n",
      "6 / 25: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 0.6, 'colsample_bytree': 0.7} ...\t\t(828.692s)\n",
      "7 / 25: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 0.7, 'colsample_bytree': 0.7} ...\t\t(848.865s)\n",
      "8 / 25: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 0.8, 'colsample_bytree': 0.7} ...\t\t(854.009s)\n",
      "9 / 25: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 0.9, 'colsample_bytree': 0.7} ...\t\t(863.061s)\n",
      "10 / 25: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 1.0, 'colsample_bytree': 0.7} ...\t\t(854.728s)\n",
      "11 / 25: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 0.6, 'colsample_bytree': 0.8} ...\t\t(833.519s)\n",
      "12 / 25: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 0.7, 'colsample_bytree': 0.8} ...\t\t(836.241s)\n",
      "13 / 25: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 0.8, 'colsample_bytree': 0.8} ...\t\t(852.569s)\n",
      "14 / 25: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 0.9, 'colsample_bytree': 0.8} ...\t\t(867.649s)\n",
      "15 / 25: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 1.0, 'colsample_bytree': 0.8} ...\t\t(837.901s)\n",
      "16 / 25: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 0.6, 'colsample_bytree': 0.9} ...\t\t(827.339s)\n",
      "17 / 25: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 0.7, 'colsample_bytree': 0.9} ...\t\t(829.429s)\n",
      "18 / 25: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 0.8, 'colsample_bytree': 0.9} ...\t\t(854.584s)\n",
      "19 / 25: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 0.9, 'colsample_bytree': 0.9} ...\t\t(865.975s)\n",
      "20 / 25: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 1.0, 'colsample_bytree': 0.9} ...\t\t(830.648s)\n",
      "21 / 25: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 0.6, 'colsample_bytree': 1.0} ...\t\t(846.784s)\n",
      "22 / 25: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 0.7, 'colsample_bytree': 1.0} ...\t\t(852.846s)\n",
      "23 / 25: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 0.8, 'colsample_bytree': 1.0} ...\t\t(850.433s)\n",
      "24 / 25: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 0.9, 'colsample_bytree': 1.0} ...\t\t(865.453s)\n",
      "25 / 25: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 1.0, 'colsample_bytree': 1.0} ...\t\t(833.121s)\n",
      "colsample_bytree=0.6, eta=0.1, eval_metric=['mlogloss', 'auc', 'merror'], gamma=0.2, gpu_id=0, max_depth=9, min_child_weight=9, nthread=8, num_class=10, objective=multi:softmax, subsample=0.9, tree_method=gpu_hist\n",
      "colsample_bytree=1.0, eta=0.1, eval_metric=['mlogloss', 'auc', 'merror'], gamma=0.2, gpu_id=0, max_depth=9, min_child_weight=9, nthread=8, num_class=10, objective=multi:softmax, subsample=0.6, tree_method=gpu_hist\n",
      "colsample_bytree=1.0, eta=0.1, eval_metric=['mlogloss', 'auc', 'merror'], gamma=0.2, gpu_id=0, max_depth=9, min_child_weight=9, nthread=8, num_class=10, objective=multi:softmax, subsample=0.9, tree_method=gpu_hist\n",
      "开始搜索：reg_alpha=[0, 0.1, 0.2, 0.5, 1, 1.5, 2, 4]\n",
      "待搜索的参数组合数量：8\n",
      "1 / 8: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 0} ...\t\t(864.738s)\n",
      "2 / 8: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 0.1} ...\t\t(871.016s)\n",
      "3 / 8: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 0.2} ...\t\t(854.900s)\n",
      "4 / 8: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 0.5} ...\t\t(846.531s)\n",
      "5 / 8: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 1} ...\t\t(857.497s)\n",
      "6 / 8: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 1.5} ...\t\t(874.460s)\n",
      "7 / 8: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 2} ...\t\t(875.624s)\n",
      "8 / 8: 200-rounds Training finished param={'objective': 'multi:softmax', 'eta': 0.1, 'nthread': 8, 'num_class': 10, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['mlogloss', 'auc', 'merror'], 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.2, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 4} ...\t\t(902.339s)\n",
      "colsample_bytree=0.6, eta=0.1, eval_metric=['mlogloss', 'auc', 'merror'], gamma=0.2, gpu_id=0, max_depth=9, min_child_weight=9, nthread=8, num_class=10, objective=multi:softmax, reg_alpha=0, subsample=0.9, tree_method=gpu_hist\n",
      "colsample_bytree=0.6, eta=0.1, eval_metric=['mlogloss', 'auc', 'merror'], gamma=0.2, gpu_id=0, max_depth=9, min_child_weight=9, nthread=8, num_class=10, objective=multi:softmax, reg_alpha=1, subsample=0.9, tree_method=gpu_hist\n",
      "colsample_bytree=0.6, eta=0.1, eval_metric=['mlogloss', 'auc', 'merror'], gamma=0.2, gpu_id=0, max_depth=9, min_child_weight=9, nthread=8, num_class=10, objective=multi:softmax, reg_alpha=4, subsample=0.9, tree_method=gpu_hist\n",
      "找到的最棒的参数是：\n",
      "colsample_bytree=0.6, eta=0.1, eval_metric=['mlogloss', 'auc', 'merror'], gamma=0.2, gpu_id=0, max_depth=9, min_child_weight=9, nthread=8, num_class=10, objective=multi:softmax, reg_alpha=0, subsample=0.9, tree_method=gpu_hist\n"
     ]
    }
   ],
   "source": [
    "base = base_param.copy()\n",
    "base.update({'max_depth': 9, 'min_child_weight': 9})\n",
    "base.update({'gamma': .2})\n",
    "grids = [ps3, ps4]\n",
    "\n",
    "rets = []\n",
    "for grid in grids:\n",
    "    params = compose_param_grid(grid, base)\n",
    "    print(f\"开始搜索：{dict_2_str(grid)}\\n待搜索的参数组合数量：{len(params)}\")\n",
    "    ret = gridsearch_cv_xgb(data.values, watch_label_res.values, params, n_round=200, verbose_eval=False, n_class=10)\n",
    "    arr = np.array([[-e['eval-merror'] for e in ret], \n",
    "                    [-e['eval-mlogloss'] for e in ret],\n",
    "                    [e['eval-auc'] for e in ret], \n",
    "                    [e['w_auc'] for e in ret]], dtype=np.float32)\n",
    "    opt_idxs = list(set(arr.argmax(axis=1)))\n",
    "    for i in opt_idxs:\n",
    "        print(dict_2_str(ret[i]['param']))\n",
    "    opt_idx = opt_idxs[0]\n",
    "    opt_param = ret[opt_idx]['param']\n",
    "    base.update(opt_param)\n",
    "    rets.append(ret)\n",
    "    \n",
    "    ks = list(grid.keys())\n",
    "    ks = '-'.join(ks)\n",
    "    with open(f\"./logs/{ks}-watch_label-{int(time())}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(ret, f)\n",
    "    with open(f\"./logs/{ks}-watch_label-{int(time())}.md\", \"w\") as f:\n",
    "        lines = []\n",
    "        for e in ret:\n",
    "            line = metric_2_str(e)\n",
    "            lines.append(line)\n",
    "            lines.append('\\n')\n",
    "        f.write(\"\\n\".join(lines))\n",
    "\n",
    "print(f\"找到的最棒的参数是：\\n{dict_2_str(base)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'multi:softmax',\n",
       " 'eta': 0.1,\n",
       " 'nthread': 8,\n",
       " 'num_class': 10,\n",
       " 'gpu_id': 0,\n",
       " 'tree_method': 'gpu_hist',\n",
       " 'eval_metric': ['mlogloss', 'auc', 'merror'],\n",
       " 'max_depth': 9,\n",
       " 'min_child_weight': 9,\n",
       " 'gamma': 0.2,\n",
       " 'subsample': 0.9,\n",
       " 'colsample_bytree': 0.6,\n",
       " 'reg_alpha': 0}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_results = gridsearch_xgb(all_params, xg_train, xg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_cv_results_sh = gridsearch_cv_xgb(data.values, watch_label_res.values, all_params, n_round=200, verbose_eval=False, n_class=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "最小误差与最大AUC对应的模型不一致 : [93 19]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-584-646c9ffaa26f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mopt_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mopt_idxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mopt_idxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"最小误差与最大AUC对应的模型不一致 : {opt_idxs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mopt_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_idxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 最小误差与最大AUC对应的模型不一致 : [93 19]"
     ]
    }
   ],
   "source": [
    "arr = np.array([[-e['test_error'] for e in gridsearch_results], [e['w_auc'] for e in gridsearch_results]], dtype=np.float32)\n",
    "opt_idxs = arr.argmax(axis=1)\n",
    "if opt_idxs[0] != opt_idxs[1]:\n",
    "     warnings.warn(f\"最小误差与最大AUC对应的模型不一致 : {opt_idxs}。选择误差最小的模型 : {opt_idxs[0]}\")\n",
    "\n",
    "opt_idx = opt_idxs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'test_error': 0.7289070620796754,\n",
       "  'aucs': array([0.57555597, 0.58567653, 0.50347593, 0.50017473, 0.50017414,\n",
       "         0.5000983 , 0.50292636, 0.50040085, 0.50878295, 0.60767447]),\n",
       "  'w_auc': 2.365403849959146,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.33      0.19      0.24     43749\\n           1       0.29      0.68      0.41    111616\\n           2       0.23      0.01      0.03     62829\\n           3       0.13      0.00      0.00     43872\\n           4       0.15      0.00      0.00     34228\\n           5       0.18      0.00      0.00     28926\\n           6       0.33      0.01      0.01     25061\\n           7       0.16      0.00      0.00     23400\\n           8       0.31      0.02      0.04     27750\\n           9       0.24      0.56      0.34     77663\\n\\n    accuracy                           0.27    479094\\n   macro avg       0.23      0.15      0.11    479094\\nweighted avg       0.24      0.27      0.18    479094\\n',\n",
       "  'model': <xgboost.core.Booster at 0x7f35ba8b00d0>},\n",
       " {'test_error': 0.73068750600091,\n",
       "  'aucs': array([0.57882633, 0.58668642, 0.50378179, 0.50067885, 0.50046282,\n",
       "         0.50010955, 0.50312644, 0.50043677, 0.50916784, 0.60848382]),\n",
       "  'w_auc': 2.367019878746503,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.32      0.20      0.25     43749\\n           1       0.29      0.66      0.40    111616\\n           2       0.18      0.03      0.04     62829\\n           3       0.12      0.01      0.01     43872\\n           4       0.12      0.00      0.00     34228\\n           5       0.08      0.00      0.00     28926\\n           6       0.25      0.01      0.01     25061\\n           7       0.11      0.00      0.00     23400\\n           8       0.27      0.02      0.04     27750\\n           9       0.24      0.57      0.34     77663\\n\\n    accuracy                           0.27    479094\\n   macro avg       0.20      0.15      0.11    479094\\nweighted avg       0.22      0.27      0.18    479094\\n',\n",
       "  'model': <xgboost.core.Booster at 0x7f3584f94e50>})"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_results[93]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.19      0.24     43749\n",
      "           1       0.29      0.68      0.41    111616\n",
      "           2       0.23      0.01      0.03     62829\n",
      "           3       0.13      0.00      0.00     43872\n",
      "           4       0.15      0.00      0.00     34228\n",
      "           5       0.18      0.00      0.00     28926\n",
      "           6       0.33      0.01      0.01     25061\n",
      "           7       0.16      0.00      0.00     23400\n",
      "           8       0.31      0.02      0.04     27750\n",
      "           9       0.24      0.56      0.34     77663\n",
      "\n",
      "    accuracy                           0.27    479094\n",
      "   macro avg       0.23      0.15      0.11    479094\n",
      "weighted avg       0.24      0.27      0.18    479094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt_idx = opt_idxs[0]\n",
    "opt_param = all_params[opt_idx]\n",
    "print(gridsearch_results[opt_idx]['report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(479094,)"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_cv_xgb(data.values, watch_label_res, all_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 8\n",
    "param['nthread'] = 8\n",
    "param['num_class'] = 10\n",
    "# param['gpu_id'] = 0\n",
    "# param['tree_method'] = 'gpu_hist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cv_res= xgb.cv(param, cv_data, num_boost_round=200,early_stopping_rounds=30,nfold=3, metrics='auc',show_stdv=True)\n",
    "print(cv_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# is_share 预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理数据不均衡问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 7338705), (1, 14319)]\n",
      "[[0.         0.99805264]\n",
      " [1.         0.00194736]]\n"
     ]
    }
   ],
   "source": [
    "items = list(Counter(is_share).items())\n",
    "items.sort(key=lambda x: x[0])\n",
    "print(items)\n",
    "\n",
    "dist = np.array(items, dtype=np.float)\n",
    "dist[:, 1] = dist[:, 1] / is_share.shape[0]\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_ss = np.array(items)\n",
    "under_ss_thresh = under_ss[1, 1] + 800\n",
    "under_ss[:, 1] = np.clip(under_ss[:, 1], a_min=None, a_max=under_ss_thresh)\n",
    "\n",
    "over_ss = under_ss.copy()\n",
    "over_ss_thresh = under_ss[1, 1]\n",
    "over_ss[:, 1] = np.clip(over_ss[:, 1], a_min=over_ss_thresh, a_max=None)\n",
    "\n",
    "under_ss = dict(under_ss)\n",
    "over_ss = dict(over_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 15119, 1: 14319}, {0: 15119, 1: 14319})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_ss, over_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7338705,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = is_share == 0\n",
    "idxs = idxs.replace(False, np.nan).dropna().index  # 保留watch_label=0的行索引\n",
    "idxs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7323586,), (15119,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_idxs = np.random.choice(idxs, under_ss_thresh, replace=False)  # 选择一部分保留\n",
    "del_idxs = idxs.difference(left_idxs)\n",
    "del_idxs.shape, left_idxs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29438, 70), (29438,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_data = np.delete(dataset.values, del_idxs, axis=0)\n",
    "resampled_sh = np.delete(is_share.values, del_idxs, axis=0)\n",
    "resampled_data.shape, resampled_sh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29438, 70), (29438,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将采样后的数据重装会DataFrame\n",
    "data_sh = pd.DataFrame(resampled_data, columns=dataset.columns)\n",
    "is_share_res = pd.Series(resampled_sh)\n",
    "data_sh.shape, is_share_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23550,), (5888,))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx, test_idx = train_test_split(data_sh.index, test_size=0.2, random_state=1)\n",
    "train_idx.shape, test_idx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sh = data_sh.iloc[train_idx]\n",
    "X_test_sh  = data_sh.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_sh = is_share_res.iloc[train_idx]\n",
    "y_test_sh  = is_share_res.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparing finished ...\t\t(0.016s)\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "xg_train_sh = xgb.DMatrix(X_train_sh.values, label=y_train_sh.values, enable_categorical=True)\n",
    "xg_test_sh = xgb.DMatrix(X_test_sh.values, label=y_test_sh.values, enable_categorical=True)\n",
    "print(f\"Data preparing finished ...\\t\\t({time()-t0:.3f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup parameters for xgboost\n",
    "param_sh = {\n",
    "    'objective': 'binary:hinge',\n",
    "    'eta': 0.1,\n",
    "    'nthread': 8,\n",
    "    'gpu_id': 0,\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'eval_metric': ['logloss', 'auc', 'error'],\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 1,\n",
    "    'gamma': 0.1,\n",
    "    'subsample': 0.6,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'reg_alpha': 0\n",
    "}\n",
    "\n",
    "# use softmax multi-class classification\n",
    "# param_sh['objective'] = 'binary:hinge'\n",
    "# scale weight of positive examples\n",
    "# param_sh['eta'] = 0.1\n",
    "# param_sh['max_depth'] = 6\n",
    "# param_sh['nthread'] = 4\n",
    "# param_sh['gpu_id'] = 0\n",
    "# param_sh['tree_method'] = 'gpu_hist'\n",
    "# param_sh['min_child_weight'] = 7\n",
    "\n",
    "\n",
    "watchlist = [(xg_train_sh, 'train'), (xg_test_sh, 'test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:18.84463\ttrain-auc:0.50000\ttrain-error:0.51151\ttest-logloss:19.22784\ttest-auc:0.50000\ttest-error:0.52191\n",
      "[1]\ttrain-logloss:18.84463\ttrain-auc:0.50000\ttrain-error:0.51151\ttest-logloss:19.22784\ttest-auc:0.50000\ttest-error:0.52191\n",
      "[2]\ttrain-logloss:18.84463\ttrain-auc:0.50000\ttrain-error:0.51151\ttest-logloss:19.22784\ttest-auc:0.50000\ttest-error:0.52191\n",
      "[3]\ttrain-logloss:18.84463\ttrain-auc:0.50000\ttrain-error:0.51151\ttest-logloss:19.22784\ttest-auc:0.50000\ttest-error:0.52191\n",
      "[4]\ttrain-logloss:18.84463\ttrain-auc:0.50000\ttrain-error:0.51151\ttest-logloss:19.22784\ttest-auc:0.50000\ttest-error:0.52191\n",
      "[5]\ttrain-logloss:18.84463\ttrain-auc:0.50000\ttrain-error:0.51151\ttest-logloss:19.22784\ttest-auc:0.50000\ttest-error:0.52191\n",
      "[6]\ttrain-logloss:18.84463\ttrain-auc:0.50000\ttrain-error:0.51151\ttest-logloss:19.22784\ttest-auc:0.50000\ttest-error:0.52191\n",
      "[7]\ttrain-logloss:18.73512\ttrain-auc:0.50289\ttrain-error:0.50853\ttest-logloss:19.10270\ttest-auc:0.50318\ttest-error:0.51851\n",
      "[8]\ttrain-logloss:18.71166\ttrain-auc:0.50351\ttrain-error:0.50790\ttest-logloss:19.07767\ttest-auc:0.50383\ttest-error:0.51783\n",
      "[9]\ttrain-logloss:18.57712\ttrain-auc:0.50706\ttrain-error:0.50425\ttest-logloss:19.00884\ttest-auc:0.50555\ttest-error:0.51597\n",
      "[10]\ttrain-logloss:18.49421\ttrain-auc:0.50924\ttrain-error:0.50200\ttest-logloss:18.93376\ttest-auc:0.50747\ttest-error:0.51393\n",
      "[11]\ttrain-logloss:18.45822\ttrain-auc:0.51019\ttrain-error:0.50102\ttest-logloss:18.90873\ttest-auc:0.50809\ttest-error:0.51325\n",
      "[12]\ttrain-logloss:18.40973\ttrain-auc:0.51147\ttrain-error:0.49970\ttest-logloss:18.83990\ttest-auc:0.50985\ttest-error:0.51138\n",
      "[13]\ttrain-logloss:18.32056\ttrain-auc:0.51380\ttrain-error:0.49728\ttest-logloss:18.72728\ttest-auc:0.51272\ttest-error:0.50832\n",
      "[14]\ttrain-logloss:17.98265\ttrain-auc:0.52265\ttrain-error:0.48811\ttest-logloss:18.50202\ttest-auc:0.51826\ttest-error:0.50221\n",
      "[15]\ttrain-logloss:17.57122\ttrain-auc:0.53333\ttrain-error:0.47694\ttest-logloss:18.22046\ttest-auc:0.52493\ttest-error:0.49456\n",
      "[16]\ttrain-logloss:17.39444\ttrain-auc:0.53788\ttrain-error:0.47214\ttest-logloss:18.01397\ttest-auc:0.52988\ttest-error:0.48896\n",
      "[17]\ttrain-logloss:16.97049\ttrain-auc:0.54883\ttrain-error:0.46064\ttest-logloss:17.81375\ttest-auc:0.53433\ttest-error:0.48353\n",
      "[18]\ttrain-logloss:16.75148\ttrain-auc:0.55453\ttrain-error:0.45469\ttest-logloss:17.62604\ttest-auc:0.53901\ttest-error:0.47843\n",
      "[19]\ttrain-logloss:16.51369\ttrain-auc:0.56068\ttrain-error:0.44824\ttest-logloss:17.46961\ttest-auc:0.54280\ttest-error:0.47419\n",
      "[20]\ttrain-logloss:16.32284\ttrain-auc:0.56559\ttrain-error:0.44306\ttest-logloss:17.33822\ttest-auc:0.54577\ttest-error:0.47062\n",
      "[21]\ttrain-logloss:15.93017\ttrain-auc:0.57561\ttrain-error:0.43240\ttest-logloss:17.09419\ttest-auc:0.55126\ttest-error:0.46399\n",
      "[22]\ttrain-logloss:15.73932\ttrain-auc:0.58031\ttrain-error:0.42722\ttest-logloss:16.93777\ttest-auc:0.55453\ttest-error:0.45975\n",
      "[23]\ttrain-logloss:15.60009\ttrain-auc:0.58377\ttrain-error:0.42344\ttest-logloss:16.80637\ttest-auc:0.55757\ttest-error:0.45618\n",
      "[24]\ttrain-logloss:15.49371\ttrain-auc:0.58637\ttrain-error:0.42055\ttest-logloss:16.62491\ttest-auc:0.56190\ttest-error:0.45126\n",
      "[25]\ttrain-logloss:15.32475\ttrain-auc:0.59072\ttrain-error:0.41597\ttest-logloss:16.58112\ttest-auc:0.56274\ttest-error:0.45007\n",
      "[26]\ttrain-logloss:15.18552\ttrain-auc:0.59423\ttrain-error:0.41219\ttest-logloss:16.38715\ttest-auc:0.56747\ttest-error:0.44480\n",
      "[27]\ttrain-logloss:15.07445\ttrain-auc:0.59698\ttrain-error:0.40917\ttest-logloss:16.24949\ttest-auc:0.57066\ttest-error:0.44107\n",
      "[28]\ttrain-logloss:14.97433\ttrain-auc:0.59949\ttrain-error:0.40645\ttest-logloss:16.11184\ttest-auc:0.57395\ttest-error:0.43733\n",
      "[29]\ttrain-logloss:14.87890\ttrain-auc:0.60189\ttrain-error:0.40386\ttest-logloss:15.99921\ttest-auc:0.57664\ttest-error:0.43427\n",
      "[30]\ttrain-logloss:14.77565\ttrain-auc:0.60450\ttrain-error:0.40106\ttest-logloss:15.91161\ttest-auc:0.57876\ttest-error:0.43189\n",
      "[31]\ttrain-logloss:14.76314\ttrain-auc:0.60477\ttrain-error:0.40072\ttest-logloss:15.90536\ttest-auc:0.57884\ttest-error:0.43173\n",
      "[32]\ttrain-logloss:14.66458\ttrain-auc:0.60733\ttrain-error:0.39805\ttest-logloss:15.95541\ttest-auc:0.57722\ttest-error:0.43308\n",
      "[33]\ttrain-logloss:14.61452\ttrain-auc:0.60850\ttrain-error:0.39669\ttest-logloss:15.85530\ttest-auc:0.57962\ttest-error:0.43037\n",
      "[34]\ttrain-logloss:14.48311\ttrain-auc:0.61182\ttrain-error:0.39312\ttest-logloss:15.74268\ttest-auc:0.58222\ttest-error:0.42731\n",
      "[35]\ttrain-logloss:14.45965\ttrain-auc:0.61231\ttrain-error:0.39248\ttest-logloss:15.71765\ttest-auc:0.58256\ttest-error:0.42663\n",
      "[36]\ttrain-logloss:14.29382\ttrain-auc:0.61658\ttrain-error:0.38798\ttest-logloss:15.61753\ttest-auc:0.58489\ttest-error:0.42391\n",
      "[37]\ttrain-logloss:14.29852\ttrain-auc:0.61633\ttrain-error:0.38811\ttest-logloss:15.57373\ttest-auc:0.58586\ttest-error:0.42272\n",
      "[38]\ttrain-logloss:14.27505\ttrain-auc:0.61690\ttrain-error:0.38747\ttest-logloss:15.51742\ttest-auc:0.58730\ttest-error:0.42120\n",
      "[39]\ttrain-logloss:14.21091\ttrain-auc:0.61854\ttrain-error:0.38573\ttest-logloss:15.47362\ttest-auc:0.58818\ttest-error:0.42001\n",
      "[40]\ttrain-logloss:14.18432\ttrain-auc:0.61913\ttrain-error:0.38501\ttest-logloss:15.45485\ttest-auc:0.58848\ttest-error:0.41950\n",
      "[41]\ttrain-logloss:14.16085\ttrain-auc:0.61969\ttrain-error:0.38437\ttest-logloss:15.39854\ttest-auc:0.58978\ttest-error:0.41797\n",
      "[42]\ttrain-logloss:14.10453\ttrain-auc:0.62112\ttrain-error:0.38284\ttest-logloss:15.37351\ttest-auc:0.59028\ttest-error:0.41729\n",
      "[43]\ttrain-logloss:14.05447\ttrain-auc:0.62235\ttrain-error:0.38149\ttest-logloss:15.31720\ttest-auc:0.59161\ttest-error:0.41576\n",
      "[44]\ttrain-logloss:13.99346\ttrain-auc:0.62383\ttrain-error:0.37983\ttest-logloss:15.19206\ttest-auc:0.59457\ttest-error:0.41236\n",
      "[45]\ttrain-logloss:13.95122\ttrain-auc:0.62490\ttrain-error:0.37868\ttest-logloss:15.17328\ttest-auc:0.59483\ttest-error:0.41186\n",
      "[46]\ttrain-logloss:13.92150\ttrain-auc:0.62560\ttrain-error:0.37788\ttest-logloss:15.11697\ttest-auc:0.59618\ttest-error:0.41033\n",
      "[47]\ttrain-logloss:13.90273\ttrain-auc:0.62605\ttrain-error:0.37737\ttest-logloss:14.99809\ttest-auc:0.59928\ttest-error:0.40710\n",
      "[48]\ttrain-logloss:13.86205\ttrain-auc:0.62710\ttrain-error:0.37626\ttest-logloss:14.95429\ttest-auc:0.60036\ttest-error:0.40591\n",
      "[49]\ttrain-logloss:13.83389\ttrain-auc:0.62775\ttrain-error:0.37550\ttest-logloss:14.91675\ttest-auc:0.60111\ttest-error:0.40489\n",
      "[50]\ttrain-logloss:13.80104\ttrain-auc:0.62856\ttrain-error:0.37461\ttest-logloss:14.92300\ttest-auc:0.60074\ttest-error:0.40506\n",
      "[51]\ttrain-logloss:13.78070\ttrain-auc:0.62907\ttrain-error:0.37406\ttest-logloss:14.93552\ttest-auc:0.60034\ttest-error:0.40540\n",
      "[52]\ttrain-logloss:13.72438\ttrain-auc:0.63049\ttrain-error:0.37253\ttest-logloss:14.91049\ttest-auc:0.60089\ttest-error:0.40472\n",
      "[53]\ttrain-logloss:13.69779\ttrain-auc:0.63112\ttrain-error:0.37180\ttest-logloss:14.86669\ttest-auc:0.60189\ttest-error:0.40353\n",
      "[54]\ttrain-logloss:13.69936\ttrain-auc:0.63104\ttrain-error:0.37185\ttest-logloss:14.84166\ttest-auc:0.60244\ttest-error:0.40285\n",
      "[55]\ttrain-logloss:13.65712\ttrain-auc:0.63206\ttrain-error:0.37070\ttest-logloss:14.81038\ttest-auc:0.60306\ttest-error:0.40200\n",
      "[56]\ttrain-logloss:13.64147\ttrain-auc:0.63243\ttrain-error:0.37028\ttest-logloss:14.79786\ttest-auc:0.60330\ttest-error:0.40166\n",
      "[57]\ttrain-logloss:13.56951\ttrain-auc:0.63419\ttrain-error:0.36832\ttest-logloss:14.69149\ttest-auc:0.60588\ttest-error:0.39878\n",
      "[58]\ttrain-logloss:13.58046\ttrain-auc:0.63388\ttrain-error:0.36862\ttest-logloss:14.71026\ttest-auc:0.60531\ttest-error:0.39929\n",
      "[59]\ttrain-logloss:13.53040\ttrain-auc:0.63515\ttrain-error:0.36726\ttest-logloss:14.67898\ttest-auc:0.60596\ttest-error:0.39844\n",
      "[60]\ttrain-logloss:13.51163\ttrain-auc:0.63561\ttrain-error:0.36675\ttest-logloss:14.71026\ttest-auc:0.60496\ttest-error:0.39929\n",
      "[61]\ttrain-logloss:13.52102\ttrain-auc:0.63532\ttrain-error:0.36701\ttest-logloss:14.67898\ttest-auc:0.60575\ttest-error:0.39844\n",
      "[62]\ttrain-logloss:13.49598\ttrain-auc:0.63597\ttrain-error:0.36633\ttest-logloss:14.72278\ttest-auc:0.60446\ttest-error:0.39963\n",
      "[63]\ttrain-logloss:13.48503\ttrain-auc:0.63625\ttrain-error:0.36603\ttest-logloss:14.71652\ttest-auc:0.60459\ttest-error:0.39946\n",
      "[64]\ttrain-logloss:13.45688\ttrain-auc:0.63694\ttrain-error:0.36527\ttest-logloss:14.69149\ttest-auc:0.60517\ttest-error:0.39878\n",
      "[65]\ttrain-logloss:13.45688\ttrain-auc:0.63693\ttrain-error:0.36527\ttest-logloss:14.68524\ttest-auc:0.60530\ttest-error:0.39861\n",
      "[66]\ttrain-logloss:13.42402\ttrain-auc:0.63777\ttrain-error:0.36437\ttest-logloss:14.71652\ttest-auc:0.60441\ttest-error:0.39946\n",
      "[67]\ttrain-logloss:13.37396\ttrain-auc:0.63906\ttrain-error:0.36301\ttest-logloss:14.76032\ttest-auc:0.60310\ttest-error:0.40064\n",
      "[68]\ttrain-logloss:13.37083\ttrain-auc:0.63913\ttrain-error:0.36293\ttest-logloss:14.73529\ttest-auc:0.60376\ttest-error:0.39997\n",
      "[69]\ttrain-logloss:13.37083\ttrain-auc:0.63910\ttrain-error:0.36293\ttest-logloss:14.76658\ttest-auc:0.60289\ttest-error:0.40081\n",
      "[70]\ttrain-logloss:13.33016\ttrain-auc:0.64017\ttrain-error:0.36183\ttest-logloss:14.76658\ttest-auc:0.60274\ttest-error:0.40081\n",
      "[71]\ttrain-logloss:13.33485\ttrain-auc:0.64001\ttrain-error:0.36195\ttest-logloss:14.76032\ttest-auc:0.60287\ttest-error:0.40064\n",
      "[72]\ttrain-logloss:13.31452\ttrain-auc:0.64054\ttrain-error:0.36140\ttest-logloss:14.79161\ttest-auc:0.60198\ttest-error:0.40149\n",
      "[73]\ttrain-logloss:13.32547\ttrain-auc:0.64023\ttrain-error:0.36170\ttest-logloss:14.79786\ttest-auc:0.60178\ttest-error:0.40166\n",
      "[74]\ttrain-logloss:13.29731\ttrain-auc:0.64095\ttrain-error:0.36093\ttest-logloss:14.83540\ttest-auc:0.60068\ttest-error:0.40268\n",
      "[75]\ttrain-logloss:13.26289\ttrain-auc:0.64183\ttrain-error:0.36000\ttest-logloss:14.81663\ttest-auc:0.60112\ttest-error:0.40217\n",
      "[76]\ttrain-logloss:13.24725\ttrain-auc:0.64222\ttrain-error:0.35957\ttest-logloss:14.81038\ttest-auc:0.60120\ttest-error:0.40200\n",
      "[77]\ttrain-logloss:13.25976\ttrain-auc:0.64186\ttrain-error:0.35991\ttest-logloss:14.76658\ttest-auc:0.60237\ttest-error:0.40081\n",
      "[78]\ttrain-logloss:13.21127\ttrain-auc:0.64314\ttrain-error:0.35860\ttest-logloss:14.69775\ttest-auc:0.60407\ttest-error:0.39895\n",
      "[79]\ttrain-logloss:13.22691\ttrain-auc:0.64268\ttrain-error:0.35902\ttest-logloss:14.67272\ttest-auc:0.60469\ttest-error:0.39827\n",
      "[80]\ttrain-logloss:13.20501\ttrain-auc:0.64325\ttrain-error:0.35843\ttest-logloss:14.65395\ttest-auc:0.60518\ttest-error:0.39776\n",
      "[81]\ttrain-logloss:13.20501\ttrain-auc:0.64319\ttrain-error:0.35843\ttest-logloss:14.69149\ttest-auc:0.60403\ttest-error:0.39878\n",
      "[82]\ttrain-logloss:13.20657\ttrain-auc:0.64313\ttrain-error:0.35847\ttest-logloss:14.66647\ttest-auc:0.60467\ttest-error:0.39810\n",
      "[83]\ttrain-logloss:13.17998\ttrain-auc:0.64384\ttrain-error:0.35775\ttest-logloss:14.67272\ttest-auc:0.60445\ttest-error:0.39827\n",
      "[84]\ttrain-logloss:13.18623\ttrain-auc:0.64366\ttrain-error:0.35792\ttest-logloss:14.66021\ttest-auc:0.60482\ttest-error:0.39793\n",
      "[85]\ttrain-logloss:13.16590\ttrain-auc:0.64419\ttrain-error:0.35737\ttest-logloss:14.64770\ttest-auc:0.60511\ttest-error:0.39759\n",
      "[86]\ttrain-logloss:13.16121\ttrain-auc:0.64432\ttrain-error:0.35724\ttest-logloss:14.65395\ttest-auc:0.60494\ttest-error:0.39776\n",
      "[87]\ttrain-logloss:13.15025\ttrain-auc:0.64464\ttrain-error:0.35694\ttest-logloss:14.65395\ttest-auc:0.60497\ttest-error:0.39776\n",
      "[88]\ttrain-logloss:13.12679\ttrain-auc:0.64522\ttrain-error:0.35631\ttest-logloss:14.66647\ttest-auc:0.60454\ttest-error:0.39810\n",
      "[89]\ttrain-logloss:13.12053\ttrain-auc:0.64539\ttrain-error:0.35614\ttest-logloss:14.62892\ttest-auc:0.60553\ttest-error:0.39708\n",
      "[90]\ttrain-logloss:13.10645\ttrain-auc:0.64577\ttrain-error:0.35575\ttest-logloss:14.63518\ttest-auc:0.60541\ttest-error:0.39725\n",
      "[91]\ttrain-logloss:13.09707\ttrain-auc:0.64602\ttrain-error:0.35550\ttest-logloss:14.67272\ttest-auc:0.60436\ttest-error:0.39827\n",
      "[92]\ttrain-logloss:13.08768\ttrain-auc:0.64628\ttrain-error:0.35524\ttest-logloss:14.65395\ttest-auc:0.60486\ttest-error:0.39776\n",
      "[93]\ttrain-logloss:13.06578\ttrain-auc:0.64679\ttrain-error:0.35465\ttest-logloss:14.65395\ttest-auc:0.60473\ttest-error:0.39776\n",
      "[94]\ttrain-logloss:13.05795\ttrain-auc:0.64699\ttrain-error:0.35444\ttest-logloss:14.66021\ttest-auc:0.60457\ttest-error:0.39793\n",
      "[95]\ttrain-logloss:13.02823\ttrain-auc:0.64779\ttrain-error:0.35363\ttest-logloss:14.68524\ttest-auc:0.60388\ttest-error:0.39861\n",
      "[96]\ttrain-logloss:13.02041\ttrain-auc:0.64799\ttrain-error:0.35342\ttest-logloss:14.67898\ttest-auc:0.60399\ttest-error:0.39844\n",
      "[97]\ttrain-logloss:13.04075\ttrain-auc:0.64744\ttrain-error:0.35397\ttest-logloss:14.68524\ttest-auc:0.60378\ttest-error:0.39861\n",
      "[98]\ttrain-logloss:13.02667\ttrain-auc:0.64781\ttrain-error:0.35359\ttest-logloss:14.65395\ttest-auc:0.60465\ttest-error:0.39776\n",
      "[99]\ttrain-logloss:13.00633\ttrain-auc:0.64835\ttrain-error:0.35304\ttest-logloss:14.67898\ttest-auc:0.60393\ttest-error:0.39844\n",
      "[100]\ttrain-logloss:13.00007\ttrain-auc:0.64850\ttrain-error:0.35287\ttest-logloss:14.67272\ttest-auc:0.60408\ttest-error:0.39827\n",
      "[101]\ttrain-logloss:13.00320\ttrain-auc:0.64840\ttrain-error:0.35295\ttest-logloss:14.69775\ttest-auc:0.60338\ttest-error:0.39895\n",
      "[102]\ttrain-logloss:12.99538\ttrain-auc:0.64862\ttrain-error:0.35274\ttest-logloss:14.69149\ttest-auc:0.60356\ttest-error:0.39878\n",
      "[103]\ttrain-logloss:12.99694\ttrain-auc:0.64857\ttrain-error:0.35278\ttest-logloss:14.67898\ttest-auc:0.60388\ttest-error:0.39844\n",
      "[104]\ttrain-logloss:12.98599\ttrain-auc:0.64884\ttrain-error:0.35248\ttest-logloss:14.64144\ttest-auc:0.60479\ttest-error:0.39742\n",
      "[105]\ttrain-logloss:12.95471\ttrain-auc:0.64969\ttrain-error:0.35163\ttest-logloss:14.64144\ttest-auc:0.60480\ttest-error:0.39742\n",
      "[106]\ttrain-logloss:12.92811\ttrain-auc:0.65041\ttrain-error:0.35091\ttest-logloss:14.62892\ttest-auc:0.60513\ttest-error:0.39708\n",
      "[107]\ttrain-logloss:12.94063\ttrain-auc:0.65004\ttrain-error:0.35125\ttest-logloss:14.62267\ttest-auc:0.60527\ttest-error:0.39691\n",
      "[108]\ttrain-logloss:12.92342\ttrain-auc:0.65050\ttrain-error:0.35079\ttest-logloss:14.63518\ttest-auc:0.60492\ttest-error:0.39725\n",
      "[109]\ttrain-logloss:12.90465\ttrain-auc:0.65099\ttrain-error:0.35028\ttest-logloss:14.66021\ttest-auc:0.60422\ttest-error:0.39793\n",
      "[110]\ttrain-logloss:12.90777\ttrain-auc:0.65093\ttrain-error:0.35036\ttest-logloss:14.61641\ttest-auc:0.60545\ttest-error:0.39674\n",
      "[111]\ttrain-logloss:12.89213\ttrain-auc:0.65132\ttrain-error:0.34994\ttest-logloss:14.65395\ttest-auc:0.60443\ttest-error:0.39776\n",
      "[112]\ttrain-logloss:12.87805\ttrain-auc:0.65171\ttrain-error:0.34955\ttest-logloss:14.61641\ttest-auc:0.60539\ttest-error:0.39674\n",
      "[113]\ttrain-logloss:12.85928\ttrain-auc:0.65221\ttrain-error:0.34904\ttest-logloss:14.63518\ttest-auc:0.60487\ttest-error:0.39725\n",
      "[114]\ttrain-logloss:12.85459\ttrain-auc:0.65231\ttrain-error:0.34892\ttest-logloss:14.64144\ttest-auc:0.60465\ttest-error:0.39742\n",
      "[115]\ttrain-logloss:12.82955\ttrain-auc:0.65299\ttrain-error:0.34824\ttest-logloss:14.65395\ttest-auc:0.60431\ttest-error:0.39776\n",
      "[116]\ttrain-logloss:12.81860\ttrain-auc:0.65328\ttrain-error:0.34794\ttest-logloss:14.61015\ttest-auc:0.60545\ttest-error:0.39657\n",
      "[117]\ttrain-logloss:12.82486\ttrain-auc:0.65308\ttrain-error:0.34811\ttest-logloss:14.58512\ttest-auc:0.60608\ttest-error:0.39589\n",
      "[118]\ttrain-logloss:12.82486\ttrain-auc:0.65304\ttrain-error:0.34811\ttest-logloss:14.55384\ttest-auc:0.60687\ttest-error:0.39504\n",
      "[119]\ttrain-logloss:12.83112\ttrain-auc:0.65287\ttrain-error:0.34828\ttest-logloss:14.54133\ttest-auc:0.60721\ttest-error:0.39470\n",
      "[120]\ttrain-logloss:12.83738\ttrain-auc:0.65268\ttrain-error:0.34845\ttest-logloss:14.52881\ttest-auc:0.60749\ttest-error:0.39436\n",
      "[121]\ttrain-logloss:12.83425\ttrain-auc:0.65277\ttrain-error:0.34836\ttest-logloss:14.54133\ttest-auc:0.60713\ttest-error:0.39470\n",
      "[122]\ttrain-logloss:12.82017\ttrain-auc:0.65315\ttrain-error:0.34798\ttest-logloss:14.56010\ttest-auc:0.60666\ttest-error:0.39521\n",
      "[123]\ttrain-logloss:12.80922\ttrain-auc:0.65343\ttrain-error:0.34769\ttest-logloss:14.55384\ttest-auc:0.60682\ttest-error:0.39504\n",
      "[124]\ttrain-logloss:12.80296\ttrain-auc:0.65360\ttrain-error:0.34752\ttest-logloss:14.52881\ttest-auc:0.60752\ttest-error:0.39436\n",
      "[125]\ttrain-logloss:12.78575\ttrain-auc:0.65406\ttrain-error:0.34705\ttest-logloss:14.54133\ttest-auc:0.60715\ttest-error:0.39470\n",
      "[126]\ttrain-logloss:12.79044\ttrain-auc:0.65392\ttrain-error:0.34718\ttest-logloss:14.52256\ttest-auc:0.60761\ttest-error:0.39419\n",
      "[127]\ttrain-logloss:12.79514\ttrain-auc:0.65379\ttrain-error:0.34730\ttest-logloss:14.52881\ttest-auc:0.60745\ttest-error:0.39436\n",
      "[128]\ttrain-logloss:12.78106\ttrain-auc:0.65415\ttrain-error:0.34692\ttest-logloss:14.54133\ttest-auc:0.60708\ttest-error:0.39470\n",
      "[129]\ttrain-logloss:12.77793\ttrain-auc:0.65422\ttrain-error:0.34684\ttest-logloss:14.54758\ttest-auc:0.60693\ttest-error:0.39487\n",
      "[130]\ttrain-logloss:12.77480\ttrain-auc:0.65431\ttrain-error:0.34675\ttest-logloss:14.52881\ttest-auc:0.60743\ttest-error:0.39436\n",
      "[131]\ttrain-logloss:12.77011\ttrain-auc:0.65444\ttrain-error:0.34662\ttest-logloss:14.53507\ttest-auc:0.60727\ttest-error:0.39453\n",
      "[132]\ttrain-logloss:12.74821\ttrain-auc:0.65503\ttrain-error:0.34603\ttest-logloss:14.53507\ttest-auc:0.60730\ttest-error:0.39453\n",
      "[133]\ttrain-logloss:12.73100\ttrain-auc:0.65549\ttrain-error:0.34556\ttest-logloss:14.54133\ttest-auc:0.60712\ttest-error:0.39470\n",
      "[134]\ttrain-logloss:12.72318\ttrain-auc:0.65567\ttrain-error:0.34535\ttest-logloss:14.51630\ttest-auc:0.60773\ttest-error:0.39402\n",
      "[135]\ttrain-logloss:12.70753\ttrain-auc:0.65608\ttrain-error:0.34493\ttest-logloss:14.51630\ttest-auc:0.60767\ttest-error:0.39402\n",
      "[136]\ttrain-logloss:12.66529\ttrain-auc:0.65723\ttrain-error:0.34378\ttest-logloss:14.51630\ttest-auc:0.60764\ttest-error:0.39402\n",
      "[137]\ttrain-logloss:12.67624\ttrain-auc:0.65691\ttrain-error:0.34408\ttest-logloss:14.53507\ttest-auc:0.60713\ttest-error:0.39453\n",
      "[138]\ttrain-logloss:12.67468\ttrain-auc:0.65694\ttrain-error:0.34403\ttest-logloss:14.53507\ttest-auc:0.60709\ttest-error:0.39453\n",
      "[139]\ttrain-logloss:12.67155\ttrain-auc:0.65702\ttrain-error:0.34395\ttest-logloss:14.51004\ttest-auc:0.60777\ttest-error:0.39385\n",
      "[140]\ttrain-logloss:12.66686\ttrain-auc:0.65714\ttrain-error:0.34382\ttest-logloss:14.51630\ttest-auc:0.60756\ttest-error:0.39402\n",
      "[141]\ttrain-logloss:12.66529\ttrain-auc:0.65719\ttrain-error:0.34378\ttest-logloss:14.50378\ttest-auc:0.60793\ttest-error:0.39368\n",
      "[142]\ttrain-logloss:12.65591\ttrain-auc:0.65743\ttrain-error:0.34352\ttest-logloss:14.49127\ttest-auc:0.60826\ttest-error:0.39334\n",
      "[143]\ttrain-logloss:12.64339\ttrain-auc:0.65775\ttrain-error:0.34319\ttest-logloss:14.50378\ttest-auc:0.60787\ttest-error:0.39368\n",
      "[144]\ttrain-logloss:12.63714\ttrain-auc:0.65790\ttrain-error:0.34302\ttest-logloss:14.50378\ttest-auc:0.60786\ttest-error:0.39368\n",
      "[145]\ttrain-logloss:12.62618\ttrain-auc:0.65821\ttrain-error:0.34272\ttest-logloss:14.49127\ttest-auc:0.60821\ttest-error:0.39334\n",
      "[146]\ttrain-logloss:12.62618\ttrain-auc:0.65820\ttrain-error:0.34272\ttest-logloss:14.49127\ttest-auc:0.60821\ttest-error:0.39334\n",
      "[147]\ttrain-logloss:12.61836\ttrain-auc:0.65840\ttrain-error:0.34251\ttest-logloss:14.49127\ttest-auc:0.60821\ttest-error:0.39334\n",
      "[148]\ttrain-logloss:12.61523\ttrain-auc:0.65849\ttrain-error:0.34242\ttest-logloss:14.49753\ttest-auc:0.60803\ttest-error:0.39351\n",
      "[149]\ttrain-logloss:12.61680\ttrain-auc:0.65844\ttrain-error:0.34246\ttest-logloss:14.51004\ttest-auc:0.60768\ttest-error:0.39385\n",
      "150-rounds Training finished ...\t\t(0.698s)\n"
     ]
    }
   ],
   "source": [
    "num_round = 150\n",
    "t0 = time()\n",
    "sh_bst_sm = xgb.train(param_sh, xg_train_sh, num_round, watchlist)\n",
    "print(f\"{num_round}-rounds Training finished ...\\t\\t({time()-t0:.3f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error using softmax = 0.393851902173913\n"
     ]
    }
   ],
   "source": [
    "# get prediction\n",
    "pred_sh = sh_bst_sm.predict(xg_test_sh)\n",
    "error_rate = np.sum(pred_sh != y_test_sh) / y_test_sh.shape[0]\n",
    "print('Test error using softmax = {}'.format(error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({0.0: 2766, 1.0: 3122}), Counter({1: 2815, 0: 3073}))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(pred_sh), Counter(y_test_sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.57      0.60      3073\n",
      "           1       0.58      0.64      0.61      2815\n",
      "\n",
      "    accuracy                           0.61      5888\n",
      "   macro avg       0.61      0.61      0.61      5888\n",
      "weighted avg       0.61      0.61      0.61      5888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_sh = metrics.classification_report(list(y_test_sh), list(pred_sh))\n",
    "print(report_sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6076795, 0.6076795])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs_sh = auc(y_test_sh.astype(np.uint8), pred_sh.astype(np.uint8), [0, 1])\n",
    "aucs_sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_param_sh = {  # 基本参数，不需要调参\n",
    "    'objective': 'binary:hinge',\n",
    "    'eta': 0.1,\n",
    "    'nthread': 8,\n",
    "#     'num_class': 10,\n",
    "    'gpu_id': 0,\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'eval_metric': ['logloss', 'auc', 'error']\n",
    "} \n",
    "# 需要调参的参数\n",
    "ps1 = {  \n",
    "    'max_depth': list(range(5, 10, 1)),\n",
    "    'min_child_weight': list(range(1, 10, 2)),\n",
    "}\n",
    "\n",
    "ps2 = {\n",
    "    'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "}\n",
    "\n",
    "ps3 = {\n",
    "    'subsample':  [i/10.0 for i in range(6,11,1)], \n",
    "    'colsample_bytree':  [i/10.0 for i in range(6,11,1)] \n",
    "}\n",
    "\n",
    "ps4 = {'reg_alpha': [0, 0.1, 0.2, 0.5, 1, 1.5, 2, 4]}\n",
    "\n",
    "\n",
    "# com_ps_sh = list(ParameterGrid(ps_sh))\n",
    "\n",
    "\n",
    "# all_params_sh = [base_param_sh.copy() for _ in range(len(com_ps_sh))] \n",
    "# for i in range(len(com_ps_sh)):\n",
    "#     all_params_sh[i].update(com_ps_sh[i])\n",
    "\n",
    "# # print(com_ps_sh)\n",
    "# print(all_params_sh.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparing finished ...\t\t(24.924s)\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "xg_train_sh = xgb.DMatrix(X_train_sh.values, label=y_train_sh.values, enable_categorical=True)\n",
    "xg_test_sh = xgb.DMatrix(X_test_sh.values, label=y_test_sh.values, enable_categorical=True)\n",
    "print(f\"Data preparing finished ...\\t\\t({time()-t0:.3f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始搜索：max_depth=[5, 6, 7, 8, 9], min_child_weight=[1, 3, 5, 7, 9]\n",
      "待搜索的参数组合数量：25\n",
      "1 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1} ...\t\t(3.035s)\n",
      "2 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 6, 'min_child_weight': 1} ...\t\t(4.271s)\n",
      "3 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 7, 'min_child_weight': 1} ...\t\t(6.333s)\n",
      "4 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 8, 'min_child_weight': 1} ...\t\t(9.294s)\n",
      "5 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 9, 'min_child_weight': 1} ...\t\t(12.788s)\n",
      "6 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 3} ...\t\t(2.993s)\n",
      "7 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 6, 'min_child_weight': 3} ...\t\t(4.183s)\n",
      "8 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 7, 'min_child_weight': 3} ...\t\t(6.127s)\n",
      "9 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 8, 'min_child_weight': 3} ...\t\t(9.131s)\n",
      "10 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 9, 'min_child_weight': 3} ...\t\t(12.637s)\n",
      "11 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 5} ...\t\t(2.996s)\n",
      "12 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 6, 'min_child_weight': 5} ...\t\t(4.244s)\n",
      "13 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 7, 'min_child_weight': 5} ...\t\t(6.028s)\n",
      "14 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 8, 'min_child_weight': 5} ...\t\t(8.756s)\n",
      "15 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 9, 'min_child_weight': 5} ...\t\t(12.128s)\n",
      "16 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 7} ...\t\t(2.959s)\n",
      "17 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 6, 'min_child_weight': 7} ...\t\t(4.105s)\n",
      "18 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 7, 'min_child_weight': 7} ...\t\t(5.897s)\n",
      "19 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 8, 'min_child_weight': 7} ...\t\t(8.433s)\n",
      "20 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 9, 'min_child_weight': 7} ...\t\t(11.471s)\n",
      "21 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 9} ...\t\t(2.935s)\n",
      "22 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 6, 'min_child_weight': 9} ...\t\t(4.050s)\n",
      "23 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 7, 'min_child_weight': 9} ...\t\t(5.802s)\n",
      "24 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 8, 'min_child_weight': 9} ...\t\t(8.152s)\n",
      "25 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 9, 'min_child_weight': 9} ...\t\t(11.286s)\n",
      "eta=0.1, eval_metric=['logloss', 'auc', 'error'], gpu_id=0, max_depth=5, min_child_weight=1, nthread=8, objective=binary:hinge, tree_method=gpu_hist\n",
      "eta=0.1, eval_metric=['logloss', 'auc', 'error'], gpu_id=0, max_depth=7, min_child_weight=9, nthread=8, objective=binary:hinge, tree_method=gpu_hist\n",
      "开始搜索：gamma=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
      "待搜索的参数组合数量：6\n",
      "1 / 6: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1} ...\t\t(3.033s)\n",
      "2 / 6: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.2} ...\t\t(3.015s)\n",
      "3 / 6: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.3} ...\t\t(3.015s)\n",
      "4 / 6: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.4} ...\t\t(3.057s)\n",
      "5 / 6: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.5} ...\t\t(3.028s)\n",
      "6 / 6: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.6} ...\t\t(3.047s)\n",
      "eta=0.1, eval_metric=['logloss', 'auc', 'error'], gamma=0.1, gpu_id=0, max_depth=5, min_child_weight=1, nthread=8, objective=binary:hinge, tree_method=gpu_hist\n",
      "eta=0.1, eval_metric=['logloss', 'auc', 'error'], gamma=0.3, gpu_id=0, max_depth=5, min_child_weight=1, nthread=8, objective=binary:hinge, tree_method=gpu_hist\n",
      "开始搜索：colsample_bytree=[0.6, 0.7, 0.8, 0.9, 1.0], subsample=[0.6, 0.7, 0.8, 0.9, 1.0]\n",
      "待搜索的参数组合数量：25\n",
      "1 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.6, 'colsample_bytree': 0.6} ...\t\t(2.884s)\n",
      "2 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.7, 'colsample_bytree': 0.6} ...\t\t(2.922s)\n",
      "3 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.6} ...\t\t(2.947s)\n",
      "4 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.9, 'colsample_bytree': 0.6} ...\t\t(2.897s)\n",
      "5 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 1.0, 'colsample_bytree': 0.6} ...\t\t(2.930s)\n",
      "6 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.6, 'colsample_bytree': 0.7} ...\t\t(2.918s)\n",
      "7 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.7, 'colsample_bytree': 0.7} ...\t\t(2.911s)\n",
      "8 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.7} ...\t\t(2.913s)\n",
      "9 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.9, 'colsample_bytree': 0.7} ...\t\t(2.894s)\n",
      "10 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 1.0, 'colsample_bytree': 0.7} ...\t\t(2.918s)\n",
      "11 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.6, 'colsample_bytree': 0.8} ...\t\t(2.878s)\n",
      "12 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.7, 'colsample_bytree': 0.8} ...\t\t(2.942s)\n",
      "13 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} ...\t\t(2.914s)\n",
      "14 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.9, 'colsample_bytree': 0.8} ...\t\t(2.922s)\n",
      "15 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 1.0, 'colsample_bytree': 0.8} ...\t\t(2.936s)\n",
      "16 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.6, 'colsample_bytree': 0.9} ...\t\t(2.921s)\n",
      "17 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.7, 'colsample_bytree': 0.9} ...\t\t(2.938s)\n",
      "18 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.9} ...\t\t(2.965s)\n",
      "19 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.9, 'colsample_bytree': 0.9} ...\t\t(3.075s)\n",
      "20 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 1.0, 'colsample_bytree': 0.9} ...\t\t(2.903s)\n",
      "21 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.6, 'colsample_bytree': 1.0} ...\t\t(2.902s)\n",
      "22 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.7, 'colsample_bytree': 1.0} ...\t\t(2.910s)\n",
      "23 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.8, 'colsample_bytree': 1.0} ...\t\t(2.951s)\n",
      "24 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.9, 'colsample_bytree': 1.0} ...\t\t(2.914s)\n",
      "25 / 25: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 1.0, 'colsample_bytree': 1.0} ...\t\t(2.935s)\n",
      "colsample_bytree=0.6, eta=0.1, eval_metric=['logloss', 'auc', 'error'], gamma=0.1, gpu_id=0, max_depth=5, min_child_weight=1, nthread=8, objective=binary:hinge, subsample=0.6, tree_method=gpu_hist\n",
      "colsample_bytree=0.6, eta=0.1, eval_metric=['logloss', 'auc', 'error'], gamma=0.1, gpu_id=0, max_depth=5, min_child_weight=1, nthread=8, objective=binary:hinge, subsample=0.8, tree_method=gpu_hist\n",
      "开始搜索：reg_alpha=[0, 0.1, 0.2, 0.5, 1, 1.5, 2, 4]\n",
      "待搜索的参数组合数量：8\n",
      "1 / 8: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.6, 'colsample_bytree': 0.6, 'reg_alpha': 0} ...\t\t(2.778s)\n",
      "2 / 8: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.6, 'colsample_bytree': 0.6, 'reg_alpha': 0.1} ...\t\t(2.773s)\n",
      "3 / 8: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.6, 'colsample_bytree': 0.6, 'reg_alpha': 0.2} ...\t\t(2.782s)\n",
      "4 / 8: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.6, 'colsample_bytree': 0.6, 'reg_alpha': 0.5} ...\t\t(2.783s)\n",
      "5 / 8: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.6, 'colsample_bytree': 0.6, 'reg_alpha': 1} ...\t\t(2.803s)\n",
      "6 / 8: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.6, 'colsample_bytree': 0.6, 'reg_alpha': 1.5} ...\t\t(2.803s)\n",
      "7 / 8: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.6, 'colsample_bytree': 0.6, 'reg_alpha': 2} ...\t\t(2.817s)\n",
      "8 / 8: 150-rounds Training finished param={'objective': 'binary:hinge', 'eta': 0.1, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'eval_metric': ['logloss', 'auc', 'error'], 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.6, 'colsample_bytree': 0.6, 'reg_alpha': 4} ...\t\t(2.815s)\n",
      "colsample_bytree=0.6, eta=0.1, eval_metric=['logloss', 'auc', 'error'], gamma=0.1, gpu_id=0, max_depth=5, min_child_weight=1, nthread=8, objective=binary:hinge, reg_alpha=0, subsample=0.6, tree_method=gpu_hist\n",
      "colsample_bytree=0.6, eta=0.1, eval_metric=['logloss', 'auc', 'error'], gamma=0.1, gpu_id=0, max_depth=5, min_child_weight=1, nthread=8, objective=binary:hinge, reg_alpha=0.5, subsample=0.6, tree_method=gpu_hist\n",
      "找到的最棒的参数是：\n",
      "colsample_bytree=0.6, eta=0.1, eval_metric=['logloss', 'auc', 'error'], gamma=0.1, gpu_id=0, max_depth=5, min_child_weight=1, nthread=8, objective=binary:hinge, reg_alpha=0, subsample=0.6, tree_method=gpu_hist\n"
     ]
    }
   ],
   "source": [
    "base_sh = base_param_sh.copy()\n",
    "grids_sh = [ps1, ps2, ps3, ps4]\n",
    "\n",
    "rets_sh = []\n",
    "for grid in grids_sh:\n",
    "    params = compose_param_grid(grid, base_sh)\n",
    "    print(f\"开始搜索：{dict_2_str(grid)}\\n待搜索的参数组合数量：{len(params)}\")\n",
    "    ret = gridsearch_cv_xgb(data_sh.values, is_share_res.values, params, n_round=150, verbose_eval=False, n_class=2)\n",
    "    arr = np.array([[-e['eval-error'] for e in ret], \n",
    "                    [-e['eval-logloss'] for e in ret],\n",
    "                    [e['eval-auc'] for e in ret], \n",
    "                    [e['w_auc'] for e in ret]], dtype=np.float32)\n",
    "    opt_idxs = list(set(arr.argmax(axis=1)))\n",
    "    for i in opt_idxs:\n",
    "        print(dict_2_str(ret[i]['param']))\n",
    "    opt_idx = opt_idxs[0]\n",
    "    opt_param = ret[opt_idx]['param']\n",
    "    base_sh.update(opt_param)\n",
    "    rets_sh.append(ret)\n",
    "    \n",
    "    ks = list(grid.keys())\n",
    "    ks = '-'.join(ks)\n",
    "    with open(f\"./logs/{ks}-is_share-{int(time())}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(ret, f)\n",
    "    with open(f\"./logs/{ks}-is_share-{int(time())}.md\", \"w\") as f:\n",
    "        lines = []\n",
    "        for e in ret:\n",
    "            line = metric_2_str(e)\n",
    "            lines.append(line)\n",
    "            lines.append('\\n')\n",
    "        f.write(\"\\n\".join(lines))\n",
    "\n",
    "print(f\"找到的最棒的参数是：\\n{dict_2_str(base_sh)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary:hinge',\n",
       " 'eta': 0.1,\n",
       " 'nthread': 8,\n",
       " 'gpu_id': 0,\n",
       " 'tree_method': 'gpu_hist',\n",
       " 'eval_metric': ['logloss', 'auc', 'error'],\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 1,\n",
       " 'gamma': 0.1,\n",
       " 'subsample': 0.6,\n",
       " 'colsample_bytree': 0.6,\n",
       " 'reg_alpha': 0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_results_sh = gridsearch_xgb(all_params_sh, xg_train_sh, xg_test_sh, num_round=150, n_class=2, verbose_eval=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_cv_results_sh = gridsearch_cv_xgb(data_sh.values, is_share_res.values, all_params_sh, n_round=150, verbose_eval=False, n_class=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('greadsearch-cv-is_share.md', 'w') as f:\n",
    "    for ret in performance:\n",
    "        f.write(f\"# {', '.join([f'{k}={v}' for k, v in ret[0].items()])}\\n\")\n",
    "        for k, v in ret[1].items():\n",
    "            is_break = '\\n' if '\\n' in str(df) else ''\n",
    "            f.write(f\"- {k} :{is_break} {v}\\n\\n\")\n",
    "        f.write(f\"{'-'*50}\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 765,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_test_error = np.array([e[1]['mean_test_error'] for e in performance])\n",
    "mean_test_error.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary:hinge',\n",
       " 'eta': 0.1,\n",
       " 'nthread': 8,\n",
       " 'gpu_id': 0,\n",
       " 'tree_method': 'gpu_hist',\n",
       " 'gamma': 0.3,\n",
       " 'max_depth': 11,\n",
       " 'min_child_weight': 9}"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([[-e['test_error'] for e in gridsearch_results_sh], [e['aucs'][1] for e in gridsearch_results_sh]], dtype=np.float32)\n",
    "opt_idxs_sh = arr.argmax(axis=1)\n",
    "if opt_idxs_sh[0] != opt_idxs_sh[1]:\n",
    "    warnings.warn(f\"最小误差与最大AUC对应的模型不一致 : {opt_idxs_sh}。选择误差最小的模型 : {opt_idxs_sh[0]}\")\n",
    "\n",
    "opt_idx_sh = opt_idxs_sh[0]\n",
    "all_params_sh[opt_idx_sh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_idx_sh = opt_idxs_sh[0]\n",
    "opt_idx_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.44      0.49      3053\n",
      "         1.0       0.50      0.60      0.54      2835\n",
      "\n",
      "    accuracy                           0.52      5888\n",
      "   macro avg       0.52      0.52      0.51      5888\n",
      "weighted avg       0.52      0.52      0.51      5888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(gridsearch_results_sh[opt_idx_sh]['report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_error</th>\n",
       "      <th>aucs</th>\n",
       "      <th>w_auc</th>\n",
       "      <th>report</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.503057</td>\n",
       "      <td>[0.50379590202715, 0.50379590202715]</td>\n",
       "      <td>None</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>&lt;xgboost.core.Booster object at 0x7f35ba907130&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.496943</td>\n",
       "      <td>[0.508734635779073, 0.508734635779073]</td>\n",
       "      <td>None</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>&lt;xgboost.core.Booster object at 0x7f32e4009580&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.501189</td>\n",
       "      <td>[0.5048543919272165, 0.5048543919272165]</td>\n",
       "      <td>None</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>&lt;xgboost.core.Booster object at 0x7f3583f4f4f0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.502717</td>\n",
       "      <td>[0.502360357955947, 0.502360357955947]</td>\n",
       "      <td>None</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>&lt;xgboost.core.Booster object at 0x7f3574279550&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.499321</td>\n",
       "      <td>[0.5061017844072763, 0.5061017844072763]</td>\n",
       "      <td>None</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>&lt;xgboost.core.Booster object at 0x7f32e4082730&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.498132</td>\n",
       "      <td>[0.5057747576472328, 0.5057747576472328]</td>\n",
       "      <td>None</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>&lt;xgboost.core.Booster object at 0x7f32468a4640&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.497962</td>\n",
       "      <td>[0.5046665869463117, 0.5046665869463118]</td>\n",
       "      <td>None</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>&lt;xgboost.core.Booster object at 0x7f32468a4850&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.499490</td>\n",
       "      <td>[0.5026636996830249, 0.5026636996830249]</td>\n",
       "      <td>None</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>&lt;xgboost.core.Booster object at 0x7f32468a46a0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.491678</td>\n",
       "      <td>[0.5107513874519006, 0.5107513874519005]</td>\n",
       "      <td>None</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>&lt;xgboost.core.Booster object at 0x7f32468a4670&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.499151</td>\n",
       "      <td>[0.5034068320344114, 0.5034068320344114]</td>\n",
       "      <td>None</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>&lt;xgboost.core.Booster object at 0x7f32468a4820&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     test_error                                      aucs w_auc  \\\n",
       "0      0.503057      [0.50379590202715, 0.50379590202715]  None   \n",
       "1      0.496943    [0.508734635779073, 0.508734635779073]  None   \n",
       "2      0.501189  [0.5048543919272165, 0.5048543919272165]  None   \n",
       "3      0.502717    [0.502360357955947, 0.502360357955947]  None   \n",
       "4      0.499321  [0.5061017844072763, 0.5061017844072763]  None   \n",
       "..          ...                                       ...   ...   \n",
       "115    0.498132  [0.5057747576472328, 0.5057747576472328]  None   \n",
       "116    0.497962  [0.5046665869463117, 0.5046665869463118]  None   \n",
       "117    0.499490  [0.5026636996830249, 0.5026636996830249]  None   \n",
       "118    0.491678  [0.5107513874519006, 0.5107513874519005]  None   \n",
       "119    0.499151  [0.5034068320344114, 0.5034068320344114]  None   \n",
       "\n",
       "                                                report  \\\n",
       "0                  precision    recall  f1-score   ...   \n",
       "1                  precision    recall  f1-score   ...   \n",
       "2                  precision    recall  f1-score   ...   \n",
       "3                  precision    recall  f1-score   ...   \n",
       "4                  precision    recall  f1-score   ...   \n",
       "..                                                 ...   \n",
       "115                precision    recall  f1-score   ...   \n",
       "116                precision    recall  f1-score   ...   \n",
       "117                precision    recall  f1-score   ...   \n",
       "118                precision    recall  f1-score   ...   \n",
       "119                precision    recall  f1-score   ...   \n",
       "\n",
       "                                               model  \n",
       "0    <xgboost.core.Booster object at 0x7f35ba907130>  \n",
       "1    <xgboost.core.Booster object at 0x7f32e4009580>  \n",
       "2    <xgboost.core.Booster object at 0x7f3583f4f4f0>  \n",
       "3    <xgboost.core.Booster object at 0x7f3574279550>  \n",
       "4    <xgboost.core.Booster object at 0x7f32e4082730>  \n",
       "..                                               ...  \n",
       "115  <xgboost.core.Booster object at 0x7f32468a4640>  \n",
       "116  <xgboost.core.Booster object at 0x7f32468a4850>  \n",
       "117  <xgboost.core.Booster object at 0x7f32468a46a0>  \n",
       "118  <xgboost.core.Booster object at 0x7f32468a4670>  \n",
       "119  <xgboost.core.Booster object at 0x7f32468a4820>  \n",
       "\n",
       "[120 rows x 5 columns]"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gridsearch_results_sh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5185122282608695"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0)\n",
    "clf.fit(X_train_sh, y_train_sh)\n",
    "clf.score(X_test_sh, y_test_sh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = inference_dataset\n",
    "test = xgb.DMatrix(test.values, enable_categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2822180, 70), 70)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_dataset.shape, test.num_col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_wl = wl_bst_sm  # gridsearch_results[opt_idx]['model']  \n",
    "bst_sh = sh_bst_sm  # gridsearch_results_sh[opt_idx_sh]['model']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({1.0: 1625618,\n",
       "          0.0: 286330,\n",
       "          9.0: 857795,\n",
       "          2.0: 34463,\n",
       "          6.0: 2312,\n",
       "          3.0: 4274,\n",
       "          8.0: 10141,\n",
       "          7.0: 499,\n",
       "          5.0: 181,\n",
       "          4.0: 567}),\n",
       " Counter({1.0: 1030603, 0.0: 1791577}))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl = bst_wl.predict(test)\n",
    "sh = bst_sh.predict(test)\n",
    "Counter(wl), Counter(Counter(sh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2822180, 4)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['watch_label'] = wl.astype(np.uint8)\n",
    "test_df['is_share'] = sh.astype(np.uint8)\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new submission saved to ../submission-1625814091.csv\n"
     ]
    }
   ],
   "source": [
    "fn = f'../submission-{int(time())}.csv'\n",
    "test_df.to_csv(fn, index=False, sep=\",\")\n",
    "print(f\"new submission saved to {fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2822180, 4)"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf = pd.read_csv('../submission-1625404864.csv')\n",
    "tdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "widx = test_df['watch_label'] != tdf['watch_label']\n",
    "sidx = test_df['is_share'] != tdf['is_share']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(913388, 0)"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "widx.sum(), sidx.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_model_name = 'wl_model_v11'\n",
    "sh_model_name = 'sh_model_v11'\n",
    "bst_wl.save_model(wl_model_name)\n",
    "bst_sh.save_model(sh_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_log(log_name, info, log_path=\"./\"):\n",
    "    import datetime\n",
    "    with open(os.path.join(log_path, log_name), 'w') as log:\n",
    "        log.write(f\"# {datetime.datetime.now().__str__()}\\n\")\n",
    "        if info.get('comment', False):\n",
    "            log.write(f\"\\n## Comment: \\n\")\n",
    "            log.write(f\"{info['comment']}\\n\")\n",
    "            \n",
    "        log.write(f\"\\n## model name: {info['model_name']}\\n\")\n",
    "        log.write(f\"- model save path : {info['model_save_path']}\\n\")\n",
    "        \n",
    "        log.write(f\"\\n## Data setup\\n\")\n",
    "        log.write(f\"- dataset.shape : {dataset.shape}\\n\")\n",
    "        log.write(f\"- dataset.columns : {dataset.columns}\\n\")\n",
    "        log.write(f\"- is resample : {info['is_resample']}\\n\")\n",
    "        log.write(f\"- Traing_Data.shape (watch_label)  : {X_train.shape}\\n\")\n",
    "        log.write(f\"- Testing_Data.shape (watch_label) : {X_test.shape}\\n\")\n",
    "        log.write(f\"- Traing_Data.shape (is_share)  : {X_train_sh.shape}\\n\")\n",
    "        log.write(f\"- Testing_Data.shape (is_share) : {X_test_sh.shape}\\n\")\n",
    "        if info.get('is_resample', False):\n",
    "            log.write(f\"- Resampled class distribution (watch_label): \\n{Counter(resampled_wl)}\\n\")\n",
    "            log.write(f\"- Resampled class distribution (is_share): \\n{Counter(resampled_sh)}\\n\")\n",
    "            \n",
    "        log.write(f\"\\n## Model Params\\n\")\n",
    "        log.write(f\"- model params (watch_label) : \\n{info['param_wl']}\\n\")\n",
    "        log.write(f\"- model params (is_share) : \\n{info['param_sh']}\\n\")\n",
    "        \n",
    "        log.write(f\"\\n## Model's Performance\\n\")\n",
    "        log.write(f\"- Aucs (watch_label) : {info['aucs']}\\n\")\n",
    "        log.write(f\"- Weighted Aucs (watch_label) : {info['w_auc']}\\n\")\n",
    "        log.write(f\"- Aucs (is_share) : {info['aucs_sh']}\\n\")\n",
    "        \n",
    "        log.write(f\"- Classification Report (watch_label) : \\n\\n{info['report']}\\n\")\n",
    "        log.write(f\"- Classification Report (is_share) : \\n\\n{info['report_sh']}\\n\")\n",
    "        \n",
    "        log.flush()\n",
    "        \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_wl = param  # all_params[opt_idx]\n",
    "param_sh = param_sh  # all_params[opt_idx_sh]\n",
    "\n",
    "aucs = aucs  # gridsearch_results[opt_idx]['aucs']\n",
    "w_auc = w_auc  # gridsearch_results[opt_idx]['w_auc']\n",
    "aucs_sh = aucs_sh  # gridsearch_results_sh[opt_idx]['aucs']\n",
    "\n",
    "report = report  # gridsearch_results[opt_idx]['report']\n",
    "report_sh = report_sh  # gridsearch_results_sh[opt_idx]['report']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_name = \"log_v12.md\"\n",
    "info = {'is_resample': True, 'model_name': [wl_model_name, sh_model_name], 'model_save_path': os.getcwd(),\n",
    "        'comment': \"对watch_label和is_share进行网格搜索以及交叉验证，交叉验证的结果均保存为.pkl文件。\\nwatch_label的预测：基础特征，is_share的预测：基础特征。\\n此次生成的提交是：submission-1625814091.csv。官方测评得分：xxx😐\",\n",
    "        'param_wl': param_wl, 'param_sh': param_sh, 'aucs': aucs, 'w_auc': w_auc, 'aucs_sh': aucs_sh, \n",
    "        'report': report, 'report_sh': report_sh}\n",
    "write_log(log_name, info, log_path=\"./logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 服务器间同步文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推向Digix服务器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssh: connect to host 49.123.120.71 port 22: No route to host\n",
      "lost connection\n"
     ]
    }
   ],
   "source": [
    "!scp ./models.ipynb digix@49.123.120.71:/home/digix/digix/Models/models.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssh: connect to host 49.123.120.71 port 22: No route to host\n",
      "lost connection\n"
     ]
    }
   ],
   "source": [
    "!scp ./log_*.md digix@49.123.120.71:/home/digix/digix/Models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explore-data.ipynb                            100%  306KB  10.6MB/s   00:00    \n"
     ]
    }
   ],
   "source": [
    "!scp ../explore-data.ipynb digix@49.123.120.71:/home/digix/digix/explore-data.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_features.jay                            100% 9035KB  11.1MB/s   00:00    \n"
     ]
    }
   ],
   "source": [
    "!scp ../2021_3_data/traindata/video_features_data/video_features.jay digix@49.123.120.71:/home/digix/digix/dataset/new_video_features.jay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从Digix服务器拉数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM.ipynb                                100%   71KB   2.2MB/s   00:00    \n"
     ]
    }
   ],
   "source": [
    "!scp  digix@49.123.120.71:/home/digix/digix/Models/LightGBM.ipynb ./LightGBM.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scp: /home/digix/digix/Models/feature_engineering.ipynb: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!scp  digix@49.123.120.71:/home/digix/digix/Models/feature_engineering.ipynb ./feature_engineering.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utils.py                                      100% 3860     2.6MB/s   00:00    \n",
      "data_analysis.ipynb                           100% 6566KB  11.2MB/s   00:00    \n",
      "__init__.py                                   100%    0     0.0KB/s   00:00    \n",
      "__init__.cpython-36.pyc                       100%  139   128.3KB/s   00:00    \n",
      "utils.cpython-36.pyc                          100% 4120     2.6MB/s   00:00    \n",
      "video_data.ipynb                              100%   55KB   1.7MB/s   00:00    \n",
      "user_data-checkpoint.ipynb                    100%  202KB  10.1MB/s   00:00    \n",
      "data_analysis-checkpoint.ipynb                100% 6554KB  11.0MB/s   00:00    \n",
      "utils-checkpoint.py                           100% 3860     2.4MB/s   00:00    \n",
      "video_data-checkpoint.ipynb                   100%   17KB   1.4MB/s   00:00    \n",
      "user_data.ipynb                               100%  202KB  10.3MB/s   00:00    \n"
     ]
    }
   ],
   "source": [
    "!scp -r digix@49.123.120.71:/home/digix/digix/Models/Feature_Engineering/  ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_status.csv                              100% 2008KB   9.1MB/s   00:00    \n",
      "user_status.csv                               100%  138MB   9.3MB/s   00:14    \n"
     ]
    }
   ],
   "source": [
    "!scp -r digix@49.123.120.71:/home/digix/digix/dataset/traindata/video_features_data/video_status.csv ../2021_3_data/traindata/video_features_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_status.csv                               100%  168MB  11.2MB/s   00:14    \n"
     ]
    }
   ],
   "source": [
    "!scp -r digix@49.123.120.71:/home/digix/digix/dataset/traindata/user_features_data/user_status.csv ../2021_3_data/traindata/user_features_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
