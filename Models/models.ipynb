{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "import datatable as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 给定预测标签，计算AUC\n",
    "使用OVR的策略计算每个类别的AUC\n",
    "过程：\n",
    "- 选择类别i作为正类，其他类别作为负类\n",
    "- 将真实标签中不等于i的标记为0，等于i的标记为1\n",
    "- 将预测标签中不等于i的标记为0，等于ide标记为1\n",
    "- 计算混淆矩阵\n",
    "- 计算(fpr, tpr)\n",
    "- 计算AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.random.randint(0, 10, 100)\n",
    "p = np.random.randint(0, 10, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(label, predict, n):\n",
    "    \"\"\"\n",
    "    计算混淆矩阵\n",
    "    :param label: 标签，np.array类型。形状可以是(n_sample,) 或者 (n_sample, n_classes)，当为第二种形状时可以表示多标签分类的情况\n",
    "    :param predict: 预测值，与 `label` 同理\n",
    "    :param n: 类别数目\n",
    "    :return: 混淆矩阵，np.array类型。shape 为 (n, n)。$cm_{ij}$表示真实标签为 $i$，预测标签为 $j$ 的样本个数\n",
    "    \"\"\"\n",
    "    k = (label >= 0) & (label < n)\n",
    "    # bincount()函数用于统计数组内每个非负整数的个数\n",
    "    # 详见 https://docs.scipy.org/doc/numpy/reference/generated/numpy.bincount.html\n",
    "    return np.bincount(n * label[k].astype(int) + predict[k], minlength=n ** 2).reshape(n, n)\n",
    "\n",
    "\n",
    "def auc(y, p, classes):\n",
    "    \"\"\"\n",
    "    给定真实标签和预测标签，计算每个类别的auc值。实际只算出了roc曲线上一个点，即一个(fpr, tpr)，再并上(0, 0)和(1, 1)来计算auc\n",
    "    :param y: 标签，np.array类型\n",
    "    :param p: 预测标签，np.array类型\n",
    "    :param classes: 类别，list-like，表示有哪些类别\n",
    "    \"\"\"\n",
    "    all_aucs = np.zeros(len(classes))\n",
    "    for i, c in enumerate(classes):\n",
    "        _y = np.zeros_like(y)\n",
    "        _y[y==c] = 1\n",
    "        _y[y!=c] = 0\n",
    "        _p = np.zeros_like(p)\n",
    "        _p[p==c] = 1\n",
    "        _p[p!=c] = 0\n",
    "#         print(_y, _p)\n",
    "        cm = confusion_matrix(_y, _p, 2)\n",
    "#         print(cm)\n",
    "        tpr = (cm[0, 0] / (cm[0, 0] + cm[0, 1])) if (cm[0, 0] + cm[0, 1]) != 0 else 0\n",
    "        fpr = (cm[1, 0] / (cm[1, 0] + cm[1, 1])) if (cm[1, 0] + cm[1, 1]) != 0 else 0\n",
    "        tpr = [0, tpr, 1]\n",
    "        fpr = [0, fpr, 1]\n",
    "        auc = metrics.auc(fpr, tpr)\n",
    "        all_aucs[i] = auc\n",
    "        if _y.sum() == 0 or _p.sum() == 0:\n",
    "            all_aucs[i] = 0\n",
    "    return all_aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5298913  0.65555556 0.52304147 0.50747508 0.52445652 0.58219623\n",
      " 0.57264957 0.46842105 0.53379416 0.50795756]\n",
      "2.3789687141650595\n"
     ]
    }
   ],
   "source": [
    "classes = list(range(10))\n",
    "weights = np.arange(0, 1, 0.1)\n",
    "all_aucs = auc(y, p, classes)\n",
    "\n",
    "weighted_auc = (all_aucs * weights).sum()\n",
    "print(f\"{all_aucs}\\n{weighted_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "classes = list(range(2))\n",
    "y = np.array([0, 0, 1, 1])\n",
    "p = np.array([0, 1, 0, 1])\n",
    "all_aucs = auc(y, p, classes)\n",
    "\n",
    "print(f\"{all_aucs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据\n",
    "训练数据加载过程：\n",
    "1. 分别加载处理好的用户特征和视频特征，以及整合的用户历史行为数据；\n",
    "2. 从用户历史行为数据中筛掉在视频特征中没出现过的video_id；\n",
    "3. 将行为数据中的user_id、video_id替换为对应用户/视频的特征\n",
    "4. 根据不同的任务划分为`watch_label`、`is_share`的数据集\n",
    "\n",
    "推断时，类似于上述过程拼接数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datatable import join\n",
    "\n",
    "def load_npz(path):\n",
    "    npz = np.load(path, allow_pickle=True)\n",
    "    return npz\n",
    "\n",
    "\n",
    "def load_table(path, ftype=\"csv\", data_name=\"data\", column_name=\"columns\"):\n",
    "    if ftype == \"npz\":\n",
    "        npz = load_npz(path)\n",
    "        tab = pd.DataFrame(npz[data_name], columns=column_name)\n",
    "    elif ftype == \"jay\":\n",
    "        tab = dt.fread(path)\n",
    "    elif ftype == \"csv\":\n",
    "        tab = pd.read_csv(path)\n",
    "        \n",
    "    return tab\n",
    "\n",
    "        \n",
    "def merge_user_video_action(user, video, action, return_others=False):\n",
    "    \"\"\"\n",
    "    将用户特征矩阵、视频特征矩阵、行为拼接起来\n",
    "    \"\"\"\n",
    "    tab_user = dt.fread(user) if isinstance(user, str) else dt.Frame(user)\n",
    "    tab_video = dt.fread(video) if isinstance(video, str) else dt.Frame(video)\n",
    "    tab_act = dt.fread(action) if isinstance(action, str) else dt.Frame(action)\n",
    "    \n",
    "    tab_user.key = 'user_id'\n",
    "    tab_act_user = tab_act[:, :, join(tab_user)]\n",
    "    tab_video.key = 'video_id'\n",
    "    tab_act_user_video = tab_act_user[:, :, join(tab_video)]\n",
    "    \n",
    "    if not return_others:\n",
    "        return tab_act_user_video \n",
    "    else:\n",
    "        return tab_act_user_video, {\"user\": tab_user, \"video\": tab_video, \"action\": tab_act}\n",
    "\n",
    "\n",
    "\n",
    "def load_train_test_data(path=None, pre_merged=True, return_others=False, **kwargs):\n",
    "    \"\"\"\n",
    "    读取保存的训练数据\n",
    "    \"\"\" \n",
    "    if pre_merged:\n",
    "        assert path is not None\n",
    "        tab = dt.fread(path)\n",
    "#     del tab[:, ['video_id', 'user_id']]\n",
    "        return tab\n",
    "    else:\n",
    "        p_user = kwargs.get('p_user')\n",
    "        p_video = kwargs.get('p_video')\n",
    "        p_action = kwargs.get('p_action')\n",
    "        \n",
    "        if return_others:\n",
    "            tab, others = merge_user_video_action(p_user, p_video, p_action, return_others=True)\n",
    "            return tab, others\n",
    "        else:\n",
    "            tab = merge_user_video_action(p_user, p_video, p_action)\n",
    "            return tab\n",
    "\n",
    "\n",
    "def read_npz_to_df(path, data_name='data', column_name='columns'):\n",
    "    npz = np.load(path, allow_pickle=True)\n",
    "    df = pd.DataFrame(npz[data_name], columns=npz[column_name])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"../2021_3_data\"\n",
    "test_data_dir  = os.path.join(base_dir, \"testdata\")\n",
    "train_data_dir = os.path.join(base_dir, \"traindata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基础特征与附加特征合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_status = dt.fread(os.path.join(train_data_dir, \"video_features_data/video_status.csv\"))\n",
    "user_status = dt.fread(os.path.join(train_data_dir, \"user_features_data/user_status.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_user = dt.fread(os.path.join(train_data_dir, \"user_features_data/user_features.jay\"))\n",
    "tab_video = dt.fread(os.path.join(train_data_dir, \"video_features_data/video_features.jay\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_status.key = 'video_id'\n",
    "video_ws = tab_video[:, :, join(video_status)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_status.key = 'user_id'\n",
    "user_ws = tab_user[:, :, join(user_status)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ws.to_jay(os.path.join(train_data_dir, \"video_features_data/video_features_with_status.jay\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ws.to_jay(os.path.join(train_data_dir, \"user_features_data/user_features_with_status.jay\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='datatable'>\n",
       "  <table class='frame'>\n",
       "  <thead>\n",
       "    <tr class='colnames'><td class='row_index'></td><th>user_id</th><th>age_0</th><th>age_1</th><th>age_2</th><th>age_3</th><th>age_4</th><th>age_5</th><th>age_6</th><th>age_7</th><th>gender_0</th><th class='vellipsis'>&hellip;</th><th>average_watch_label</th><th>sum_watch_times</th><th>sum_comment_times</th><th>sum_collect_times</th><th>sum_share_times</th></tr>\n",
       "    <tr class='coltypes'><td class='row_index'></td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td></td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><td class='row_index'>0</td><td>1.757e+06</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td class=vellipsis>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>1</td><td>17938</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td class=vellipsis>&hellip;</td><td>0.0967742</td><td>3</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>2</td><td>4.26352e+06</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td class=vellipsis>&hellip;</td><td>0.204545</td><td>2</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>3</td><td>1.4116e+06</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td class=vellipsis>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>4</td><td>3.99224e+06</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td class=vellipsis>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>5</td><td>4.0116e+06</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td class=vellipsis>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>6</td><td>4.78556e+06</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td class=vellipsis>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>7</td><td>5.11036e+06</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td class=vellipsis>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>8</td><td>1.3212e+06</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td class=vellipsis>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>9</td><td>3.20698e+06</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td class=vellipsis>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>10</td><td>5.18172e+06</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td class=vellipsis>&hellip;</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>11</td><td>1.878e+06</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td class=vellipsis>&hellip;</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>12</td><td>3.04464e+06</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td class=vellipsis>&hellip;</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>13</td><td>108273</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td class=vellipsis>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>14</td><td>5.64838e+06</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td class=vellipsis>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22F1;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td></tr>\n",
       "    <tr><td class='row_index'>5,910,795</td><td>3.22343e+06</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td class=vellipsis>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>5,910,796</td><td>4.70783e+06</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td class=vellipsis>&hellip;</td><td>0.142857</td><td>3</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>5,910,797</td><td>5.90765e+06</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td class=vellipsis>&hellip;</td><td>0</td><td>2</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>5,910,798</td><td>3.63322e+06</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td class=vellipsis>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>5,910,799</td><td>782537</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td class=vellipsis>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "  </tbody>\n",
       "  </table>\n",
       "  <div class='footer'>\n",
       "    <div class='frame_dimensions'>5,910,800 rows &times; 36 columns</div>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<Frame#7f315506be10 5910800x36>"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过 .npz 读取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 单表读取后合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.6 s, sys: 2.4 s, total: 6 s\n",
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 单独读取每个文件再进行合并\n",
    "user_df = read_npz_to_df(os.path.join(train_data_dir, \"user_features_data/user_features.npz\"), data_name='features', column_name='columns')\n",
    "video_df = read_npz_to_df(os.path.join(train_data_dir, \"video_features_data/video_features.npz\"), data_name='features')\n",
    "action_df = read_npz_to_df(os.path.join(train_data_dir, \"all_actions.npz\"), data_name='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因为将字符串保存到 .npz时会使dtype为object，重新读回DataFrame时各个列的数据类型均为 object，所以先转换类型\n",
    "dtypes = dict(zip(video_df.columns, [np.float32] * video_df.shape[1]))\n",
    "dtypes.update({'video_name': np.str})\n",
    "video_df = video_df.astype(dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 29s, sys: 5.88 s, total: 1min 35s\n",
      "Wall time: 40.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7353024, 76)"
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 合并各个表\n",
    "df_train = merge_user_video_action(user_df, video_df, action_df)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(os.path.join(train_data_dir, \"train.npz\"), data=df_train.to_pandas().values, columns=df_train.to_pandas().columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 626 ms, sys: 0 ns, total: 626 ms\n",
      "Wall time: 721 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_df = load_table(os.path.join(test_data_dir, \"test.csv\"), ftype=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 8s, sys: 12.8 s, total: 3min 20s\n",
      "Wall time: 51.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2822180, 73)"
      ]
     },
     "execution_count": 779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_test = merge_user_video_action(user_df, video_df, test_df)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取合并好的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 2s, sys: 38.4 s, total: 3min 40s\n",
      "Wall time: 3min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7353024, 76)"
      ]
     },
     "execution_count": 806,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 直接读取保存好的合并后的训练数据\n",
    "path = os.path.join(train_data_dir, \"train.npz\")\n",
    "df_train = read_npz_to_df(path, data_name='data')\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 37s, sys: 36.9 s, total: 2min 14s\n",
      "Wall time: 5min 49s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2822180, 73)"
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 直接读取保存好的合并后的测试数据\n",
    "path = os.path.join(test_data_dir, \"test.npz\")\n",
    "df_test = read_npz_to_df(path, data_name='data')\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过 .jay 文件读取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 单表读取后合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_status = False\n",
    "if with_status:\n",
    "    user_features_name = \"user_features_with_status\"\n",
    "    video_features_name = \"video_features_with_status\"\n",
    "else:\n",
    "    user_features_name = \"user_features\"\n",
    "    video_features_name = \"video_features\"\n",
    "    \n",
    "p_user = os.path.join(train_data_dir, f\"user_features_data/{user_features_name}.jay\")\n",
    "p_video = os.path.join(train_data_dir, f\"video_features_data/{video_features_name}.jay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 36min 50s, sys: 5.33 s, total: 1h 36min 56s\n",
      "Wall time: 3min 27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7353024, 76)"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "## 使用datatable 加载训练数据\n",
    "p_act = os.path.join(train_data_dir, \"all_actions.jay\")\n",
    "\n",
    "df_train, others = load_train_test_data(None, pre_merged=False, return_others=True,\n",
    "                           **{\"p_user\": p_user, \"p_video\": p_video, \"p_action\": p_act})\n",
    "user_df = others['user']\n",
    "video_df = others['video']\n",
    "action_df = others['action']\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = df_train.to_pandas()\n",
    "np.savez(os.path.join(train_data_dir, \"train\"), data=tt.values, columns=tt.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 9s, sys: 2.91 s, total: 1min 12s\n",
      "Wall time: 1.84 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2822180, 73)"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# p_user = os.path.join(train_data_dir, \"user_features_data/user_features.jay\")\n",
    "# p_video = os.path.join(train_data_dir, \"video_features_data/video_features.jay\")\n",
    "p_act = os.path.join(test_data_dir, \"test.csv\")\n",
    "\n",
    "path = os.path.join(test_data_dir, \"test.jay\")\n",
    "kwargs = {\"p_user\": p_user, \"p_video\": p_video, \"p_action\": p_act}\n",
    "\n",
    "df_test, others = load_train_test_data(None, pre_merged=False, return_others=True, **kwargs)\n",
    "test_df = others['action']\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_df = action_df.to_pandas()\n",
    "user_df = user_df.to_pandas()\n",
    "video_df = video_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取合并好后的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 177 ms, total: 177 ms\n",
      "Wall time: 184 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7353024, 76)"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 直接读取保存好的合并后的训练数据\n",
    "path = os.path.join(train_data_dir, \"train.jay\")\n",
    "df_train = load_train_test_data(path, pre_merged=True)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 649 µs, sys: 46 µs, total: 695 µs\n",
      "Wall time: 684 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2822180, 72)"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 直接读取保存好的合并后的测试数据\n",
    "path = os.path.join(test_data_dir, \"test.jay\")\n",
    "df_test = load_train_test_data(path, pre_merged=True)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理训练数据\n",
    "可在此做一些预处理：\n",
    "- 从用户历史行为数据中筛掉在视频特征中没出现过的video_id\n",
    "- 删除多余的列\n",
    "- 调整列的顺序\n",
    "- 改变列的数据类型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.8 s, sys: 9.82 s, total: 39.6 s\n",
      "Wall time: 16.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if isinstance(df_train, dt.Frame):\n",
    "    df_train = df_train.to_pandas()\n",
    "if isinstance(df_test, dt.Frame):\n",
    "    df_test = df_test.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7353024 entries, 0 to 7353023\n",
      "Data columns (total 76 columns):\n",
      " #   Column               Dtype  \n",
      "---  ------               -----  \n",
      " 0   user_id              int64  \n",
      " 1   video_id             int64  \n",
      " 2   is_watch             int64  \n",
      " 3   is_share             int64  \n",
      " 4   watch_label          int64  \n",
      " 5   age_0                float64\n",
      " 6   age_1                float64\n",
      " 7   age_2                float64\n",
      " 8   age_3                float64\n",
      " 9   age_4                float64\n",
      " 10  age_5                float64\n",
      " 11  age_6                float64\n",
      " 12  age_7                float64\n",
      " 13  gender_0             float64\n",
      " 14  gender_1             float64\n",
      " 15  gender_2             float64\n",
      " 16  gender_3             float64\n",
      " 17  city_level_0         float64\n",
      " 18  city_level_1         float64\n",
      " 19  city_level_2         float64\n",
      " 20  city_level_3         float64\n",
      " 21  city_level_4         float64\n",
      " 22  city_level_5         float64\n",
      " 23  city_level_6         float64\n",
      " 24  city_level_7         float64\n",
      " 25  device_name_0        float64\n",
      " 26  device_name_1        float64\n",
      " 27  device_name_2        float64\n",
      " 28  device_name_3        float64\n",
      " 29  device_name_4        float64\n",
      " 30  device_name_5        float64\n",
      " 31  device_name_6        float64\n",
      " 32  device_name_7        float64\n",
      " 33  device_name_8        float64\n",
      " 34  device_name_9        float64\n",
      " 35  video_name           object \n",
      " 36  video_score          float32\n",
      " 37  video_duration       float32\n",
      " 38  video_release_year   float32\n",
      " 39  video_release_month  float32\n",
      " 40  video_release_day    float32\n",
      " 41  desc_0               float32\n",
      " 42  desc_1               float32\n",
      " 43  desc_2               float32\n",
      " 44  desc_3               float32\n",
      " 45  desc_4               float32\n",
      " 46  desc_5               float32\n",
      " 47  desc_6               float32\n",
      " 48  desc_7               float32\n",
      " 49  desc_8               float32\n",
      " 50  desc_9               float32\n",
      " 51  tags_0               float32\n",
      " 52  tags_1               float32\n",
      " 53  tags_2               float32\n",
      " 54  tags_3               float32\n",
      " 55  tags_4               float32\n",
      " 56  tags_5               float32\n",
      " 57  tags_6               float32\n",
      " 58  tags_7               float32\n",
      " 59  tags_8               float32\n",
      " 60  tags_9               float32\n",
      " 61  class_0              float32\n",
      " 62  class_1              float32\n",
      " 63  class_2              float32\n",
      " 64  class_3              float32\n",
      " 65  class_4              float32\n",
      " 66  class_5              float32\n",
      " 67  class_6              float32\n",
      " 68  class_7              float32\n",
      " 69  class_8              float32\n",
      " 70  class_9              float32\n",
      " 71  da_0                 float32\n",
      " 72  da_1                 float32\n",
      " 73  da_2                 float32\n",
      " 74  da_3                 float32\n",
      " 75  da_4                 float32\n",
      "dtypes: float32(40), float64(30), int64(5), object(1)\n",
      "memory usage: 3.1+ GB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除 video_name、is_watch 列\n",
    "df_train.drop(['video_name', 'is_watch'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'action_df' not in dir():\n",
    "    action_df = load_table(os.path.join(train_data_dir, \"all_actions.jay\")).to_pandas()\n",
    "if 'video_df' not in dir():\n",
    "    video_df = load_table(os.path.join(train_data_dir, \"video_features_data/video_features.jay\")).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7353024 entries, 0 to 7353023\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Dtype\n",
      "---  ------       -----\n",
      " 0   user_id      int64\n",
      " 1   video_id     int64\n",
      " 2   is_watch     int64\n",
      " 3   is_share     int64\n",
      " 4   watch_label  int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 280.5 MB\n"
     ]
    }
   ],
   "source": [
    "action_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([], dtype='int64')"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从用户历史行为数据中筛掉在视频特征中没出现过的video_id\n",
    "idx1 = pd.Index(action_df['video_id'].unique())\n",
    "idx2 = pd.Index(video_df['video_id'])\n",
    "not_exists = idx1.difference(idx2)\n",
    "not_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "CPU times: user 1.25 ms, sys: 0 ns, total: 1.25 ms\n",
      "Wall time: 1.07 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 将训练数据中未出现的视频剔除\n",
    "n = 0\n",
    "for vid in not_exists:\n",
    "    tn = (df_train['video_id'] == vid).sum()\n",
    "    df_train['video_id'].replace(vid, np.nan, inplace=True)\n",
    "    n += tn\n",
    "\n",
    "if n > 0:\n",
    "    df_train.dropna(axis=0, inplace=True)\n",
    "    df_train.reset_index(drop=True, inplace=True)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除 video_id、user_id列\n",
    "df_train.drop(['user_id', 'video_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7353024, 72)"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df_train\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7353024,), (7353024,), (7353024, 70))"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 准备数据\n",
    "watch_label = dataset.pop('watch_label').astype(np.uint8)\n",
    "is_share = dataset.pop('is_share').astype(np.uint8)\n",
    "watch_label.shape, is_share.shape, dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'test_df' not in dir():\n",
    "    test_df = pd.read_csv(os.path.join(test_data_dir, \"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2822180 entries, 0 to 2822179\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Dtype\n",
      "---  ------       -----\n",
      " 0   user_id      int32\n",
      " 1   video_id     int32\n",
      " 2   watch_label  uint8\n",
      " 3   is_share     uint8\n",
      "dtypes: int32(2), uint8(2)\n",
      "memory usage: 26.9 MB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2822180 entries, 0 to 2822179\n",
      "Data columns (total 72 columns):\n",
      " #   Column               Dtype  \n",
      "---  ------               -----  \n",
      " 0   user_id              float32\n",
      " 1   video_id             float32\n",
      " 2   age_0                float32\n",
      " 3   age_1                float32\n",
      " 4   age_2                float32\n",
      " 5   age_3                float32\n",
      " 6   age_4                float32\n",
      " 7   age_5                float32\n",
      " 8   age_6                float32\n",
      " 9   age_7                float32\n",
      " 10  gender_0             float32\n",
      " 11  gender_1             float32\n",
      " 12  gender_2             float32\n",
      " 13  gender_3             float32\n",
      " 14  city_level_0         float32\n",
      " 15  city_level_1         float32\n",
      " 16  city_level_2         float32\n",
      " 17  city_level_3         float32\n",
      " 18  city_level_4         float32\n",
      " 19  city_level_5         float32\n",
      " 20  city_level_6         float32\n",
      " 21  city_level_7         float32\n",
      " 22  device_name_0        float32\n",
      " 23  device_name_1        float32\n",
      " 24  device_name_2        float32\n",
      " 25  device_name_3        float32\n",
      " 26  device_name_4        float32\n",
      " 27  device_name_5        float32\n",
      " 28  device_name_6        float32\n",
      " 29  device_name_7        float32\n",
      " 30  device_name_8        float32\n",
      " 31  device_name_9        float32\n",
      " 32  video_score          float32\n",
      " 33  video_duration       float32\n",
      " 34  video_release_year   float32\n",
      " 35  video_release_month  float32\n",
      " 36  video_release_day    float32\n",
      " 37  desc_0               float32\n",
      " 38  desc_1               float32\n",
      " 39  desc_2               float32\n",
      " 40  desc_3               float32\n",
      " 41  desc_4               float32\n",
      " 42  desc_5               float32\n",
      " 43  desc_6               float32\n",
      " 44  desc_7               float32\n",
      " 45  desc_8               float32\n",
      " 46  desc_9               float32\n",
      " 47  tags_0               float32\n",
      " 48  tags_1               float32\n",
      " 49  tags_2               float32\n",
      " 50  tags_3               float32\n",
      " 51  tags_4               float32\n",
      " 52  tags_5               float32\n",
      " 53  tags_6               float32\n",
      " 54  tags_7               float32\n",
      " 55  tags_8               float32\n",
      " 56  tags_9               float32\n",
      " 57  class_0              float32\n",
      " 58  class_1              float32\n",
      " 59  class_2              float32\n",
      " 60  class_3              float32\n",
      " 61  class_4              float32\n",
      " 62  class_5              float32\n",
      " 63  class_6              float32\n",
      " 64  class_7              float32\n",
      " 65  class_8              float32\n",
      " 66  class_9              float32\n",
      " 67  da_0                 float32\n",
      " 68  da_1                 float32\n",
      " 69  da_2                 float32\n",
      " 70  da_3                 float32\n",
      " 71  da_4                 float32\n",
      "dtypes: float32(72)\n",
      "memory usage: 775.1 MB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除 video_name 列\n",
    "if 'video_name' in df_test.columns:\n",
    "    df_test.drop('video_name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([], dtype='int64')"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试数据集中存在video_id没有在视频特征中出现\n",
    "idx1 = pd.Index(test_df['video_id'].unique())\n",
    "idx2 = pd.Index(video_df['video_id'].unique())\n",
    "non_exists = idx1.difference(idx2)\n",
    "non_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在视频特征中不存在的video_id在测试数据集中出现的次数 = 0\t\t(cost 0.000s)\n",
      "CPU times: user 0 ns, sys: 430 µs, total: 430 µs\n",
      "Wall time: 390 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t0 = time()\n",
    "n = 0\n",
    "for vid in not_exists:\n",
    "    tn = (test_df['video_id'] == vid).sum()\n",
    "#     df_test = action_df[action_df['video_id'] != vid]\n",
    "    n += tn\n",
    "\n",
    "print(f\"在视频特征中不存在的video_id在测试数据集中出现的次数 = {n}\\t\\t(cost {time() - t0:.3f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除 video_id、user_id 列\n",
    "df_test.drop(['user_id', 'video_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2822180, 70)"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_dataset = df_test\n",
    "inference_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# watch_label 预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理数据不均衡问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 5176743), (1, 557421), (2, 314107), (3, 219188), (4, 172404), (5, 143001), (6, 125092), (7, 117749), (8, 138798), (9, 388521)]\n",
      "[[0.         0.70402912]\n",
      " [1.         0.0758084 ]\n",
      " [2.         0.04271807]\n",
      " [3.         0.02980923]\n",
      " [4.         0.02344668]\n",
      " [5.         0.01944792]\n",
      " [6.         0.01701232]\n",
      " [7.         0.01601368]\n",
      " [8.         0.01887632]\n",
      " [9.         0.05283826]]\n"
     ]
    }
   ],
   "source": [
    "items = list(Counter(watch_label).items())\n",
    "items.sort(key=lambda x: x[0])\n",
    "print(items)\n",
    "\n",
    "dist = np.array(items, dtype=np.float)\n",
    "dist[:, 1] = dist[:, 1] / watch_label.shape[0]\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_ss = np.array(items)\n",
    "under_ss_thresh = under_ss[3, 1]  # 设置每个类别样本数目的上限\n",
    "under_ss[:, 1] = np.clip(under_ss[:, 1], a_min=None, a_max=under_ss_thresh)\n",
    "\n",
    "over_ss = under_ss.copy()\n",
    "over_ss_thresh = under_ss[2, 1]  # 设置每个类别样本数据的下限\n",
    "over_ss[:, 1] = np.clip(over_ss[:, 1], a_min=over_ss_thresh, a_max=None)\n",
    "\n",
    "under_ss = dict(under_ss)\n",
    "over_ss = dict(over_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 219188,\n",
       "  1: 219188,\n",
       "  2: 219188,\n",
       "  3: 219188,\n",
       "  4: 172404,\n",
       "  5: 143001,\n",
       "  6: 125092,\n",
       "  7: 117749,\n",
       "  8: 138798,\n",
       "  9: 219188},\n",
       " {0: 219188,\n",
       "  1: 219188,\n",
       "  2: 219188,\n",
       "  3: 219188,\n",
       "  4: 219188,\n",
       "  5: 219188,\n",
       "  6: 219188,\n",
       "  7: 219188,\n",
       "  8: 219188,\n",
       "  9: 219188})"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_ss, over_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5176743,)"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = watch_label == 0\n",
    "idxs = idxs.replace(False, np.nan).dropna().index  # 保留watch_label=0的行索引\n",
    "idxs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4957555,), (219188,))"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_idxs = np.random.choice(idxs, under_ss_thresh, replace=False)  # 选择一部分保留，注意replace参数，为True时会重复采样\n",
    "del_idxs = idxs.difference(left_idxs)\n",
    "del_idxs.shape, left_idxs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 314107,\n",
       "         0: 5176743,\n",
       "         5: 143001,\n",
       "         4: 172404,\n",
       "         1: 557421,\n",
       "         9: 388521,\n",
       "         3: 219188,\n",
       "         8: 138798,\n",
       "         7: 117749,\n",
       "         6: 125092})"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(watch_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2395469, 70), (2395469,))"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_data = np.delete(dataset.values, del_idxs, axis=0)\n",
    "resampled_wl = np.delete(watch_label.values, del_idxs, axis=0)\n",
    "resampled_data.shape, resampled_wl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 314107,\n",
       "         5: 143001,\n",
       "         4: 172404,\n",
       "         1: 557421,\n",
       "         0: 219188,\n",
       "         9: 388521,\n",
       "         3: 219188,\n",
       "         8: 138798,\n",
       "         7: 117749,\n",
       "         6: 125092})"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(resampled_wl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 速度太慢，难以忍受！\n",
    "nm  = TomekLinks(sampling_strategy=under_ss)\n",
    "smt = SMOTE(sampling_strategy=over_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "X_r, y_r = nm.fit_resample(resampled_data, pd.Series(resampled_wl))\n",
    "print(f\"Under Sampling finished ...\\t\\t({time()-t0:.3f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_r, y_r = smt.fit_resample(X_r, y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2395469, 70), (7353024,))"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将采样后的数据重装回 DataFrame\n",
    "data = pd.DataFrame(resampled_data, columns=dataset.columns)\n",
    "watch_label_res = pd.Series(resampled_wl)\n",
    "data.shape, watch_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1916375,), (479094,))"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx, test_idx = train_test_split(data.index, test_size=0.2, random_state=0)\n",
    "train_idx.shape, test_idx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.iloc[train_idx]\n",
    "X_test  = data.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = watch_label_res.iloc[train_idx]\n",
    "y_test  = watch_label_res.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1916375, 70), (1916375,), (479094, 70), (479094,))"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparing finished ...\t\t(1.521s)\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "xg_train = xgb.DMatrix(X_train.values, label=y_train.values, enable_categorical=True)\n",
    "xg_test = xgb.DMatrix(X_test.values, label=y_test.values, enable_categorical=True)\n",
    "print(f\"Data preparing finished ...\\t\\t({time()-t0:.3f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 11\n",
    "param['min_child_weight'] = 7\n",
    "param['nthread'] = 8\n",
    "param['num_class'] = 10\n",
    "param['gpu_id'] = 0\n",
    "param['tree_method'] = 'gpu_hist'\n",
    "# param['scale_pos_weight'] = 2\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:06:12] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\ttrain-mlogloss:2.27322\ttest-mlogloss:2.27402\n",
      "[1]\ttrain-mlogloss:2.24908\ttest-mlogloss:2.25062\n",
      "[2]\ttrain-mlogloss:2.22869\ttest-mlogloss:2.23093\n",
      "[3]\ttrain-mlogloss:2.21114\ttest-mlogloss:2.21408\n",
      "[4]\ttrain-mlogloss:2.19593\ttest-mlogloss:2.19955\n",
      "[5]\ttrain-mlogloss:2.18259\ttest-mlogloss:2.18689\n",
      "[6]\ttrain-mlogloss:2.17102\ttest-mlogloss:2.17597\n",
      "[7]\ttrain-mlogloss:2.16074\ttest-mlogloss:2.16635\n",
      "[8]\ttrain-mlogloss:2.15146\ttest-mlogloss:2.15772\n",
      "[9]\ttrain-mlogloss:2.14330\ttest-mlogloss:2.15018\n",
      "[10]\ttrain-mlogloss:2.13587\ttest-mlogloss:2.14341\n",
      "[11]\ttrain-mlogloss:2.12925\ttest-mlogloss:2.13743\n",
      "[12]\ttrain-mlogloss:2.12326\ttest-mlogloss:2.13210\n",
      "[13]\ttrain-mlogloss:2.11784\ttest-mlogloss:2.12727\n",
      "[14]\ttrain-mlogloss:2.11293\ttest-mlogloss:2.12299\n",
      "[15]\ttrain-mlogloss:2.10846\ttest-mlogloss:2.11918\n",
      "[16]\ttrain-mlogloss:2.10435\ttest-mlogloss:2.11573\n",
      "[17]\ttrain-mlogloss:2.10067\ttest-mlogloss:2.11267\n",
      "[18]\ttrain-mlogloss:2.09729\ttest-mlogloss:2.10991\n",
      "[19]\ttrain-mlogloss:2.09423\ttest-mlogloss:2.10746\n",
      "[20]\ttrain-mlogloss:2.09131\ttest-mlogloss:2.10518\n",
      "[21]\ttrain-mlogloss:2.08866\ttest-mlogloss:2.10316\n",
      "[22]\ttrain-mlogloss:2.08621\ttest-mlogloss:2.10136\n",
      "[23]\ttrain-mlogloss:2.08395\ttest-mlogloss:2.09975\n",
      "[24]\ttrain-mlogloss:2.08183\ttest-mlogloss:2.09827\n",
      "[25]\ttrain-mlogloss:2.07985\ttest-mlogloss:2.09694\n",
      "[26]\ttrain-mlogloss:2.07798\ttest-mlogloss:2.09571\n",
      "[27]\ttrain-mlogloss:2.07624\ttest-mlogloss:2.09459\n",
      "[28]\ttrain-mlogloss:2.07447\ttest-mlogloss:2.09349\n",
      "[29]\ttrain-mlogloss:2.07289\ttest-mlogloss:2.09252\n",
      "[30]\ttrain-mlogloss:2.07137\ttest-mlogloss:2.09168\n",
      "[31]\ttrain-mlogloss:2.06989\ttest-mlogloss:2.09085\n",
      "[32]\ttrain-mlogloss:2.06858\ttest-mlogloss:2.09018\n",
      "[33]\ttrain-mlogloss:2.06723\ttest-mlogloss:2.08946\n",
      "[34]\ttrain-mlogloss:2.06596\ttest-mlogloss:2.08886\n",
      "[35]\ttrain-mlogloss:2.06476\ttest-mlogloss:2.08828\n",
      "[36]\ttrain-mlogloss:2.06350\ttest-mlogloss:2.08771\n",
      "[37]\ttrain-mlogloss:2.06236\ttest-mlogloss:2.08723\n",
      "[38]\ttrain-mlogloss:2.06128\ttest-mlogloss:2.08681\n",
      "[39]\ttrain-mlogloss:2.06032\ttest-mlogloss:2.08644\n",
      "[40]\ttrain-mlogloss:2.05931\ttest-mlogloss:2.08608\n",
      "[41]\ttrain-mlogloss:2.05841\ttest-mlogloss:2.08580\n",
      "[42]\ttrain-mlogloss:2.05736\ttest-mlogloss:2.08543\n",
      "[43]\ttrain-mlogloss:2.05650\ttest-mlogloss:2.08518\n",
      "[44]\ttrain-mlogloss:2.05560\ttest-mlogloss:2.08492\n",
      "[45]\ttrain-mlogloss:2.05478\ttest-mlogloss:2.08468\n",
      "[46]\ttrain-mlogloss:2.05402\ttest-mlogloss:2.08452\n",
      "[47]\ttrain-mlogloss:2.05323\ttest-mlogloss:2.08437\n",
      "[48]\ttrain-mlogloss:2.05254\ttest-mlogloss:2.08424\n",
      "[49]\ttrain-mlogloss:2.05190\ttest-mlogloss:2.08409\n",
      "[50]\ttrain-mlogloss:2.05118\ttest-mlogloss:2.08392\n",
      "[51]\ttrain-mlogloss:2.05053\ttest-mlogloss:2.08383\n",
      "[52]\ttrain-mlogloss:2.04985\ttest-mlogloss:2.08372\n",
      "[53]\ttrain-mlogloss:2.04920\ttest-mlogloss:2.08362\n",
      "[54]\ttrain-mlogloss:2.04859\ttest-mlogloss:2.08353\n",
      "[55]\ttrain-mlogloss:2.04799\ttest-mlogloss:2.08345\n",
      "[56]\ttrain-mlogloss:2.04742\ttest-mlogloss:2.08339\n",
      "[57]\ttrain-mlogloss:2.04673\ttest-mlogloss:2.08331\n",
      "[58]\ttrain-mlogloss:2.04614\ttest-mlogloss:2.08325\n",
      "[59]\ttrain-mlogloss:2.04552\ttest-mlogloss:2.08319\n",
      "[60]\ttrain-mlogloss:2.04482\ttest-mlogloss:2.08304\n",
      "[61]\ttrain-mlogloss:2.04421\ttest-mlogloss:2.08299\n",
      "[62]\ttrain-mlogloss:2.04352\ttest-mlogloss:2.08286\n",
      "[63]\ttrain-mlogloss:2.04286\ttest-mlogloss:2.08282\n",
      "[64]\ttrain-mlogloss:2.04220\ttest-mlogloss:2.08273\n",
      "[65]\ttrain-mlogloss:2.04163\ttest-mlogloss:2.08269\n",
      "[66]\ttrain-mlogloss:2.04107\ttest-mlogloss:2.08263\n",
      "[67]\ttrain-mlogloss:2.04050\ttest-mlogloss:2.08261\n",
      "[68]\ttrain-mlogloss:2.03995\ttest-mlogloss:2.08257\n",
      "[69]\ttrain-mlogloss:2.03932\ttest-mlogloss:2.08248\n",
      "[70]\ttrain-mlogloss:2.03873\ttest-mlogloss:2.08247\n",
      "[71]\ttrain-mlogloss:2.03811\ttest-mlogloss:2.08245\n",
      "[72]\ttrain-mlogloss:2.03764\ttest-mlogloss:2.08241\n",
      "[73]\ttrain-mlogloss:2.03714\ttest-mlogloss:2.08240\n",
      "[74]\ttrain-mlogloss:2.03656\ttest-mlogloss:2.08240\n",
      "[75]\ttrain-mlogloss:2.03605\ttest-mlogloss:2.08237\n",
      "[76]\ttrain-mlogloss:2.03557\ttest-mlogloss:2.08237\n",
      "[77]\ttrain-mlogloss:2.03508\ttest-mlogloss:2.08235\n",
      "[78]\ttrain-mlogloss:2.03469\ttest-mlogloss:2.08232\n",
      "[79]\ttrain-mlogloss:2.03423\ttest-mlogloss:2.08229\n",
      "[80]\ttrain-mlogloss:2.03376\ttest-mlogloss:2.08226\n",
      "[81]\ttrain-mlogloss:2.03331\ttest-mlogloss:2.08220\n",
      "[82]\ttrain-mlogloss:2.03288\ttest-mlogloss:2.08219\n",
      "[83]\ttrain-mlogloss:2.03237\ttest-mlogloss:2.08216\n",
      "[84]\ttrain-mlogloss:2.03193\ttest-mlogloss:2.08210\n",
      "[85]\ttrain-mlogloss:2.03145\ttest-mlogloss:2.08208\n",
      "[86]\ttrain-mlogloss:2.03097\ttest-mlogloss:2.08204\n",
      "[87]\ttrain-mlogloss:2.03051\ttest-mlogloss:2.08202\n",
      "[88]\ttrain-mlogloss:2.03003\ttest-mlogloss:2.08200\n",
      "[89]\ttrain-mlogloss:2.02959\ttest-mlogloss:2.08194\n",
      "[90]\ttrain-mlogloss:2.02916\ttest-mlogloss:2.08192\n",
      "[91]\ttrain-mlogloss:2.02865\ttest-mlogloss:2.08190\n",
      "[92]\ttrain-mlogloss:2.02821\ttest-mlogloss:2.08191\n",
      "[93]\ttrain-mlogloss:2.02784\ttest-mlogloss:2.08189\n",
      "[94]\ttrain-mlogloss:2.02735\ttest-mlogloss:2.08190\n",
      "[95]\ttrain-mlogloss:2.02688\ttest-mlogloss:2.08188\n",
      "[96]\ttrain-mlogloss:2.02637\ttest-mlogloss:2.08187\n",
      "[97]\ttrain-mlogloss:2.02588\ttest-mlogloss:2.08182\n",
      "[98]\ttrain-mlogloss:2.02546\ttest-mlogloss:2.08182\n",
      "[99]\ttrain-mlogloss:2.02498\ttest-mlogloss:2.08181\n",
      "[100]\ttrain-mlogloss:2.02458\ttest-mlogloss:2.08178\n",
      "[101]\ttrain-mlogloss:2.02418\ttest-mlogloss:2.08176\n",
      "[102]\ttrain-mlogloss:2.02371\ttest-mlogloss:2.08173\n",
      "[103]\ttrain-mlogloss:2.02326\ttest-mlogloss:2.08170\n",
      "[104]\ttrain-mlogloss:2.02291\ttest-mlogloss:2.08170\n",
      "[105]\ttrain-mlogloss:2.02246\ttest-mlogloss:2.08171\n",
      "[106]\ttrain-mlogloss:2.02217\ttest-mlogloss:2.08171\n",
      "[107]\ttrain-mlogloss:2.02177\ttest-mlogloss:2.08169\n",
      "[108]\ttrain-mlogloss:2.02140\ttest-mlogloss:2.08168\n",
      "[109]\ttrain-mlogloss:2.02103\ttest-mlogloss:2.08167\n",
      "[110]\ttrain-mlogloss:2.02063\ttest-mlogloss:2.08167\n",
      "[111]\ttrain-mlogloss:2.02027\ttest-mlogloss:2.08167\n",
      "[112]\ttrain-mlogloss:2.01987\ttest-mlogloss:2.08167\n",
      "[113]\ttrain-mlogloss:2.01956\ttest-mlogloss:2.08168\n",
      "[114]\ttrain-mlogloss:2.01913\ttest-mlogloss:2.08168\n",
      "[115]\ttrain-mlogloss:2.01879\ttest-mlogloss:2.08170\n",
      "[116]\ttrain-mlogloss:2.01835\ttest-mlogloss:2.08170\n",
      "[117]\ttrain-mlogloss:2.01798\ttest-mlogloss:2.08170\n",
      "[118]\ttrain-mlogloss:2.01756\ttest-mlogloss:2.08173\n",
      "[119]\ttrain-mlogloss:2.01710\ttest-mlogloss:2.08172\n",
      "[120]\ttrain-mlogloss:2.01668\ttest-mlogloss:2.08173\n",
      "[121]\ttrain-mlogloss:2.01636\ttest-mlogloss:2.08174\n",
      "[122]\ttrain-mlogloss:2.01592\ttest-mlogloss:2.08174\n",
      "[123]\ttrain-mlogloss:2.01548\ttest-mlogloss:2.08174\n",
      "[124]\ttrain-mlogloss:2.01508\ttest-mlogloss:2.08175\n",
      "[125]\ttrain-mlogloss:2.01467\ttest-mlogloss:2.08177\n",
      "[126]\ttrain-mlogloss:2.01433\ttest-mlogloss:2.08177\n",
      "[127]\ttrain-mlogloss:2.01389\ttest-mlogloss:2.08177\n",
      "[128]\ttrain-mlogloss:2.01357\ttest-mlogloss:2.08179\n",
      "[129]\ttrain-mlogloss:2.01329\ttest-mlogloss:2.08180\n",
      "[130]\ttrain-mlogloss:2.01297\ttest-mlogloss:2.08180\n",
      "[131]\ttrain-mlogloss:2.01262\ttest-mlogloss:2.08182\n",
      "[132]\ttrain-mlogloss:2.01214\ttest-mlogloss:2.08182\n",
      "[133]\ttrain-mlogloss:2.01179\ttest-mlogloss:2.08183\n",
      "[134]\ttrain-mlogloss:2.01142\ttest-mlogloss:2.08182\n",
      "[135]\ttrain-mlogloss:2.01104\ttest-mlogloss:2.08183\n",
      "[136]\ttrain-mlogloss:2.01072\ttest-mlogloss:2.08185\n",
      "[137]\ttrain-mlogloss:2.01032\ttest-mlogloss:2.08184\n",
      "[138]\ttrain-mlogloss:2.00997\ttest-mlogloss:2.08185\n",
      "[139]\ttrain-mlogloss:2.00963\ttest-mlogloss:2.08187\n",
      "[140]\ttrain-mlogloss:2.00934\ttest-mlogloss:2.08189\n",
      "[141]\ttrain-mlogloss:2.00891\ttest-mlogloss:2.08191\n",
      "[142]\ttrain-mlogloss:2.00860\ttest-mlogloss:2.08189\n",
      "[143]\ttrain-mlogloss:2.00831\ttest-mlogloss:2.08191\n",
      "[144]\ttrain-mlogloss:2.00800\ttest-mlogloss:2.08191\n",
      "[145]\ttrain-mlogloss:2.00763\ttest-mlogloss:2.08192\n",
      "[146]\ttrain-mlogloss:2.00726\ttest-mlogloss:2.08193\n",
      "[147]\ttrain-mlogloss:2.00695\ttest-mlogloss:2.08195\n",
      "[148]\ttrain-mlogloss:2.00658\ttest-mlogloss:2.08197\n",
      "[149]\ttrain-mlogloss:2.00630\ttest-mlogloss:2.08197\n",
      "[150]\ttrain-mlogloss:2.00585\ttest-mlogloss:2.08197\n",
      "[151]\ttrain-mlogloss:2.00556\ttest-mlogloss:2.08200\n",
      "[152]\ttrain-mlogloss:2.00517\ttest-mlogloss:2.08203\n",
      "[153]\ttrain-mlogloss:2.00474\ttest-mlogloss:2.08203\n",
      "[154]\ttrain-mlogloss:2.00440\ttest-mlogloss:2.08205\n",
      "[155]\ttrain-mlogloss:2.00409\ttest-mlogloss:2.08207\n",
      "[156]\ttrain-mlogloss:2.00381\ttest-mlogloss:2.08207\n",
      "[157]\ttrain-mlogloss:2.00345\ttest-mlogloss:2.08209\n",
      "[158]\ttrain-mlogloss:2.00310\ttest-mlogloss:2.08212\n",
      "[159]\ttrain-mlogloss:2.00273\ttest-mlogloss:2.08214\n",
      "[160]\ttrain-mlogloss:2.00234\ttest-mlogloss:2.08216\n",
      "[161]\ttrain-mlogloss:2.00196\ttest-mlogloss:2.08220\n",
      "[162]\ttrain-mlogloss:2.00165\ttest-mlogloss:2.08220\n",
      "[163]\ttrain-mlogloss:2.00133\ttest-mlogloss:2.08223\n",
      "[164]\ttrain-mlogloss:2.00103\ttest-mlogloss:2.08226\n",
      "[165]\ttrain-mlogloss:2.00060\ttest-mlogloss:2.08227\n",
      "[166]\ttrain-mlogloss:2.00032\ttest-mlogloss:2.08230\n",
      "[167]\ttrain-mlogloss:2.00004\ttest-mlogloss:2.08232\n",
      "[168]\ttrain-mlogloss:1.99969\ttest-mlogloss:2.08234\n",
      "[169]\ttrain-mlogloss:1.99934\ttest-mlogloss:2.08235\n",
      "[170]\ttrain-mlogloss:1.99903\ttest-mlogloss:2.08236\n",
      "[171]\ttrain-mlogloss:1.99870\ttest-mlogloss:2.08238\n",
      "[172]\ttrain-mlogloss:1.99832\ttest-mlogloss:2.08240\n",
      "[173]\ttrain-mlogloss:1.99788\ttest-mlogloss:2.08241\n",
      "[174]\ttrain-mlogloss:1.99757\ttest-mlogloss:2.08244\n",
      "[175]\ttrain-mlogloss:1.99722\ttest-mlogloss:2.08247\n",
      "[176]\ttrain-mlogloss:1.99689\ttest-mlogloss:2.08249\n",
      "[177]\ttrain-mlogloss:1.99652\ttest-mlogloss:2.08251\n",
      "[178]\ttrain-mlogloss:1.99622\ttest-mlogloss:2.08254\n",
      "[179]\ttrain-mlogloss:1.99588\ttest-mlogloss:2.08256\n",
      "[180]\ttrain-mlogloss:1.99552\ttest-mlogloss:2.08260\n",
      "[181]\ttrain-mlogloss:1.99516\ttest-mlogloss:2.08262\n",
      "[182]\ttrain-mlogloss:1.99479\ttest-mlogloss:2.08264\n",
      "[183]\ttrain-mlogloss:1.99444\ttest-mlogloss:2.08268\n",
      "[184]\ttrain-mlogloss:1.99413\ttest-mlogloss:2.08271\n",
      "[185]\ttrain-mlogloss:1.99383\ttest-mlogloss:2.08274\n",
      "[186]\ttrain-mlogloss:1.99343\ttest-mlogloss:2.08276\n",
      "[187]\ttrain-mlogloss:1.99309\ttest-mlogloss:2.08277\n",
      "[188]\ttrain-mlogloss:1.99272\ttest-mlogloss:2.08278\n",
      "[189]\ttrain-mlogloss:1.99236\ttest-mlogloss:2.08281\n",
      "[190]\ttrain-mlogloss:1.99203\ttest-mlogloss:2.08284\n",
      "[191]\ttrain-mlogloss:1.99170\ttest-mlogloss:2.08287\n",
      "[192]\ttrain-mlogloss:1.99139\ttest-mlogloss:2.08290\n",
      "[193]\ttrain-mlogloss:1.99107\ttest-mlogloss:2.08292\n",
      "[194]\ttrain-mlogloss:1.99074\ttest-mlogloss:2.08295\n",
      "[195]\ttrain-mlogloss:1.99045\ttest-mlogloss:2.08297\n",
      "[196]\ttrain-mlogloss:1.99010\ttest-mlogloss:2.08300\n",
      "[197]\ttrain-mlogloss:1.98984\ttest-mlogloss:2.08304\n",
      "[198]\ttrain-mlogloss:1.98954\ttest-mlogloss:2.08306\n",
      "[199]\ttrain-mlogloss:1.98912\ttest-mlogloss:2.08309\n",
      "200-rounds Training finished ...\t\t(193.472s)\n"
     ]
    }
   ],
   "source": [
    "num_round = 200\n",
    "t0 = time()\n",
    "wl_bst_sm = xgb.train(param, xg_train, num_round, watchlist)\n",
    "print(f\"{num_round}-rounds Training finished ...\\t\\t({time()-t0:.3f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error using softmax = 0.7301364659127436\n"
     ]
    }
   ],
   "source": [
    "# get prediction\n",
    "pred = wl_bst_sm.predict(xg_test)\n",
    "# pred = pred.astype(np.uint8)\n",
    "error_rate = np.sum(pred != y_test) / y_test.shape[0]\n",
    "print('Test error using softmax = {}'.format(error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.57430505, 0.58606509, 0.50357122, 0.50041816, 0.50033007,\n",
       "        0.50013865, 0.50273403, 0.50042983, 0.50980292, 0.60638754]),\n",
       " 2.3651799768885837)"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.arange(0, 1, 0.1)\n",
    "aucs = auc(y_test.astype(np.uint8), pred.astype(np.uint8), np.arange(param['num_class']))\n",
    "# aucs[aucs == 0.5] = 0\n",
    "w_aucs = (aucs * weights).sum()\n",
    "aucs, w_aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = metrics.classification_report(list(y_test), list(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.54      0.67     43867\n",
      "           1       0.41      0.73      0.52    111843\n",
      "           2       0.41      0.16      0.23     62804\n",
      "           3       0.46      0.13      0.20     43875\n",
      "           4       0.45      0.09      0.15     34453\n",
      "           5       0.55      0.10      0.17     28592\n",
      "           6       0.46      0.05      0.08     24837\n",
      "           7       0.56      0.07      0.12     23675\n",
      "           8       0.39      0.07      0.12     27616\n",
      "           9       0.31      0.75      0.43     77532\n",
      "\n",
      "    accuracy                           0.40    479094\n",
      "   macro avg       0.49      0.27      0.27    479094\n",
      "weighted avg       0.46      0.40      0.34    479094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from collections.abc import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_xgb(param, cv, X, y, n_rounds=200, n_splits=5, stratified=True, shuffle=True, random_state=444):\n",
    "    if isinstance(cv, int):\n",
    "        if stratified:\n",
    "            cv = StratifiedFold(n_splits, shuffle=shuffle, random_state=random_state)\n",
    "        else:\n",
    "            cv = KFold(n_splits, shuffle=shuffle, random_state=random_state)\n",
    "    \n",
    "    results = []\n",
    "    if not isinstance(X, np.ndarray):\n",
    "        X = np.array(X)\n",
    "    if not isinstance(y, np.ndarray):\n",
    "        y = np.array(y)\n",
    "    \n",
    "    \n",
    "    num_round = n_rounds\n",
    "    for i, train_idxs, test_idxs in enumerate(cv.split(X, y)):\n",
    "        X_train = X[train_idxs]\n",
    "        X_test  = X[test_idxs]\n",
    "        y_train = y[train_idxs]\n",
    "        y_test  = y[test_idxs]\n",
    "        \n",
    "        xg_train = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)\n",
    "        xg_test = xgb.DMatrix(X_test, label=y_test, enable_categorical=True)\n",
    "        \n",
    "        \n",
    "        t0 = time()\n",
    "        model = xgb.train(param, xg_train, num_round, watchlist)\n",
    "#         print(f\"{num_round}-rounds Training finished ...\\t\\t({time()-t0:.3f}s)\")\n",
    "\n",
    "        # get prediction\n",
    "        pred = model.predict(xg_test)\n",
    "        # pred = pred.astype(np.uint8)\n",
    "        error_rate = np.sum(pred != y_test) / y_test.shape[0]\n",
    "        print('Test error using softmax = {}'.format(error_rate))\n",
    "\n",
    "        weights = np.arange(0, 1, 0.1)\n",
    "        aucs = auc(y_test.astype(np.uint8), pred.astype(np.uint8), np.arange(param.get('num_class', 2)))\n",
    "        # aucs[aucs == 0.5] = 0\n",
    "        w_aucs = (aucs * weights).sum()\n",
    "        aucs, w_aucs\n",
    "\n",
    "        rep = metrics.classification_report(list(y_test), list(pred))\n",
    "        results.append({\n",
    "            'test_error': error_rate, \n",
    "            'aucs': aucs,\n",
    "            'w_auc': w_aucs,\n",
    "            'report': rep,\n",
    "#             'model': model,\n",
    "            'split': i\n",
    "        })\n",
    "\n",
    "\n",
    "def gridsearch_xgb(grid_params, xg_train, xg_test, num_round=200):\n",
    "    \"\"\"\n",
    "    xg_train, xg_test: DMatrix\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    num_round = num_round\n",
    "    for i, p in enumerate(all_params):\n",
    "        t0 = time()\n",
    "        model = xgb.train(p, xg_train, num_round, watchlist)\n",
    "        print(f\"{num_round}-rounds Training finished ...\\t\\t({time()-t0:.3f}s)\")\n",
    "\n",
    "        # get prediction\n",
    "        pred = model.predict(xg_test)\n",
    "        # pred = pred.astype(np.uint8)\n",
    "        error_rate = np.sum(pred != y_test) / y_test.shape[0]\n",
    "        print('Test error using softmax = {}'.format(error_rate))\n",
    "\n",
    "        weights = np.arange(0, 1, 0.1)\n",
    "        aucs = auc(y_test.astype(np.uint8), pred.astype(np.uint8), np.arange(param['num_class']))\n",
    "        # aucs[aucs == 0.5] = 0\n",
    "        w_aucs = (aucs * weights).sum()\n",
    "        aucs, w_aucs\n",
    "\n",
    "        rep = metrics.classification_report(list(y_test), list(pred))\n",
    "        results.append({\n",
    "            'test_error': error_rate, \n",
    "            'aucs': aucs,\n",
    "            'w_auc': w_aucs,\n",
    "            'report': rep,\n",
    "            'model': model\n",
    "        })\n",
    "\n",
    "        print(f\"{i} : {num_round}-rounds Training finished ...\\t\\t({time()-t0:.3f}s)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def gridsearch_cv_xgb(X, y, param_grid, n_splits=5, random_state=444):\n",
    "    results = []\n",
    "    num_rounds = 200\n",
    "    for i, p in enumerate(all_params):  # 针对一组超参数进行cv\n",
    "        t0 = time()\n",
    "        cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "        ret = cv_xgb(p, cv, X, y, n_rounds=num_rounds, n_splits=n_splits, stratified=True, shuffle=True, random_state=444)\n",
    "        \n",
    "        ret['param'] = p\n",
    "        results.append(ret)\n",
    "\n",
    "        print(f\"{i} : {num_round}-rounds Training finished param={p} ...\\t\\t({time()-t0:.3f}s)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def myproduct(*iterables):\n",
    "    n = len(iterables)\n",
    "    if n == 0:\n",
    "        return None\n",
    "    if n == 1:\n",
    "        return iterables\n",
    "    \n",
    "    ret = []\n",
    "    ret.extend([[e] for e in iterables[0].copy()])\n",
    "\n",
    "    # 将需要调参的参数进行组合，即笛卡尔乘积。类似于sklearn中的 ParameterGrid\n",
    "    for k in range(1, n):\n",
    "        v = iterables[k].copy()\n",
    "        l = len(ret)\n",
    "        ret = [ret[i%l].copy() for i in range(len(v) * len(ret))]\n",
    "        for i, e in enumerate(ret):\n",
    "            e.append(v[i // l])\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "base_param = {  # 基本参数，不需要调参\n",
    "    'objective': 'multi:softmax',\n",
    "    'eta': 0.1,\n",
    "    'nthread': 8,\n",
    "    'num_class': 10,\n",
    "    'gpu_id': 0,\n",
    "    'tree_method': 'gpu_hist'\n",
    "} \n",
    "ps = {  # 需要调参的参数\n",
    "    'max_depth': list(range(5, 14, 2)),\n",
    "    'min_child_weight': list(range(1, 10, 2)),\n",
    "    'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6],\n",
    "}\n",
    "\n",
    "# 将需要调参的参数进行组合，即笛卡尔乘积。类似于sklearn中的 ParameterGrid\n",
    "items = list(ps.items())\n",
    "iterables = [item[1] for item in items]\n",
    "keys = [item[0] for item in items]\n",
    "\n",
    "ret = myproduct(*iterables)\n",
    "com_ps = [dict(zip(keys, e)) for e in ret]\n",
    "\n",
    "\n",
    "all_params = [base_param.copy() for _ in range(len(com_ps))] \n",
    "for i in range(len(com_ps)):\n",
    "    all_params[i].update(com_ps[i])\n",
    "    \n",
    "print(com_ps.__len__())    \n",
    "# print(all_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparing finished ...\t\t(5.092s)\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "xg_train = xgb.DMatrix(X_train.values, label=y_train.values, enable_categorical=True)\n",
    "xg_test = xgb.DMatrix(X_test.values, label=y_test.values, enable_categorical=True)\n",
    "print(f\"Data preparing finished ...\\t\\t({time()-t0:.3f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[185]\ttrain-mlogloss:1.97290\ttest-mlogloss:1.98271\n",
      "[186]\ttrain-mlogloss:1.97290\ttest-mlogloss:1.98271\n",
      "[187]\ttrain-mlogloss:1.97290\ttest-mlogloss:1.98271\n"
     ]
    }
   ],
   "source": [
    "gridsearch_results = gridsearch_xgb(all_params, xg_train, xg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[-e['test_error'] for e in results], [e['w_auc'] for e in results]], dtype=np.float32)\n",
    "opt_idxs = arr.argmax(axis=1)\n",
    "if opt_idxs[0] != opt_idxs[1]:\n",
    "    raise ValueError(f\"最小误差与最大AUC对应的模型不一致 : {opt_idxs}\")\n",
    "else:\n",
    "    opt_idx = opt_idxs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-501-ff41abadd3c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgridsearch_cv_xgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwatch_label_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'all_params' is not defined"
     ]
    }
   ],
   "source": [
    "gridsearch_cv_xgb(data.values, watch_label_res, all_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 8\n",
    "param['nthread'] = 8\n",
    "param['num_class'] = 10\n",
    "# param['gpu_id'] = 0\n",
    "# param['tree_method'] = 'gpu_hist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cv_res= xgb.cv(param, cv_data, num_boost_round=200,early_stopping_rounds=30,nfold=3, metrics='auc',show_stdv=True)\n",
    "print(cv_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# is_share 预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理数据不均衡问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 7338705), (1, 14319)]\n",
      "[[0.         0.99805264]\n",
      " [1.         0.00194736]]\n"
     ]
    }
   ],
   "source": [
    "items = list(Counter(is_share).items())\n",
    "items.sort(key=lambda x: x[0])\n",
    "print(items)\n",
    "\n",
    "dist = np.array(items, dtype=np.float)\n",
    "dist[:, 1] = dist[:, 1] / is_share.shape[0]\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_ss = np.array(items)\n",
    "under_ss_thresh = under_ss[1, 1] + 800\n",
    "under_ss[:, 1] = np.clip(under_ss[:, 1], a_min=None, a_max=under_ss_thresh)\n",
    "\n",
    "over_ss = under_ss.copy()\n",
    "over_ss_thresh = under_ss[1, 1]\n",
    "over_ss[:, 1] = np.clip(over_ss[:, 1], a_min=over_ss_thresh, a_max=None)\n",
    "\n",
    "under_ss = dict(under_ss)\n",
    "over_ss = dict(over_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 15119, 1: 14319}, {0: 15119, 1: 14319})"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_ss, over_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7338705,)"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = is_share == 0\n",
    "idxs = idxs.replace(False, np.nan).dropna().index  # 保留watch_label=0的行索引\n",
    "idxs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7323586,), (15119,))"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_idxs = np.random.choice(idxs, under_ss_thresh, replace=False)  # 选择一部分保留\n",
    "del_idxs = idxs.difference(left_idxs)\n",
    "del_idxs.shape, left_idxs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29438, 70), (29438,))"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_data = np.delete(dataset.values, del_idxs, axis=0)\n",
    "resampled_sh = np.delete(is_share.values, del_idxs, axis=0)\n",
    "resampled_data.shape, resampled_sh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2395469, 70), (7353024,))"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将采样后的数据重装会DataFrame\n",
    "data_sh = pd.DataFrame(resampled_data, columns=dataset.columns)\n",
    "is_share_res = pd.Series(resampled_sh)\n",
    "data.shape, is_share.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23550,), (5888,))"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx, test_idx = train_test_split(data_sh.index, test_size=0.2, random_state=1)\n",
    "train_idx.shape, test_idx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sh = data_sh.iloc[train_idx]\n",
    "X_test_sh  = data_sh.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_sh = is_share_res.iloc[train_idx]\n",
    "y_test_sh  = is_share_res.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparing finished ...\t\t(0.023s)\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "xg_train_sh = xgb.DMatrix(X_train_sh.values, label=y_train_sh.values, enable_categorical=True)\n",
    "xg_test_sh = xgb.DMatrix(X_test_sh.values, label=y_test_sh.values, enable_categorical=True)\n",
    "print(f\"Data preparing finished ...\\t\\t({time()-t0:.3f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup parameters for xgboost\n",
    "param_sh = {}\n",
    "# use softmax multi-class classification\n",
    "param_sh['objective'] = 'binary:hinge'\n",
    "# scale weight of positive examples\n",
    "param_sh['eta'] = 0.1\n",
    "param_sh['max_depth'] = 6\n",
    "param_sh['nthread'] = 4\n",
    "param_sh['gpu_id'] = 0\n",
    "param_sh['tree_method'] = 'gpu_hist'\n",
    "# param_sh['min_child_weight'] = 7\n",
    "\n",
    "\n",
    "watchlist = [(xg_train_sh, 'train'), (xg_test_sh, 'test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.51236\ttest-error:0.51851\n",
      "[1]\ttrain-error:0.51236\ttest-error:0.51851\n",
      "[2]\ttrain-error:0.51236\ttest-error:0.51851\n",
      "[3]\ttrain-error:0.51236\ttest-error:0.51851\n",
      "[4]\ttrain-error:0.51236\ttest-error:0.51851\n",
      "[5]\ttrain-error:0.51134\ttest-error:0.51783\n",
      "[6]\ttrain-error:0.50297\ttest-error:0.51172\n",
      "[7]\ttrain-error:0.50157\ttest-error:0.51087\n",
      "[8]\ttrain-error:0.50110\ttest-error:0.50934\n",
      "[9]\ttrain-error:0.50081\ttest-error:0.50917\n",
      "[10]\ttrain-error:0.49983\ttest-error:0.50968\n",
      "[11]\ttrain-error:0.48858\ttest-error:0.49966\n",
      "[12]\ttrain-error:0.48726\ttest-error:0.49796\n",
      "[13]\ttrain-error:0.47091\ttest-error:0.48403\n",
      "[14]\ttrain-error:0.45427\ttest-error:0.47130\n",
      "[15]\ttrain-error:0.44832\ttest-error:0.46365\n",
      "[16]\ttrain-error:0.44484\ttest-error:0.46128\n",
      "[17]\ttrain-error:0.43257\ttest-error:0.44837\n",
      "[18]\ttrain-error:0.42514\ttest-error:0.43886\n",
      "[19]\ttrain-error:0.42064\ttest-error:0.43886\n",
      "[20]\ttrain-error:0.41677\ttest-error:0.43393\n",
      "[21]\ttrain-error:0.41350\ttest-error:0.43376\n",
      "[22]\ttrain-error:0.41028\ttest-error:0.43308\n",
      "[23]\ttrain-error:0.40747\ttest-error:0.42935\n",
      "[24]\ttrain-error:0.40314\ttest-error:0.42612\n",
      "[25]\ttrain-error:0.39983\ttest-error:0.42578\n",
      "[26]\ttrain-error:0.39529\ttest-error:0.41933\n",
      "[27]\ttrain-error:0.39181\ttest-error:0.41712\n",
      "[28]\ttrain-error:0.38913\ttest-error:0.41491\n",
      "[29]\ttrain-error:0.38539\ttest-error:0.41219\n",
      "[30]\ttrain-error:0.38391\ttest-error:0.41016\n",
      "[31]\ttrain-error:0.38272\ttest-error:0.40863\n",
      "[32]\ttrain-error:0.38055\ttest-error:0.40744\n",
      "[33]\ttrain-error:0.37983\ttest-error:0.40523\n",
      "[34]\ttrain-error:0.37754\ttest-error:0.40438\n",
      "[35]\ttrain-error:0.37643\ttest-error:0.40268\n",
      "[36]\ttrain-error:0.37546\ttest-error:0.40319\n",
      "[37]\ttrain-error:0.37469\ttest-error:0.40217\n",
      "[38]\ttrain-error:0.37274\ttest-error:0.40098\n",
      "[39]\ttrain-error:0.37146\ttest-error:0.39980\n",
      "[40]\ttrain-error:0.37083\ttest-error:0.39929\n",
      "[41]\ttrain-error:0.36905\ttest-error:0.39912\n",
      "[42]\ttrain-error:0.36739\ttest-error:0.39895\n",
      "[43]\ttrain-error:0.36705\ttest-error:0.39912\n",
      "[44]\ttrain-error:0.36671\ttest-error:0.39844\n",
      "[45]\ttrain-error:0.36628\ttest-error:0.39793\n",
      "[46]\ttrain-error:0.36561\ttest-error:0.39640\n",
      "[47]\ttrain-error:0.36471\ttest-error:0.39572\n",
      "[48]\ttrain-error:0.36225\ttest-error:0.39385\n",
      "[49]\ttrain-error:0.36174\ttest-error:0.39419\n",
      "[50]\ttrain-error:0.36174\ttest-error:0.39487\n",
      "[51]\ttrain-error:0.36098\ttest-error:0.39402\n",
      "[52]\ttrain-error:0.36089\ttest-error:0.39368\n",
      "[53]\ttrain-error:0.36059\ttest-error:0.39249\n",
      "[54]\ttrain-error:0.35979\ttest-error:0.39300\n",
      "[55]\ttrain-error:0.35932\ttest-error:0.39215\n",
      "[56]\ttrain-error:0.35868\ttest-error:0.39198\n",
      "[57]\ttrain-error:0.35843\ttest-error:0.39080\n",
      "[58]\ttrain-error:0.35741\ttest-error:0.39080\n",
      "[59]\ttrain-error:0.35703\ttest-error:0.39011\n",
      "[60]\ttrain-error:0.35597\ttest-error:0.38944\n",
      "[61]\ttrain-error:0.35478\ttest-error:0.38927\n",
      "[62]\ttrain-error:0.35423\ttest-error:0.38808\n",
      "[63]\ttrain-error:0.35355\ttest-error:0.38791\n",
      "[64]\ttrain-error:0.35253\ttest-error:0.38927\n",
      "[65]\ttrain-error:0.35244\ttest-error:0.38825\n",
      "[66]\ttrain-error:0.35168\ttest-error:0.38876\n",
      "[67]\ttrain-error:0.35104\ttest-error:0.38927\n",
      "[68]\ttrain-error:0.35066\ttest-error:0.38927\n",
      "[69]\ttrain-error:0.34998\ttest-error:0.38842\n",
      "[70]\ttrain-error:0.34815\ttest-error:0.39045\n",
      "[71]\ttrain-error:0.34773\ttest-error:0.38893\n",
      "[72]\ttrain-error:0.34739\ttest-error:0.38842\n",
      "[73]\ttrain-error:0.34705\ttest-error:0.38791\n",
      "[74]\ttrain-error:0.34692\ttest-error:0.38944\n",
      "[75]\ttrain-error:0.34569\ttest-error:0.39164\n",
      "[76]\ttrain-error:0.34518\ttest-error:0.39147\n",
      "[77]\ttrain-error:0.34480\ttest-error:0.39164\n",
      "[78]\ttrain-error:0.34429\ttest-error:0.39181\n",
      "[79]\ttrain-error:0.34399\ttest-error:0.39080\n",
      "[80]\ttrain-error:0.34378\ttest-error:0.39011\n",
      "[81]\ttrain-error:0.34357\ttest-error:0.39062\n",
      "[82]\ttrain-error:0.34336\ttest-error:0.38944\n",
      "[83]\ttrain-error:0.34331\ttest-error:0.38995\n",
      "[84]\ttrain-error:0.34285\ttest-error:0.39028\n",
      "[85]\ttrain-error:0.34268\ttest-error:0.38944\n",
      "[86]\ttrain-error:0.34221\ttest-error:0.38893\n",
      "[87]\ttrain-error:0.34221\ttest-error:0.38859\n",
      "[88]\ttrain-error:0.34191\ttest-error:0.38859\n",
      "[89]\ttrain-error:0.34183\ttest-error:0.38944\n",
      "[90]\ttrain-error:0.34093\ttest-error:0.38893\n",
      "[91]\ttrain-error:0.34110\ttest-error:0.38927\n",
      "[92]\ttrain-error:0.34021\ttest-error:0.38961\n",
      "[93]\ttrain-error:0.33958\ttest-error:0.38944\n",
      "[94]\ttrain-error:0.33915\ttest-error:0.38961\n",
      "[95]\ttrain-error:0.33894\ttest-error:0.38961\n",
      "[96]\ttrain-error:0.33877\ttest-error:0.38825\n",
      "[97]\ttrain-error:0.33839\ttest-error:0.38876\n",
      "[98]\ttrain-error:0.33809\ttest-error:0.38944\n",
      "[99]\ttrain-error:0.33792\ttest-error:0.38978\n",
      "[100]\ttrain-error:0.33728\ttest-error:0.38978\n",
      "[101]\ttrain-error:0.33669\ttest-error:0.38961\n",
      "[102]\ttrain-error:0.33635\ttest-error:0.38995\n",
      "[103]\ttrain-error:0.33575\ttest-error:0.38944\n",
      "[104]\ttrain-error:0.33550\ttest-error:0.39028\n",
      "[105]\ttrain-error:0.33524\ttest-error:0.39011\n",
      "[106]\ttrain-error:0.33503\ttest-error:0.38995\n",
      "[107]\ttrain-error:0.33465\ttest-error:0.39011\n",
      "[108]\ttrain-error:0.33448\ttest-error:0.38995\n",
      "[109]\ttrain-error:0.33422\ttest-error:0.39028\n",
      "[110]\ttrain-error:0.33393\ttest-error:0.39028\n",
      "[111]\ttrain-error:0.33380\ttest-error:0.38944\n",
      "[112]\ttrain-error:0.33329\ttest-error:0.38944\n",
      "[113]\ttrain-error:0.33253\ttest-error:0.38910\n",
      "[114]\ttrain-error:0.33240\ttest-error:0.38927\n",
      "[115]\ttrain-error:0.33193\ttest-error:0.38910\n",
      "[116]\ttrain-error:0.33168\ttest-error:0.38944\n",
      "[117]\ttrain-error:0.33108\ttest-error:0.38978\n",
      "[118]\ttrain-error:0.33108\ttest-error:0.38961\n",
      "[119]\ttrain-error:0.33087\ttest-error:0.38910\n",
      "[120]\ttrain-error:0.33019\ttest-error:0.38808\n",
      "[121]\ttrain-error:0.32985\ttest-error:0.38808\n",
      "[122]\ttrain-error:0.32938\ttest-error:0.38774\n",
      "[123]\ttrain-error:0.32854\ttest-error:0.38723\n",
      "[124]\ttrain-error:0.32794\ttest-error:0.38740\n",
      "[125]\ttrain-error:0.32790\ttest-error:0.38808\n",
      "[126]\ttrain-error:0.32781\ttest-error:0.38774\n",
      "[127]\ttrain-error:0.32752\ttest-error:0.38808\n",
      "[128]\ttrain-error:0.32735\ttest-error:0.38808\n",
      "[129]\ttrain-error:0.32722\ttest-error:0.38706\n",
      "[130]\ttrain-error:0.32692\ttest-error:0.38723\n",
      "[131]\ttrain-error:0.32654\ttest-error:0.38791\n",
      "[132]\ttrain-error:0.32565\ttest-error:0.38825\n",
      "[133]\ttrain-error:0.32514\ttest-error:0.38808\n",
      "[134]\ttrain-error:0.32510\ttest-error:0.38774\n",
      "[135]\ttrain-error:0.32467\ttest-error:0.38825\n",
      "[136]\ttrain-error:0.32454\ttest-error:0.38842\n",
      "[137]\ttrain-error:0.32399\ttest-error:0.38859\n",
      "[138]\ttrain-error:0.32314\ttest-error:0.38859\n",
      "[139]\ttrain-error:0.32314\ttest-error:0.38825\n",
      "[140]\ttrain-error:0.32238\ttest-error:0.38740\n",
      "[141]\ttrain-error:0.32187\ttest-error:0.38706\n",
      "[142]\ttrain-error:0.32153\ttest-error:0.38842\n",
      "[143]\ttrain-error:0.32140\ttest-error:0.38944\n",
      "[144]\ttrain-error:0.32157\ttest-error:0.38978\n",
      "[145]\ttrain-error:0.32144\ttest-error:0.38978\n",
      "[146]\ttrain-error:0.32102\ttest-error:0.38995\n",
      "[147]\ttrain-error:0.32085\ttest-error:0.39011\n",
      "[148]\ttrain-error:0.32051\ttest-error:0.38978\n",
      "[149]\ttrain-error:0.32000\ttest-error:0.38944\n",
      "[150]\ttrain-error:0.32000\ttest-error:0.38910\n",
      "[151]\ttrain-error:0.31970\ttest-error:0.38927\n",
      "[152]\ttrain-error:0.31928\ttest-error:0.38893\n",
      "[153]\ttrain-error:0.31873\ttest-error:0.38859\n",
      "[154]\ttrain-error:0.31830\ttest-error:0.38910\n",
      "[155]\ttrain-error:0.31817\ttest-error:0.38842\n",
      "[156]\ttrain-error:0.31800\ttest-error:0.38893\n",
      "[157]\ttrain-error:0.31779\ttest-error:0.38944\n",
      "[158]\ttrain-error:0.31758\ttest-error:0.38893\n",
      "[159]\ttrain-error:0.31754\ttest-error:0.38893\n",
      "[160]\ttrain-error:0.31690\ttest-error:0.38825\n",
      "[161]\ttrain-error:0.31677\ttest-error:0.38842\n",
      "[162]\ttrain-error:0.31631\ttest-error:0.38808\n",
      "[163]\ttrain-error:0.31588\ttest-error:0.38791\n",
      "[164]\ttrain-error:0.31558\ttest-error:0.38791\n",
      "[165]\ttrain-error:0.31533\ttest-error:0.38893\n",
      "[166]\ttrain-error:0.31486\ttest-error:0.38893\n",
      "[167]\ttrain-error:0.31465\ttest-error:0.38876\n",
      "[168]\ttrain-error:0.31456\ttest-error:0.38910\n",
      "[169]\ttrain-error:0.31439\ttest-error:0.38842\n",
      "[170]\ttrain-error:0.31410\ttest-error:0.38876\n",
      "[171]\ttrain-error:0.31380\ttest-error:0.38978\n",
      "[172]\ttrain-error:0.31355\ttest-error:0.38995\n",
      "[173]\ttrain-error:0.31325\ttest-error:0.38961\n",
      "[174]\ttrain-error:0.31282\ttest-error:0.39028\n",
      "[175]\ttrain-error:0.31261\ttest-error:0.39045\n",
      "[176]\ttrain-error:0.31231\ttest-error:0.38995\n",
      "[177]\ttrain-error:0.31176\ttest-error:0.39011\n",
      "[178]\ttrain-error:0.31104\ttest-error:0.39045\n",
      "[179]\ttrain-error:0.31074\ttest-error:0.38961\n",
      "[180]\ttrain-error:0.31036\ttest-error:0.38978\n",
      "[181]\ttrain-error:0.31002\ttest-error:0.38944\n",
      "[182]\ttrain-error:0.31002\ttest-error:0.38944\n",
      "[183]\ttrain-error:0.30994\ttest-error:0.38893\n",
      "[184]\ttrain-error:0.30938\ttest-error:0.38927\n",
      "[185]\ttrain-error:0.30909\ttest-error:0.38927\n",
      "[186]\ttrain-error:0.30888\ttest-error:0.38910\n",
      "[187]\ttrain-error:0.30879\ttest-error:0.38961\n",
      "[188]\ttrain-error:0.30854\ttest-error:0.38927\n",
      "[189]\ttrain-error:0.30854\ttest-error:0.38893\n",
      "[190]\ttrain-error:0.30854\ttest-error:0.38961\n",
      "[191]\ttrain-error:0.30764\ttest-error:0.38927\n",
      "[192]\ttrain-error:0.30752\ttest-error:0.38927\n",
      "[193]\ttrain-error:0.30739\ttest-error:0.38893\n",
      "[194]\ttrain-error:0.30713\ttest-error:0.38876\n",
      "[195]\ttrain-error:0.30701\ttest-error:0.38961\n",
      "[196]\ttrain-error:0.30620\ttest-error:0.38859\n",
      "[197]\ttrain-error:0.30624\ttest-error:0.38842\n",
      "[198]\ttrain-error:0.30565\ttest-error:0.38842\n",
      "[199]\ttrain-error:0.30518\ttest-error:0.38825\n",
      "200-rounds Training finished ...\t\t(1.209s)\n"
     ]
    }
   ],
   "source": [
    "num_round = 200\n",
    "t0 = time()\n",
    "sh_bst_sm = xgb.train(param_sh, xg_train_sh, num_round, watchlist)\n",
    "print(f\"{num_round}-rounds Training finished ...\\t\\t({time()-t0:.3f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error using softmax = 0.3882472826086957\n"
     ]
    }
   ],
   "source": [
    "# get prediction\n",
    "pred_sh = sh_bst_sm.predict(xg_test_sh)\n",
    "error_rate = np.sum(pred_sh != y_test_sh) / y_test_sh.shape[0]\n",
    "print('Test error using softmax = {}'.format(error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({1.0: 3043, 0.0: 2845}), Counter({1: 2835, 0: 3053}))"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(pred_sh), Counter(y_test_sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.59      0.61      3053\n",
      "           1       0.59      0.63      0.61      2835\n",
      "\n",
      "    accuracy                           0.61      5888\n",
      "   macro avg       0.61      0.61      0.61      5888\n",
      "weighted avg       0.61      0.61      0.61      5888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_sh = metrics.classification_report(list(y_test_sh), list(pred_sh))\n",
    "print(report_sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6125295, 0.6125295])"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs_sh = auc(y_test_sh.astype(np.uint8), pred_sh.astype(np.uint8), [0, 1])\n",
    "aucs_sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'max_depth': 5, 'min_child_weight': 1}, {'max_depth': 5, 'min_child_weight': 3}, {'max_depth': 5, 'min_child_weight': 5}, {'max_depth': 5, 'min_child_weight': 7}, {'max_depth': 7, 'min_child_weight': 1}, {'max_depth': 7, 'min_child_weight': 3}, {'max_depth': 7, 'min_child_weight': 5}, {'max_depth': 7, 'min_child_weight': 7}, {'max_depth': 9, 'min_child_weight': 1}, {'max_depth': 9, 'min_child_weight': 3}, {'max_depth': 9, 'min_child_weight': 5}, {'max_depth': 9, 'min_child_weight': 7}, {'max_depth': 11, 'min_child_weight': 1}, {'max_depth': 11, 'min_child_weight': 3}, {'max_depth': 11, 'min_child_weight': 5}, {'max_depth': 11, 'min_child_weight': 7}]\n",
      "[{'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 5, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 1}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 5, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 3}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 5, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 5}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 5, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 7}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 7, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 1}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 7, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 3}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 7, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 5}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 7, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 7}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 9, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 1}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 9, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 3}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 9, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 5}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 9, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 7}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 11, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 1}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 11, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 3}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 11, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 5}, {'objective': 'binary:hinge', 'eta': 0.1, 'max_depth': 11, 'nthread': 8, 'gpu_id': 0, 'tree_method': 'gpu_hist', 'min_child_weight': 7}]\n"
     ]
    }
   ],
   "source": [
    "base_param_sh = {  # 基本参数，不需要调参\n",
    "    'objective': 'binary:hinge',\n",
    "    'eta': 0.1,\n",
    "    'nthread': 8,\n",
    "#     'num_class': 10,\n",
    "    'gpu_id': 0,\n",
    "    'tree_method': 'gpu_hist'\n",
    "} \n",
    "ps_sh = {  # 需要调参的参数\n",
    "    'max_depth': list(range(5, 13, 2)),\n",
    "    'min_child_weight': list(range(1, 10, 2))\n",
    "}\n",
    "\n",
    "com_ps_sh = list(ParameterGrid(ps_sh))\n",
    "print(com_ps_sh)\n",
    "\n",
    "all_params_sh = [base_param_sh.copy() for _ in range(len(com_ps_sh))] \n",
    "for i in range(len(com_ps_sh)):\n",
    "    all_params_sh[i].update(com_ps_sh[i])\n",
    "    \n",
    "print(all_params_sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_sh = []\n",
    "num_round = 250\n",
    "for i, p in enumerate(all_params):\n",
    "    t0 = time()\n",
    "    bst = xgb.train(p, xg_train_sh, num_round, watchlist)\n",
    "    \n",
    "    # get prediction\n",
    "    pred = bst.predict(xg_test_sh)\n",
    "    # pred = pred.astype(np.uint8)\n",
    "    error_rate = np.sum(pred != y_test_sh) / y_test_sh.shape[0]\n",
    "    \n",
    "    aucs = auc(y_test_sh.astype(np.uint8), pred.astype(np.uint8), np.arange(2))\n",
    "    \n",
    "    rep = metrics.classification_report(list(y_test_sh), list(pred))\n",
    "    results_sh.append({\n",
    "        'test_error': error_rate, \n",
    "        'aucs': aucs,\n",
    "        'report': rep,\n",
    "        'model': bst\n",
    "    })\n",
    "    \n",
    "    print(f\"{i} : {num_round}-rounds Training finished error_rate={error_rate}  aucs={aucs}...\\t\\t({time()-t0:.3f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary:hinge',\n",
       " 'eta': 0.1,\n",
       " 'max_depth': 11,\n",
       " 'nthread': 8,\n",
       " 'gpu_id': 0,\n",
       " 'tree_method': 'gpu_hist',\n",
       " 'min_child_weight': 7}"
      ]
     },
     "execution_count": 876,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([[-e['test_error'] for e in results], [e['w_auc'] for e in results]], dtype=np.float32)\n",
    "opt_idxs_sh = arr.argmax(axis=1)\n",
    "if opt_idxs_sh[0] != opt_idxs_sh[1]:\n",
    "    raise ValueError(f\"最小误差与最大AUC对应的模型不一致 : {opt_idxs_sh}\")\n",
    "else:\n",
    "    opt_idx_sh = opt_idxs_sh[0]\n",
    "all_params_sh[opt_idx_sh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [0.621498838085251, 0.621498838085251]\n",
       "1     [0.6191077482441057, 0.6191077482441057]\n",
       "2     [0.6077097920740165, 0.6077097920740165]\n",
       "3     [0.6092416694226004, 0.6092416694226004]\n",
       "4     [0.6235535033609287, 0.6235535033609287]\n",
       "5     [0.6109579445337427, 0.6109579445337427]\n",
       "6      [0.609377418608228, 0.6093774186082281]\n",
       "7     [0.6066783439631294, 0.6066783439631293]\n",
       "8     [0.6226984063414158, 0.6226984063414157]\n",
       "9     [0.6128707795516763, 0.6128707795516763]\n",
       "10    [0.6130186908815368, 0.6130186908815368]\n",
       "11    [0.6000360933128845, 0.6000360933128845]\n",
       "12    [0.6218615525382517, 0.6218615525382518]\n",
       "13    [0.6121879181504891, 0.6121879181504892]\n",
       "14    [0.6121575127899075, 0.6121575127899075]\n",
       "15    [0.6054038372425004, 0.6054038372425004]\n",
       "Name: aucs, dtype: object"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_sh)['aucs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0)\n",
    "clf.fit(X_train_sh, y_train_sh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = inference_dataset\n",
    "test = xgb.DMatrix(test.values, enable_categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2822180, 70), 70)"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_dataset.shape, test.num_col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bst_wl = wl_bst_sm\n",
    "bst_sh = sh_bst_sm  # results_sh[4]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({1.0: 1510645,\n",
       "          0.0: 335797,\n",
       "          3.0: 11933,\n",
       "          9.0: 877013,\n",
       "          2.0: 67310,\n",
       "          7.0: 1087,\n",
       "          4.0: 2601,\n",
       "          8.0: 11715,\n",
       "          5.0: 1114,\n",
       "          6.0: 2965}),\n",
       " Counter({1.0: 1006378, 0.0: 1815802}))"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wl = bst_wl.predict(test)\n",
    "sh = bst_sh.predict(test)\n",
    "Counter(wl), Counter(Counter(sh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2822180, 4)"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['watch_label'] = wl.astype(np.uint8)\n",
    "test_df['is_share'] = sh.astype(np.uint8)\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new submission saved to ../submission-1625404864.csv\n"
     ]
    }
   ],
   "source": [
    "fn = f'../submission-{int(time())}.csv'\n",
    "test_df.to_csv(fn, index=False, sep=\",\")\n",
    "print(f\"new submission saved to {fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2822180, 4)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf = pd.read_csv('../submission-1625380995.csv')\n",
    "tdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "widx = test_df['watch_label'] != tdf['watch_label']\n",
    "sidx = test_df['is_share'] != tdf['is_share']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(493990, 474150)"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "widx.sum(), sidx.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_model_name = 'wl_model_v9'\n",
    "sh_model_name = 'sh_model_v9'\n",
    "bst_wl.save_model(wl_model_name)\n",
    "bst_sh.save_model(sh_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_log(log_name, info, log_path=\"./\"):\n",
    "    import datetime\n",
    "    with open(os.path.join(log_path, log_name), 'w') as log:\n",
    "        log.write(f\"# {datetime.datetime.now().__str__()}\\n\")\n",
    "        if info.get('comment', False):\n",
    "            log.write(f\"\\n## Comment: \\n\")\n",
    "            log.write(f\"{info['comment']}\\n\")\n",
    "            \n",
    "        log.write(f\"\\n## model name: {info['model_name']}\\n\")\n",
    "        log.write(f\"- model save path : {info['model_save_path']}\\n\")\n",
    "        \n",
    "        log.write(f\"\\n## Data setup\\n\")\n",
    "        log.write(f\"- dataset.shape : {dataset.shape}\\n\")\n",
    "        log.write(f\"- dataset.columns : {dataset.columns}\\n\")\n",
    "        log.write(f\"- is resample : {info['is_resample']}\\n\")\n",
    "        log.write(f\"- Traing_Data.shape (watch_label)  : {X_train.shape}\\n\")\n",
    "        log.write(f\"- Testing_Data.shape (watch_label) : {X_test.shape}\\n\")\n",
    "        log.write(f\"- Traing_Data.shape (is_share)  : {X_train_sh.shape}\\n\")\n",
    "        log.write(f\"- Testing_Data.shape (is_share) : {X_test_sh.shape}\\n\")\n",
    "        if info.get('is_resample', False):\n",
    "            log.write(f\"- Resampled class distribution (watch_label): \\n{Counter(resampled_wl)}\\n\")\n",
    "            log.write(f\"- Resampled class distribution (is_share): \\n{Counter(resampled_sh)}\\n\")\n",
    "            \n",
    "        log.write(f\"\\n## Model Params\\n\")\n",
    "        log.write(f\"- model params (watch_label) : \\n{param}\\n\")\n",
    "        log.write(f\"- model params (is_share) : \\n{param_sh}\\n\")\n",
    "        \n",
    "        log.write(f\"\\n## Model's Performance\\n\")\n",
    "        log.write(f\"- Aucs (watch_label) : {aucs}\\n\")\n",
    "        log.write(f\"- Weighted Aucs (watch_label) : {w_aucs}\\n\")\n",
    "        log.write(f\"- Aucs (is_share) : {aucs_sh}\\n\")\n",
    "        \n",
    "        log.write(f\"- Classification Report (watch_label) : \\n\\n{report}\\n\")\n",
    "        log.write(f\"- Classification Report (is_share) : \\n\\n{report_sh}\\n\")\n",
    "        \n",
    "        log.flush()\n",
    "        \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_name = \"log_v9.2.md\"\n",
    "info = {'is_resample': True, 'model_name': [wl_model_name, sh_model_name], 'model_save_path': os.getcwd(),\n",
    "        'comment': \"模型配置与log_v8.md中的配置一致，使用的完整的视频特征（后续不加特殊说明均为完整特征）。\\nwatch_label的预测：基础特征，is_share的预测：基础特征。\\n此次生成的提交是：submission-1625404864.csv。官方测评得分：xxx😐\"}\n",
    "write_log(log_name, info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 服务器间同步文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推向Digix服务器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models.ipynb                                  100%  103KB   9.3MB/s   00:00    \n"
     ]
    }
   ],
   "source": [
    "!scp ./models.ipynb digix@49.123.120.71:/home/digix/digix/Models/models.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_v3.md                                     100% 3404   263.2KB/s   00:00    \n",
      "log_v4.md                                     100% 3403     2.6MB/s   00:00    \n",
      "log_v5.md                                     100% 3316     2.6MB/s   00:00    \n",
      "log_v6.md                                     100% 3572     2.8MB/s   00:00    \n",
      "log_v7.md                                     100% 3638     2.9MB/s   00:00    \n"
     ]
    }
   ],
   "source": [
    "!scp ./log_*.md digix@49.123.120.71:/home/digix/digix/Models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explore-data.ipynb                            100%  306KB  10.6MB/s   00:00    \n"
     ]
    }
   ],
   "source": [
    "!scp ../explore-data.ipynb digix@49.123.120.71:/home/digix/digix/explore-data.ipynb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从Digix服务器拉数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM.ipynb                                100%   71KB   2.2MB/s   00:00    \n"
     ]
    }
   ],
   "source": [
    "!scp  digix@49.123.120.71:/home/digix/digix/Models/LightGBM.ipynb ./LightGBM.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scp: /home/digix/digix/Models/feature_engineering.ipynb: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!scp  digix@49.123.120.71:/home/digix/digix/Models/feature_engineering.ipynb ./feature_engineering.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utils.py                                      100% 3860     2.6MB/s   00:00    \n",
      "data_analysis.ipynb                           100% 6566KB  11.2MB/s   00:00    \n",
      "__init__.py                                   100%    0     0.0KB/s   00:00    \n",
      "__init__.cpython-36.pyc                       100%  139   128.3KB/s   00:00    \n",
      "utils.cpython-36.pyc                          100% 4120     2.6MB/s   00:00    \n",
      "video_data.ipynb                              100%   55KB   1.7MB/s   00:00    \n",
      "user_data-checkpoint.ipynb                    100%  202KB  10.1MB/s   00:00    \n",
      "data_analysis-checkpoint.ipynb                100% 6554KB  11.0MB/s   00:00    \n",
      "utils-checkpoint.py                           100% 3860     2.4MB/s   00:00    \n",
      "video_data-checkpoint.ipynb                   100%   17KB   1.4MB/s   00:00    \n",
      "user_data.ipynb                               100%  202KB  10.3MB/s   00:00    \n"
     ]
    }
   ],
   "source": [
    "!scp -r digix@49.123.120.71:/home/digix/digix/Models/Feature_Engineering/  ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_status.csv                              100% 2008KB   9.1MB/s   00:00    \n",
      "user_status.csv                               100%  138MB   9.3MB/s   00:14    \n"
     ]
    }
   ],
   "source": [
    "!scp -r digix@49.123.120.71:/home/digix/digix/dataset/traindata/video_features_data/video_status.csv ../2021_3_data/traindata/video_features_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_status.csv                               100%  168MB  11.2MB/s   00:14    \n"
     ]
    }
   ],
   "source": [
    "!scp -r digix@49.123.120.71:/home/digix/digix/dataset/traindata/user_features_data/user_status.csv ../2021_3_data/traindata/user_features_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
