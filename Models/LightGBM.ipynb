{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "extra-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-bible",
   "metadata": {},
   "source": [
    "# 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "median-spank",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../dataset/traindata/user_video_14day_action_train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "shared-hometown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "1          0\n",
       "2          3\n",
       "3          9\n",
       "4          0\n",
       "          ..\n",
       "7308013    0\n",
       "7308014    2\n",
       "7308015    1\n",
       "7308016    0\n",
       "7308017    0\n",
       "Name: watch_label, Length: 7308018, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watch_label = data['watch_label']\n",
    "watch_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "communist-calendar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          0\n",
       "          ..\n",
       "7308013    0\n",
       "7308014    0\n",
       "7308015    0\n",
       "7308016    0\n",
       "7308017    0\n",
       "Name: is_share, Length: 7308018, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "share_label = data['is_share']\n",
    "share_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "saving-market",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['is_share', 'watch_label'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "placed-virginia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age_0</th>\n",
       "      <th>age_1</th>\n",
       "      <th>age_2</th>\n",
       "      <th>age_3</th>\n",
       "      <th>age_4</th>\n",
       "      <th>age_5</th>\n",
       "      <th>age_6</th>\n",
       "      <th>age_7</th>\n",
       "      <th>gender_0</th>\n",
       "      <th>...</th>\n",
       "      <th>class_5</th>\n",
       "      <th>class_6</th>\n",
       "      <th>class_7</th>\n",
       "      <th>class_8</th>\n",
       "      <th>class_9</th>\n",
       "      <th>da_0</th>\n",
       "      <th>da_1</th>\n",
       "      <th>da_2</th>\n",
       "      <th>da_3</th>\n",
       "      <th>da_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17938.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041772</td>\n",
       "      <td>0.349582</td>\n",
       "      <td>0.041779</td>\n",
       "      <td>0.041780</td>\n",
       "      <td>0.041772</td>\n",
       "      <td>0.324848</td>\n",
       "      <td>0.083544</td>\n",
       "      <td>0.083544</td>\n",
       "      <td>0.083544</td>\n",
       "      <td>0.424519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17938.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17938.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035480</td>\n",
       "      <td>0.035478</td>\n",
       "      <td>0.035479</td>\n",
       "      <td>0.035482</td>\n",
       "      <td>0.035480</td>\n",
       "      <td>0.432491</td>\n",
       "      <td>0.075271</td>\n",
       "      <td>0.073186</td>\n",
       "      <td>0.071487</td>\n",
       "      <td>0.347565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4263520.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037601</td>\n",
       "      <td>0.037601</td>\n",
       "      <td>0.037601</td>\n",
       "      <td>0.037601</td>\n",
       "      <td>0.037601</td>\n",
       "      <td>0.075201</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.699193</td>\n",
       "      <td>0.075201</td>\n",
       "      <td>0.075202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5181723.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034261</td>\n",
       "      <td>0.034301</td>\n",
       "      <td>0.034266</td>\n",
       "      <td>0.034261</td>\n",
       "      <td>0.034261</td>\n",
       "      <td>0.504280</td>\n",
       "      <td>0.072258</td>\n",
       "      <td>0.070551</td>\n",
       "      <td>0.069007</td>\n",
       "      <td>0.283903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  age_0  age_1  age_2  age_3  age_4  age_5  age_6  age_7  \\\n",
       "0    17938.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1    17938.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2    17938.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3  4263520.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4  5181723.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   gender_0  ...   class_5   class_6   class_7   class_8   class_9      da_0  \\\n",
       "0       1.0  ...  0.041772  0.349582  0.041779  0.041780  0.041772  0.324848   \n",
       "1       1.0  ...  0.050000  0.050000  0.050000  0.050000  0.050000  0.100000   \n",
       "2       1.0  ...  0.035480  0.035478  0.035479  0.035482  0.035480  0.432491   \n",
       "3       1.0  ...  0.037601  0.037601  0.037601  0.037601  0.037601  0.075201   \n",
       "4       0.0  ...  0.034261  0.034301  0.034266  0.034261  0.034261  0.504280   \n",
       "\n",
       "       da_1      da_2      da_3      da_4  \n",
       "0  0.083544  0.083544  0.083544  0.424519  \n",
       "1  0.100000  0.600000  0.100000  0.100000  \n",
       "2  0.075271  0.073186  0.071487  0.347565  \n",
       "3  0.075202  0.699193  0.075201  0.075202  \n",
       "4  0.072258  0.070551  0.069007  0.283903  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-north",
   "metadata": {},
   "source": [
    "# watch_label预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "reported-registrar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboosting_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gbdt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_leaves\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m31\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample_for_bin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_split_gain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_child_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_child_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolsample_bytree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_lambda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'split'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      LightGBM classifier.\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Construct a gradient boosting model.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "boosting_type : string, optional (default='gbdt')\n",
       "    'gbdt', traditional Gradient Boosting Decision Tree.\n",
       "    'dart', Dropouts meet Multiple Additive Regression Trees.\n",
       "    'goss', Gradient-based One-Side Sampling.\n",
       "    'rf', Random Forest.\n",
       "num_leaves : int, optional (default=31)\n",
       "    Maximum tree leaves for base learners.\n",
       "max_depth : int, optional (default=-1)\n",
       "    Maximum tree depth for base learners, <=0 means no limit.\n",
       "learning_rate : float, optional (default=0.1)\n",
       "    Boosting learning rate.\n",
       "    You can use ``callbacks`` parameter of ``fit`` method to shrink/adapt learning rate\n",
       "    in training using ``reset_parameter`` callback.\n",
       "    Note, that this will ignore the ``learning_rate`` argument in training.\n",
       "n_estimators : int, optional (default=100)\n",
       "    Number of boosted trees to fit.\n",
       "subsample_for_bin : int, optional (default=200000)\n",
       "    Number of samples for constructing bins.\n",
       "objective : string, callable or None, optional (default=None)\n",
       "    Specify the learning task and the corresponding learning objective or\n",
       "    a custom objective function to be used (see note below).\n",
       "    Default: 'regression' for LGBMRegressor, 'binary' or 'multiclass' for LGBMClassifier, 'lambdarank' for LGBMRanker.\n",
       "class_weight : dict, 'balanced' or None, optional (default=None)\n",
       "    Weights associated with classes in the form ``{class_label: weight}``.\n",
       "    Use this parameter only for multi-class classification task;\n",
       "    for binary classification task you may use ``is_unbalance`` or ``scale_pos_weight`` parameters.\n",
       "    Note, that the usage of all these parameters will result in poor estimates of the individual class probabilities.\n",
       "    You may want to consider performing probability calibration\n",
       "    (https://scikit-learn.org/stable/modules/calibration.html) of your model.\n",
       "    The 'balanced' mode uses the values of y to automatically adjust weights\n",
       "    inversely proportional to class frequencies in the input data as ``n_samples / (n_classes * np.bincount(y))``.\n",
       "    If None, all classes are supposed to have weight one.\n",
       "    Note, that these weights will be multiplied with ``sample_weight`` (passed through the ``fit`` method)\n",
       "    if ``sample_weight`` is specified.\n",
       "min_split_gain : float, optional (default=0.)\n",
       "    Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
       "min_child_weight : float, optional (default=1e-3)\n",
       "    Minimum sum of instance weight (hessian) needed in a child (leaf).\n",
       "min_child_samples : int, optional (default=20)\n",
       "    Minimum number of data needed in a child (leaf).\n",
       "subsample : float, optional (default=1.)\n",
       "    Subsample ratio of the training instance.\n",
       "subsample_freq : int, optional (default=0)\n",
       "    Frequence of subsample, <=0 means no enable.\n",
       "colsample_bytree : float, optional (default=1.)\n",
       "    Subsample ratio of columns when constructing each tree.\n",
       "reg_alpha : float, optional (default=0.)\n",
       "    L1 regularization term on weights.\n",
       "reg_lambda : float, optional (default=0.)\n",
       "    L2 regularization term on weights.\n",
       "random_state : int, RandomState object or None, optional (default=None)\n",
       "    Random number seed.\n",
       "    If int, this number is used to seed the C++ code.\n",
       "    If RandomState object (numpy), a random integer is picked based on its state to seed the C++ code.\n",
       "    If None, default seeds in C++ code are used.\n",
       "n_jobs : int, optional (default=-1)\n",
       "    Number of parallel threads.\n",
       "silent : bool, optional (default=True)\n",
       "    Whether to print messages while running boosting.\n",
       "importance_type : string, optional (default='split')\n",
       "    The type of feature importance to be filled into ``feature_importances_``.\n",
       "    If 'split', result contains numbers of times the feature is used in a model.\n",
       "    If 'gain', result contains total gains of splits which use the feature.\n",
       "**kwargs\n",
       "    Other parameters for the model.\n",
       "    Check http://lightgbm.readthedocs.io/en/latest/Parameters.html for more parameters.\n",
       "\n",
       "    .. warning::\n",
       "\n",
       "        \\*\\*kwargs is not supported in sklearn, it may cause unexpected issues.\n",
       "\n",
       "Note\n",
       "----\n",
       "A custom objective function can be provided for the ``objective`` parameter.\n",
       "In this case, it should have the signature\n",
       "``objective(y_true, y_pred) -> grad, hess`` or\n",
       "``objective(y_true, y_pred, group) -> grad, hess``:\n",
       "\n",
       "    y_true : array-like of shape = [n_samples]\n",
       "        The target values.\n",
       "    y_pred : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
       "        The predicted values.\n",
       "    group : array-like\n",
       "        Group/query data, used for ranking task.\n",
       "    grad : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
       "        The value of the first order derivative (gradient) for each sample point.\n",
       "    hess : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
       "        The value of the second order derivative (Hessian) for each sample point.\n",
       "\n",
       "For binary task, the y_pred is margin.\n",
       "For multi-class task, the y_pred is group by class_id first, then group by row_id.\n",
       "If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i]\n",
       "and you should group grad and hess in this way as well.\n",
       "\u001b[0;31mFile:\u001b[0m           /home/anaconda/envs/digix/lib/python3.6/site-packages/lightgbm/sklearn.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LGBMClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "possible-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练数据和测试数据\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, watch_label, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "awful-receiver",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    silent=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "hidden-heaven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.617951 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9736\n",
      "[LightGBM] [Info] Number of data points in the train set: 5846414, number of used features: 66\n",
      "[LightGBM] [Info] Start training from score -0.350802\n",
      "[LightGBM] [Info] Start training from score -2.577933\n",
      "[LightGBM] [Info] Start training from score -3.152199\n",
      "[LightGBM] [Info] Start training from score -3.513707\n",
      "[LightGBM] [Info] Start training from score -3.751802\n",
      "[LightGBM] [Info] Start training from score -3.940522\n",
      "[LightGBM] [Info] Start training from score -4.072402\n",
      "[LightGBM] [Info] Start training from score -4.136361\n",
      "[LightGBM] [Info] Start training from score -3.972276\n",
      "[LightGBM] [Info] Start training from score -2.944267\n",
      "[1]\tvalid_0's multi_logloss: 1.20205\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.19504\n",
      "[3]\tvalid_0's multi_logloss: 1.18948\n",
      "[4]\tvalid_0's multi_logloss: 1.18498\n",
      "[5]\tvalid_0's multi_logloss: 1.1814\n",
      "[6]\tvalid_0's multi_logloss: 1.17838\n",
      "[7]\tvalid_0's multi_logloss: 1.17586\n",
      "[8]\tvalid_0's multi_logloss: 1.17367\n",
      "[9]\tvalid_0's multi_logloss: 1.1718\n",
      "[10]\tvalid_0's multi_logloss: 1.1701\n",
      "[11]\tvalid_0's multi_logloss: 1.16865\n",
      "[12]\tvalid_0's multi_logloss: 1.16739\n",
      "[13]\tvalid_0's multi_logloss: 1.16619\n",
      "[14]\tvalid_0's multi_logloss: 1.16513\n",
      "[15]\tvalid_0's multi_logloss: 1.16416\n",
      "[16]\tvalid_0's multi_logloss: 1.16332\n",
      "[17]\tvalid_0's multi_logloss: 1.16256\n",
      "[18]\tvalid_0's multi_logloss: 1.16186\n",
      "[19]\tvalid_0's multi_logloss: 1.16118\n",
      "[20]\tvalid_0's multi_logloss: 1.16062\n",
      "[21]\tvalid_0's multi_logloss: 1.16011\n",
      "[22]\tvalid_0's multi_logloss: 1.15958\n",
      "[23]\tvalid_0's multi_logloss: 1.15904\n",
      "[24]\tvalid_0's multi_logloss: 1.15854\n",
      "[25]\tvalid_0's multi_logloss: 1.15813\n",
      "[26]\tvalid_0's multi_logloss: 1.15768\n",
      "[27]\tvalid_0's multi_logloss: 1.15732\n",
      "[28]\tvalid_0's multi_logloss: 1.15695\n",
      "[29]\tvalid_0's multi_logloss: 1.15654\n",
      "[30]\tvalid_0's multi_logloss: 1.15621\n",
      "[31]\tvalid_0's multi_logloss: 1.15587\n",
      "[32]\tvalid_0's multi_logloss: 1.15562\n",
      "[33]\tvalid_0's multi_logloss: 1.15531\n",
      "[34]\tvalid_0's multi_logloss: 1.15507\n",
      "[35]\tvalid_0's multi_logloss: 1.15476\n",
      "[36]\tvalid_0's multi_logloss: 1.15449\n",
      "[37]\tvalid_0's multi_logloss: 1.15424\n",
      "[38]\tvalid_0's multi_logloss: 1.15398\n",
      "[39]\tvalid_0's multi_logloss: 1.15375\n",
      "[40]\tvalid_0's multi_logloss: 1.15354\n",
      "[41]\tvalid_0's multi_logloss: 1.15327\n",
      "[42]\tvalid_0's multi_logloss: 1.15307\n",
      "[43]\tvalid_0's multi_logloss: 1.15284\n",
      "[44]\tvalid_0's multi_logloss: 1.15263\n",
      "[45]\tvalid_0's multi_logloss: 1.15247\n",
      "[46]\tvalid_0's multi_logloss: 1.15225\n",
      "[47]\tvalid_0's multi_logloss: 1.15205\n",
      "[48]\tvalid_0's multi_logloss: 1.15188\n",
      "[49]\tvalid_0's multi_logloss: 1.15168\n",
      "[50]\tvalid_0's multi_logloss: 1.15152\n",
      "[51]\tvalid_0's multi_logloss: 1.15136\n",
      "[52]\tvalid_0's multi_logloss: 1.15121\n",
      "[53]\tvalid_0's multi_logloss: 1.15108\n",
      "[54]\tvalid_0's multi_logloss: 1.15094\n",
      "[55]\tvalid_0's multi_logloss: 1.1508\n",
      "[56]\tvalid_0's multi_logloss: 1.15066\n",
      "[57]\tvalid_0's multi_logloss: 1.15048\n",
      "[58]\tvalid_0's multi_logloss: 1.15037\n",
      "[59]\tvalid_0's multi_logloss: 1.15023\n",
      "[60]\tvalid_0's multi_logloss: 1.15009\n",
      "[61]\tvalid_0's multi_logloss: 1.14999\n",
      "[62]\tvalid_0's multi_logloss: 1.14986\n",
      "[63]\tvalid_0's multi_logloss: 1.14974\n",
      "[64]\tvalid_0's multi_logloss: 1.14961\n",
      "[65]\tvalid_0's multi_logloss: 1.14951\n",
      "[66]\tvalid_0's multi_logloss: 1.14941\n",
      "[67]\tvalid_0's multi_logloss: 1.14929\n",
      "[68]\tvalid_0's multi_logloss: 1.14916\n",
      "[69]\tvalid_0's multi_logloss: 1.14904\n",
      "[70]\tvalid_0's multi_logloss: 1.14893\n",
      "[71]\tvalid_0's multi_logloss: 1.14884\n",
      "[72]\tvalid_0's multi_logloss: 1.14876\n",
      "[73]\tvalid_0's multi_logloss: 1.14864\n",
      "[74]\tvalid_0's multi_logloss: 1.14854\n",
      "[75]\tvalid_0's multi_logloss: 1.14842\n",
      "[76]\tvalid_0's multi_logloss: 1.1483\n",
      "[77]\tvalid_0's multi_logloss: 1.14821\n",
      "[78]\tvalid_0's multi_logloss: 1.14813\n",
      "[79]\tvalid_0's multi_logloss: 1.14803\n",
      "[80]\tvalid_0's multi_logloss: 1.14794\n",
      "[81]\tvalid_0's multi_logloss: 1.14781\n",
      "[82]\tvalid_0's multi_logloss: 1.1477\n",
      "[83]\tvalid_0's multi_logloss: 1.1476\n",
      "[84]\tvalid_0's multi_logloss: 1.14753\n",
      "[85]\tvalid_0's multi_logloss: 1.14744\n",
      "[86]\tvalid_0's multi_logloss: 1.14734\n",
      "[87]\tvalid_0's multi_logloss: 1.14725\n",
      "[88]\tvalid_0's multi_logloss: 1.14717\n",
      "[89]\tvalid_0's multi_logloss: 1.14709\n",
      "[90]\tvalid_0's multi_logloss: 1.14701\n",
      "[91]\tvalid_0's multi_logloss: 1.14693\n",
      "[92]\tvalid_0's multi_logloss: 1.14685\n",
      "[93]\tvalid_0's multi_logloss: 1.14676\n",
      "[94]\tvalid_0's multi_logloss: 1.1467\n",
      "[95]\tvalid_0's multi_logloss: 1.14659\n",
      "[96]\tvalid_0's multi_logloss: 1.14651\n",
      "[97]\tvalid_0's multi_logloss: 1.14643\n",
      "[98]\tvalid_0's multi_logloss: 1.14638\n",
      "[99]\tvalid_0's multi_logloss: 1.1463\n",
      "[100]\tvalid_0's multi_logloss: 1.14625\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.14625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(objective='multiclass', silent=False)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型训练\n",
    "gbm.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "adolescent-collins",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./ckp/watch_lgb_v1.pkl']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型存储\n",
    "joblib.dump(gbm, './ckp/watch_lgb_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "asian-pontiac",
   "metadata": {},
   "outputs": [],
   "source": [
    "del gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "german-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型加载\n",
    "gbm = joblib.load('./ckp/watch_lgb_v1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-liberal",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "friendly-senator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "test_data = pd.read_csv(\"../dataset/testdata/user_video_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cordless-scheduling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age_0</th>\n",
       "      <th>age_1</th>\n",
       "      <th>age_2</th>\n",
       "      <th>age_3</th>\n",
       "      <th>age_4</th>\n",
       "      <th>age_5</th>\n",
       "      <th>age_6</th>\n",
       "      <th>age_7</th>\n",
       "      <th>gender_0</th>\n",
       "      <th>...</th>\n",
       "      <th>class_5</th>\n",
       "      <th>class_6</th>\n",
       "      <th>class_7</th>\n",
       "      <th>class_8</th>\n",
       "      <th>class_9</th>\n",
       "      <th>da_0</th>\n",
       "      <th>da_1</th>\n",
       "      <th>da_2</th>\n",
       "      <th>da_3</th>\n",
       "      <th>da_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1688013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044262</td>\n",
       "      <td>0.044256</td>\n",
       "      <td>0.601629</td>\n",
       "      <td>0.044261</td>\n",
       "      <td>0.044258</td>\n",
       "      <td>0.089812</td>\n",
       "      <td>0.089831</td>\n",
       "      <td>0.220794</td>\n",
       "      <td>0.089921</td>\n",
       "      <td>0.509642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4502598.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037079</td>\n",
       "      <td>0.037079</td>\n",
       "      <td>0.037084</td>\n",
       "      <td>0.037091</td>\n",
       "      <td>0.037079</td>\n",
       "      <td>0.224282</td>\n",
       "      <td>0.074159</td>\n",
       "      <td>0.553241</td>\n",
       "      <td>0.074159</td>\n",
       "      <td>0.074159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4502598.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037617</td>\n",
       "      <td>0.037614</td>\n",
       "      <td>0.037615</td>\n",
       "      <td>0.357728</td>\n",
       "      <td>0.341329</td>\n",
       "      <td>0.075635</td>\n",
       "      <td>0.075640</td>\n",
       "      <td>0.077071</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.075225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4502598.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.050009</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5585629.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041441</td>\n",
       "      <td>0.345918</td>\n",
       "      <td>0.041441</td>\n",
       "      <td>0.041441</td>\n",
       "      <td>0.041447</td>\n",
       "      <td>0.084386</td>\n",
       "      <td>0.362494</td>\n",
       "      <td>0.082881</td>\n",
       "      <td>0.387358</td>\n",
       "      <td>0.082881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  age_0  age_1  age_2  age_3  age_4  age_5  age_6  age_7  \\\n",
       "0  1688013.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1  4502598.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2  4502598.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3  4502598.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4  5585629.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   gender_0  ...   class_5   class_6   class_7   class_8   class_9      da_0  \\\n",
       "0       1.0  ...  0.044262  0.044256  0.601629  0.044261  0.044258  0.089812   \n",
       "1       1.0  ...  0.037079  0.037079  0.037084  0.037091  0.037079  0.224282   \n",
       "2       1.0  ...  0.037617  0.037614  0.037615  0.357728  0.341329  0.075635   \n",
       "3       1.0  ...  0.050000  0.050000  0.050003  0.050009  0.050000  0.600000   \n",
       "4       0.0  ...  0.041441  0.345918  0.041441  0.041441  0.041447  0.084386   \n",
       "\n",
       "       da_1      da_2      da_3      da_4  \n",
       "0  0.089831  0.220794  0.089921  0.509642  \n",
       "1  0.074159  0.553241  0.074159  0.074159  \n",
       "2  0.075640  0.077071  0.696429  0.075225  \n",
       "3  0.100000  0.100000  0.100000  0.100000  \n",
       "4  0.362494  0.082881  0.387358  0.082881  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "polar-gentleman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2822180, 72)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "color-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ans = gbm.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "hawaiian-prevention",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ans_df = pd.DataFrame(test_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "finnish-commission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.822180e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.601280e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.213814e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  2.822180e+06\n",
       "mean   6.601280e-04\n",
       "std    5.213814e-02\n",
       "min    0.000000e+00\n",
       "25%    0.000000e+00\n",
       "50%    0.000000e+00\n",
       "75%    0.000000e+00\n",
       "max    8.000000e+00"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ans_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "former-modem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2822180 entries, 0 to 2822179\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Dtype\n",
      "---  ------  -----\n",
      " 0   0       int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 21.5 MB\n"
     ]
    }
   ],
   "source": [
    "test_ans_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "handmade-passenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ans_df.to_csv(\"../dataset/testdata/watch_label_result.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "downtown-immune",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2822180 entries, 0 to 2822179\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Dtype\n",
      "---  ------  -----\n",
      " 0   0       int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 21.5 MB\n"
     ]
    }
   ],
   "source": [
    "test_ans_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fleet-helping",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ans_df.to_csv(\"../dataset/testdata/watch_label_result.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "hairy-password",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of prediction is: 0.7044774097498365\n",
      "Feature importances: [1311, 184, 366, 469, 199, 855, 78, 102, 0, 320, 221, 26, 0, 73, 81, 89, 151, 137, 150, 158, 0, 418, 295, 206, 230, 0, 0, 0, 404, 156, 250, 1688, 1742, 3597, 2587, 756, 875, 1048, 1154, 1056, 935, 1223, 1019, 769, 1066, 1571, 1034, 921, 991, 933, 840, 1011, 985, 884, 856, 693, 925, 584, 521, 604, 686, 544, 624, 566, 454, 683, 835, 905, 673, 764, 649, 820]\n"
     ]
    }
   ],
   "source": [
    "# 模型预测\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration_)\n",
    "\n",
    "# 模型评估\n",
    "print('The accuracy of prediction is:', accuracy_score(y_test, y_pred))\n",
    "\n",
    "# 特征重要度\n",
    "print('Feature importances:', list(gbm.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-trading",
   "metadata": {},
   "source": [
    "# is_share 分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "about-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练数据和测试数据\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, share_label, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "smooth-shareware",
   "metadata": {},
   "outputs": [],
   "source": [
    "del gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "catholic-schema",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = LGBMClassifier(\n",
    "    objective='binary',\n",
    "    silent=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "certain-british",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 11376, number of negative: 5835038\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.540807 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9736\n",
      "[LightGBM] [Info] Number of data points in the train set: 5846414, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240130\n",
      "[LightGBM] [Info] Start training from score -6.240130\n",
      "[1]\tvalid_0's auc: 0.609217\tvalid_0's binary_logloss: 0.0143565\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.625076\tvalid_0's binary_logloss: 0.0143576\n",
      "[3]\tvalid_0's auc: 0.633658\tvalid_0's binary_logloss: 0.0143305\n",
      "[4]\tvalid_0's auc: 0.638026\tvalid_0's binary_logloss: 0.0143105\n",
      "[5]\tvalid_0's auc: 0.639738\tvalid_0's binary_logloss: 0.0143163\n",
      "[6]\tvalid_0's auc: 0.641107\tvalid_0's binary_logloss: 0.0143046\n",
      "[7]\tvalid_0's auc: 0.643237\tvalid_0's binary_logloss: 0.0142918\n",
      "[8]\tvalid_0's auc: 0.64273\tvalid_0's binary_logloss: 0.0142904\n",
      "[9]\tvalid_0's auc: 0.644349\tvalid_0's binary_logloss: 0.0142795\n",
      "[10]\tvalid_0's auc: 0.644854\tvalid_0's binary_logloss: 0.0142874\n",
      "[11]\tvalid_0's auc: 0.646523\tvalid_0's binary_logloss: 0.0143151\n",
      "[12]\tvalid_0's auc: 0.647949\tvalid_0's binary_logloss: 0.0143171\n",
      "[13]\tvalid_0's auc: 0.648884\tvalid_0's binary_logloss: 0.0143101\n",
      "[14]\tvalid_0's auc: 0.649669\tvalid_0's binary_logloss: 0.0142947\n",
      "[15]\tvalid_0's auc: 0.649833\tvalid_0's binary_logloss: 0.014298\n",
      "[16]\tvalid_0's auc: 0.649973\tvalid_0's binary_logloss: 0.0142921\n",
      "[17]\tvalid_0's auc: 0.651086\tvalid_0's binary_logloss: 0.0143252\n",
      "[18]\tvalid_0's auc: 0.651222\tvalid_0's binary_logloss: 0.0143181\n",
      "[19]\tvalid_0's auc: 0.65208\tvalid_0's binary_logloss: 0.014354\n",
      "[20]\tvalid_0's auc: 0.652599\tvalid_0's binary_logloss: 0.0143283\n",
      "[21]\tvalid_0's auc: 0.652888\tvalid_0's binary_logloss: 0.0143276\n",
      "[22]\tvalid_0's auc: 0.653221\tvalid_0's binary_logloss: 0.014327\n",
      "[23]\tvalid_0's auc: 0.653659\tvalid_0's binary_logloss: 0.0143525\n",
      "[24]\tvalid_0's auc: 0.654116\tvalid_0's binary_logloss: 0.0143265\n",
      "[25]\tvalid_0's auc: 0.654293\tvalid_0's binary_logloss: 0.0143544\n",
      "[26]\tvalid_0's auc: 0.655095\tvalid_0's binary_logloss: 0.0143371\n",
      "[27]\tvalid_0's auc: 0.655121\tvalid_0's binary_logloss: 0.0143381\n",
      "[28]\tvalid_0's auc: 0.655482\tvalid_0's binary_logloss: 0.0143493\n",
      "[29]\tvalid_0's auc: 0.655519\tvalid_0's binary_logloss: 0.0142879\n",
      "[30]\tvalid_0's auc: 0.655627\tvalid_0's binary_logloss: 0.0142834\n",
      "[31]\tvalid_0's auc: 0.656048\tvalid_0's binary_logloss: 0.0142815\n",
      "[32]\tvalid_0's auc: 0.656162\tvalid_0's binary_logloss: 0.0142907\n",
      "[33]\tvalid_0's auc: 0.656669\tvalid_0's binary_logloss: 0.0143088\n",
      "[34]\tvalid_0's auc: 0.656874\tvalid_0's binary_logloss: 0.0143027\n",
      "[35]\tvalid_0's auc: 0.656974\tvalid_0's binary_logloss: 0.0143387\n",
      "[36]\tvalid_0's auc: 0.65693\tvalid_0's binary_logloss: 0.0143209\n",
      "[37]\tvalid_0's auc: 0.657412\tvalid_0's binary_logloss: 0.0143533\n",
      "[38]\tvalid_0's auc: 0.65715\tvalid_0's binary_logloss: 0.014367\n",
      "[39]\tvalid_0's auc: 0.657562\tvalid_0's binary_logloss: 0.0146087\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.644349\tvalid_0's binary_logloss: 0.0142795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(objective='binary', silent=False)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型训练\n",
    "gbm.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=30,  eval_metric='auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "tutorial-scale",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./ckp/share_lgb_v1.pkl']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(gbm, './ckp/share_lgb_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = joblib.load('share_lgb_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "patent-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "settled-explosion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of prediction is: 0.7044774097498365\n"
     ]
    }
   ],
   "source": [
    "# 模型评估\n",
    "print('The accuracy of prediction is:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-vacuum",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "systematic-competition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "test_data = pd.read_csv(\"../dataset/testdata/user_video_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "dried-tucson",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = gbm.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "royal-armstrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_share_ans_df = pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "persistent-membrane",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.822180e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.385907e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.338678e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  2.822180e+06\n",
       "mean   5.385907e-05\n",
       "std    7.338678e-03\n",
       "min    0.000000e+00\n",
       "25%    0.000000e+00\n",
       "50%    0.000000e+00\n",
       "75%    0.000000e+00\n",
       "max    1.000000e+00"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_share_ans_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "canadian-stanley",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_share_ans_df.to_csv(\"../dataset/testdata/share_label_result.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "overall-pierce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.822180e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.385907e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.338678e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  2.822180e+06\n",
       "mean   5.385907e-05\n",
       "std    7.338678e-03\n",
       "min    0.000000e+00\n",
       "25%    0.000000e+00\n",
       "50%    0.000000e+00\n",
       "75%    0.000000e+00\n",
       "max    1.000000e+00"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_share_ans_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "static-bhutan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances: [32, 4, 5, 1, 1, 11, 0, 0, 0, 1, 1, 1, 0, 0, 1, 3, 5, 0, 4, 2, 0, 7, 4, 4, 3, 0, 0, 0, 2, 1, 3, 11, 24, 17, 14, 2, 1, 8, 1, 1, 1, 5, 7, 1, 0, 4, 3, 2, 1, 1, 4, 7, 1, 7, 2, 3, 1, 1, 5, 2, 0, 2, 3, 4, 5, 4, 4, 3, 2, 4, 1, 5]\n"
     ]
    }
   ],
   "source": [
    "print('Feature importances:', list(gbm.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-convergence",
   "metadata": {},
   "source": [
    "# 调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "independent-finding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 9101, number of negative: 4668030\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.466347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9747\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677131, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240108\n",
      "[LightGBM] [Info] Start training from score -6.240108\n",
      "[LightGBM] [Info] Number of positive: 9101, number of negative: 4668030\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.444159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9734\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677131, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240108\n",
      "[LightGBM] [Info] Start training from score -6.240108\n",
      "[LightGBM] [Info] Number of positive: 9101, number of negative: 4668030\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.435628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9736\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677131, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240108\n",
      "[LightGBM] [Info] Start training from score -6.240108\n",
      "[LightGBM] [Info] Number of positive: 9100, number of negative: 4668031\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.454049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9729\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677131, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240218\n",
      "[LightGBM] [Info] Start training from score -6.240218\n",
      "[LightGBM] [Info] Number of positive: 9101, number of negative: 4668031\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.429255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677132, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240108\n",
      "[LightGBM] [Info] Start training from score -6.240108\n",
      "[LightGBM] [Info] Number of positive: 9101, number of negative: 4668030\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.457996 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9747\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677131, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240108\n",
      "[LightGBM] [Info] Start training from score -6.240108\n",
      "[LightGBM] [Info] Number of positive: 9101, number of negative: 4668030\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.440927 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9734\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677131, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240108\n",
      "[LightGBM] [Info] Start training from score -6.240108\n",
      "[LightGBM] [Info] Number of positive: 9101, number of negative: 4668030\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.193292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9736\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677131, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240108\n",
      "[LightGBM] [Info] Start training from score -6.240108\n",
      "[LightGBM] [Info] Number of positive: 9100, number of negative: 4668031\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.449812 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9729\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677131, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240218\n",
      "[LightGBM] [Info] Start training from score -6.240218\n",
      "[LightGBM] [Info] Number of positive: 9101, number of negative: 4668031\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.447937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677132, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240108\n",
      "[LightGBM] [Info] Start training from score -6.240108\n",
      "[LightGBM] [Info] Number of positive: 9101, number of negative: 4668030\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.444590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9747\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677131, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240108\n",
      "[LightGBM] [Info] Start training from score -6.240108\n",
      "[LightGBM] [Info] Number of positive: 9101, number of negative: 4668030\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.441639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9734\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677131, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240108\n",
      "[LightGBM] [Info] Start training from score -6.240108\n",
      "[LightGBM] [Info] Number of positive: 9101, number of negative: 4668030\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.450590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9736\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677131, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240108\n",
      "[LightGBM] [Info] Start training from score -6.240108\n",
      "[LightGBM] [Info] Number of positive: 9100, number of negative: 4668031\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.194281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9729\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677131, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240218\n",
      "[LightGBM] [Info] Start training from score -6.240218\n",
      "[LightGBM] [Info] Number of positive: 9101, number of negative: 4668031\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.440403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677132, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240108\n",
      "[LightGBM] [Info] Start training from score -6.240108\n",
      "[LightGBM] [Info] Number of positive: 9101, number of negative: 4668030\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.195085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9747\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677131, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240108\n",
      "[LightGBM] [Info] Start training from score -6.240108\n",
      "[LightGBM] [Info] Number of positive: 9101, number of negative: 4668030\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.493694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9734\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677131, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240108\n",
      "[LightGBM] [Info] Start training from score -6.240108\n",
      "[LightGBM] [Info] Number of positive: 9101, number of negative: 4668030\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.494765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9736\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677131, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240108\n",
      "[LightGBM] [Info] Start training from score -6.240108\n",
      "[LightGBM] [Info] Number of positive: 9100, number of negative: 4668031\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.500805 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9729\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677131, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240218\n",
      "[LightGBM] [Info] Start training from score -6.240218\n",
      "[LightGBM] [Info] Number of positive: 9101, number of negative: 4668031\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.499834 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677132, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240108\n",
      "[LightGBM] [Info] Start training from score -6.240108\n",
      "[LightGBM] [Info] Number of positive: 9101, number of negative: 4668030\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.495108 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9747\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677131, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240108\n",
      "[LightGBM] [Info] Start training from score -6.240108\n",
      "[LightGBM] [Info] Number of positive: 9101, number of negative: 4668030\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.213130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9734\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677131, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240108\n",
      "[LightGBM] [Info] Start training from score -6.240108\n",
      "[LightGBM] [Info] Number of positive: 9101, number of negative: 4668030\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.722742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9736\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677131, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240108\n",
      "[LightGBM] [Info] Start training from score -6.240108\n",
      "[LightGBM] [Info] Number of positive: 9100, number of negative: 4668031\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.446386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9729\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677131, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240218\n",
      "[LightGBM] [Info] Start training from score -6.240218\n",
      "[LightGBM] [Info] Number of positive: 9101, number of negative: 4668031\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.696476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677132, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240108\n",
      "[LightGBM] [Info] Start training from score -6.240108\n",
      "[LightGBM] [Info] Number of positive: 9101, number of negative: 4668030\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.446713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9747\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677131, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240108\n",
      "[LightGBM] [Info] Start training from score -6.240108\n",
      "[LightGBM] [Info] Number of positive: 9101, number of negative: 4668030\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.438673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9734\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677131, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240108\n",
      "[LightGBM] [Info] Start training from score -6.240108\n",
      "[LightGBM] [Info] Number of positive: 9101, number of negative: 4668030\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.441126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9736\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677131, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240108\n",
      "[LightGBM] [Info] Start training from score -6.240108\n",
      "[LightGBM] [Info] Number of positive: 9100, number of negative: 4668031\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.440587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9729\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677131, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240218\n",
      "[LightGBM] [Info] Start training from score -6.240218\n",
      "[LightGBM] [Info] Number of positive: 9101, number of negative: 4668031\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.464965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677132, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240108\n",
      "[LightGBM] [Info] Start training from score -6.240108\n",
      "[LightGBM] [Info] Number of positive: 11376, number of negative: 5835038\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.605221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9736\n",
      "[LightGBM] [Info] Number of data points in the train set: 5846414, number of used features: 66\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001946 -> initscore=-6.240130\n",
      "[LightGBM] [Info] Start training from score -6.240130\n",
      "Best parameters found by grid search are: {'learning_rate': 0.01, 'n_estimators': 20}\n"
     ]
    }
   ],
   "source": [
    "# 网格搜索，参数优化\n",
    "estimator = lgb.LGBMClassifier(num_leaves=31,silent=False)\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'n_estimators': [20, 40],\n",
    "}\n",
    "gbm = GridSearchCV(estimator, param_grid)\n",
    "gbm.fit(X_train, y_train)\n",
    "print('Best parameters found by grid search are:', gbm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-yield",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
